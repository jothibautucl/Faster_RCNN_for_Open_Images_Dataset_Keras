2021-03-03 22:14:33.491557: I tensorflow/core/platform/profile_utils/cpu_utils.cc:102] CPU Frequency: 3800000000 Hz
2021-03-03 22:14:33.492714: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5588f1ba35a0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2021-03-03 22:14:33.492737: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2021-03-03 22:14:33.494495: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2021-03-03 22:14:34.158189: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5588f1b56400 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2021-03-03 22:14:34.158225: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): GeForce RTX 2080 SUPER, Compute Capability 7.5
2021-03-03 22:14:34.158705: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1558] Found device 0 with properties: 
pciBusID: 0000:65:00.0 name: GeForce RTX 2080 SUPER computeCapability: 7.5
coreClock: 1.845GHz coreCount: 48 deviceMemorySize: 7.79GiB deviceMemoryBandwidth: 462.00GiB/s
2021-03-03 22:14:34.158936: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.2
2021-03-03 22:14:34.160359: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2021-03-03 22:14:34.161689: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2021-03-03 22:14:34.161953: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2021-03-03 22:14:34.163369: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2021-03-03 22:14:34.164142: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2021-03-03 22:14:34.167190: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2021-03-03 22:14:34.167848: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1700] Adding visible gpu devices: 0
2021-03-03 22:14:34.167895: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.2
2021-03-03 22:14:34.168811: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1099] Device interconnect StreamExecutor with strength 1 edge matrix:
2021-03-03 22:14:34.168820: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1105]      0 
2021-03-03 22:14:34.168824: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1118] 0:   N 
2021-03-03 22:14:34.169451: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1244] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7184 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2080 SUPER, pci bus id: 0000:65:00.0, compute capability: 7.5)
2021-03-03 22:14:34.818417: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1558] Found device 0 with properties: 
pciBusID: 0000:65:00.0 name: GeForce RTX 2080 SUPER computeCapability: 7.5
coreClock: 1.845GHz coreCount: 48 deviceMemorySize: 7.79GiB deviceMemoryBandwidth: 462.00GiB/s
2021-03-03 22:14:34.818486: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.2
2021-03-03 22:14:34.818498: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2021-03-03 22:14:34.818508: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2021-03-03 22:14:34.818518: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2021-03-03 22:14:34.818527: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2021-03-03 22:14:34.818540: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2021-03-03 22:14:34.818550: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2021-03-03 22:14:34.819150: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1700] Adding visible gpu devices: 0
2021-03-03 22:14:34.819942: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1558] Found device 0 with properties: 
pciBusID: 0000:65:00.0 name: GeForce RTX 2080 SUPER computeCapability: 7.5
coreClock: 1.845GHz coreCount: 48 deviceMemorySize: 7.79GiB deviceMemoryBandwidth: 462.00GiB/s
2021-03-03 22:14:34.819994: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.2
2021-03-03 22:14:34.820005: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2021-03-03 22:14:34.820015: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2021-03-03 22:14:34.820024: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2021-03-03 22:14:34.820033: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2021-03-03 22:14:34.820043: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2021-03-03 22:14:34.820052: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2021-03-03 22:14:34.820602: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1700] Adding visible gpu devices: 0
2021-03-03 22:14:34.820624: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1099] Device interconnect StreamExecutor with strength 1 edge matrix:
2021-03-03 22:14:34.820630: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1105]      0 
2021-03-03 22:14:34.820634: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1118] 0:   N 
2021-03-03 22:14:34.821245: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1244] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7184 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2080 SUPER, pci bus id: 0000:65:00.0, compute capability: 7.5)
2021-03-03 22:14:37.137800: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2021-03-03 22:14:38.038565: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
Parsing annotation files
idx=1idx=2idx=3idx=4idx=5idx=6idx=7idx=8idx=9idx=10idx=11idx=12idx=13idx=14idx=15idx=16idx=17idx=18idx=19idx=20idx=21idx=22idx=23idx=24idx=25idx=26idx=27idx=28idx=29idx=30idx=31idx=32idx=33idx=34idx=35idx=36idx=37idx=38idx=39idx=40idx=41idx=42idx=43idx=44idx=45idx=46idx=47idx=48idx=49idx=50idx=51idx=52idx=53idx=54idx=55idx=56idx=57idx=58idx=59idx=60idx=61idx=62idx=63idx=64idx=65idx=66idx=67idx=68idx=69idx=70idx=71idx=72idx=73idx=74idx=75idx=76idx=77idx=78idx=79idx=80idx=81idx=82idx=83idx=84idx=85idx=86idx=87idx=88idx=89idx=90idx=91idx=92idx=93idx=94idx=95idx=96idx=97
Spend 0.01 mins to load the data
Training images per class:
{'bg': 0, 'bourdon_des_jardins': 97}
Num classes (including bg) = 2
{'bourdon_des_jardins': 0, 'bg': 1}
Config has been written to ./config/test_100_bourdons_val.pickle, and can be loaded when testing to ensure correct results
Num train samples (images) 97
=== Fold 1/4 ===
Loading weights from ./model/vgg16_weights_tf_dim_ordering_tf_kernels.h5
Epoch 1/2

 1/72 [..............................] - ETA: 6:00 - rpn_cls: 9.3907 - rpn_regr: 0.1411 - final_cls: 0.6931 - final_regr: 0.4526 - loss: 10.6776
 2/72 [..............................] - ETA: 3:31 - rpn_cls: 7.0448 - rpn_regr: 0.1326 - final_cls: 0.6930 - final_regr: 0.4578 - loss: 8.3282 
 3/72 [>.............................] - ETA: 2:23 - rpn_cls: 6.4806 - rpn_regr: 0.1572 - final_cls: 0.6936 - final_regr: 0.4901 - loss: 7.8215
 4/72 [>.............................] - ETA: 1:58 - rpn_cls: 6.2447 - rpn_regr: 0.1815 - final_cls: 0.6939 - final_regr: 0.5114 - loss: 7.6315
 5/72 [=>............................] - ETA: 1:44 - rpn_cls: 5.9918 - rpn_regr: 0.1886 - final_cls: 0.6939 - final_regr: 0.5166 - loss: 7.3910
 6/72 [=>............................] - ETA: 1:27 - rpn_cls: 5.8610 - rpn_regr: 0.1921 - final_cls: 0.6943 - final_regr: 0.5052 - loss: 7.2526
 7/72 [=>............................] - ETA: 1:22 - rpn_cls: 5.7883 - rpn_regr: 0.1948 - final_cls: 0.6946 - final_regr: 0.4977 - loss: 7.1754
 8/72 [==>...........................] - ETA: 1:19 - rpn_cls: 5.7926 - rpn_regr: 0.1951 - final_cls: 0.6951 - final_regr: 0.4930 - loss: 7.1759
 9/72 [==>...........................] - ETA: 1:15 - rpn_cls: 5.7426 - rpn_regr: 0.1948 - final_cls: 0.6955 - final_regr: 0.4928 - loss: 7.1258
10/72 [===>..........................] - ETA: 1:12 - rpn_cls: 5.6518 - rpn_regr: 0.1943 - final_cls: 0.6958 - final_regr: 0.4905 - loss: 7.0324
11/72 [===>..........................] - ETA: 1:06 - rpn_cls: 5.6041 - rpn_regr: 0.1942 - final_cls: 0.6962 - final_regr: 0.4865 - loss: 6.9810
12/72 [====>.........................] - ETA: 1:02 - rpn_cls: 5.6071 - rpn_regr: 0.1932 - final_cls: 0.6964 - final_regr: 0.4825 - loss: 6.9793
13/72 [====>.........................] - ETA: 1:00 - rpn_cls: 5.6528 - rpn_regr: 0.1916 - final_cls: 0.6966 - final_regr: 0.4789 - loss: 7.0199
14/72 [====>.........................] - ETA: 56s - rpn_cls: 5.6604 - rpn_regr: 0.1901 - final_cls: 0.6968 - final_regr: 0.4759 - loss: 7.0232 
15/72 [=====>........................] - ETA: 52s - rpn_cls: 5.6619 - rpn_regr: 0.1887 - final_cls: 0.6969 - final_regr: 0.4726 - loss: 7.0201
16/72 [=====>........................] - ETA: 50s - rpn_cls: 5.6586 - rpn_regr: 0.1875 - final_cls: 0.6971 - final_regr: 0.4697 - loss: 7.0130
17/72 [======>.......................] - ETA: 47s - rpn_cls: 5.6524 - rpn_regr: 0.1861 - final_cls: 0.6972 - final_regr: 0.4667 - loss: 7.0024
18/72 [======>.......................] - ETA: 44s - rpn_cls: 5.6376 - rpn_regr: 0.1848 - final_cls: 0.6973 - final_regr: 0.4638 - loss: 6.9835
19/72 [======>.......................] - ETA: 44s - rpn_cls: 5.6323 - rpn_regr: 0.1837 - final_cls: 0.6974 - final_regr: 0.4615 - loss: 6.9748
20/72 [=======>......................] - ETA: 43s - rpn_cls: 5.6350 - rpn_regr: 0.1829 - final_cls: 0.6974 - final_regr: 0.4595 - loss: 6.9749
21/72 [=======>......................] - ETA: 41s - rpn_cls: 5.6247 - rpn_regr: 0.1824 - final_cls: 0.6974 - final_regr: 0.4580 - loss: 6.9624
22/72 [========>.....................] - ETA: 40s - rpn_cls: 5.6176 - rpn_regr: 0.1820 - final_cls: 0.6973 - final_regr: 0.4561 - loss: 6.9531
23/72 [========>.....................] - ETA: 39s - rpn_cls: 5.6091 - rpn_regr: 0.1818 - final_cls: 0.6973 - final_regr: 0.4543 - loss: 6.9425
24/72 [=========>....................] - ETA: 38s - rpn_cls: 5.5922 - rpn_regr: 0.1813 - final_cls: 0.6972 - final_regr: 0.4523 - loss: 6.9230
25/72 [=========>....................] - ETA: 37s - rpn_cls: 5.5796 - rpn_regr: 0.1807 - final_cls: 0.6972 - final_regr: 0.4502 - loss: 6.9077
26/72 [=========>....................] - ETA: 36s - rpn_cls: 5.5666 - rpn_regr: 0.1800 - final_cls: 0.6971 - final_regr: 0.4487 - loss: 6.8925
27/72 [==========>...................] - ETA: 35s - rpn_cls: 5.5612 - rpn_regr: 0.1793 - final_cls: 0.6970 - final_regr: 0.4473 - loss: 6.8849
28/72 [==========>...................] - ETA: 33s - rpn_cls: 5.5493 - rpn_regr: 0.1788 - final_cls: 0.6969 - final_regr: 0.4460 - loss: 6.8711
29/72 [===========>..................] - ETA: 32s - rpn_cls: 5.5351 - rpn_regr: 0.1782 - final_cls: 0.6969 - final_regr: 0.4448 - loss: 6.8550
30/72 [===========>..................] - ETA: 30s - rpn_cls: 5.5198 - rpn_regr: 0.1776 - final_cls: 0.6968 - final_regr: 0.4437 - loss: 6.8380
31/72 [===========>..................] - ETA: 29s - rpn_cls: 5.5100 - rpn_regr: 0.1770 - final_cls: 0.6967 - final_regr: 0.4426 - loss: 6.8263
32/72 [============>.................] - ETA: 28s - rpn_cls: 5.5079 - rpn_regr: 0.1764 - final_cls: 0.6966 - final_regr: 0.4412 - loss: 6.8221
33/72 [============>.................] - ETA: 26s - rpn_cls: 5.5037 - rpn_regr: 0.1758 - final_cls: 0.6966 - final_regr: 0.4399 - loss: 6.8160
34/72 [=============>................] - ETA: 26s - rpn_cls: 5.5015 - rpn_regr: 0.1752 - final_cls: 0.6965 - final_regr: 0.4386 - loss: 6.8118
35/72 [=============>................] - ETA: 25s - rpn_cls: 5.4977 - rpn_regr: 0.1746 - final_cls: 0.6964 - final_regr: 0.4374 - loss: 6.8061
36/72 [==============>...............] - ETA: 24s - rpn_cls: 5.4917 - rpn_regr: 0.1739 - final_cls: 0.6963 - final_regr: 0.4361 - loss: 6.7979
37/72 [==============>...............] - ETA: 23s - rpn_cls: 5.4837 - rpn_regr: 0.1731 - final_cls: 0.6962 - final_regr: 0.4348 - loss: 6.7879
38/72 [==============>...............] - ETA: 22s - rpn_cls: 5.4726 - rpn_regr: 0.1724 - final_cls: 0.6962 - final_regr: 0.4338 - loss: 6.7750
39/72 [===============>..............] - ETA: 21s - rpn_cls: 5.4597 - rpn_regr: 0.1718 - final_cls: 0.6961 - final_regr: 0.4328 - loss: 6.7605
40/72 [===============>..............] - ETA: 20s - rpn_cls: 5.4512 - rpn_regr: 0.1712 - final_cls: 0.6960 - final_regr: 0.4319 - loss: 6.7504
41/72 [================>.............] - ETA: 19s - rpn_cls: 5.4423 - rpn_regr: 0.1706 - final_cls: 0.6960 - final_regr: 0.4310 - loss: 6.7398
42/72 [================>.............] - ETA: 18s - rpn_cls: 5.4347 - rpn_regr: 0.1699 - final_cls: 0.6959 - final_regr: 0.4301 - loss: 6.7306
43/72 [================>.............] - ETA: 18s - rpn_cls: 5.4282 - rpn_regr: 0.1694 - final_cls: 0.6958 - final_regr: 0.4291 - loss: 6.7225
44/72 [=================>............] - ETA: 17s - rpn_cls: 5.4196 - rpn_regr: 0.1688 - final_cls: 0.6957 - final_regr: 0.4283 - loss: 6.7124
45/72 [=================>............] - ETA: 16s - rpn_cls: 5.4127 - rpn_regr: 0.1682 - final_cls: 0.6957 - final_regr: 0.4275 - loss: 6.7041
46/72 [==================>...........] - ETA: 15s - rpn_cls: 5.4069 - rpn_regr: 0.1676 - final_cls: 0.6956 - final_regr: 0.4270 - loss: 6.6971
47/72 [==================>...........] - ETA: 14s - rpn_cls: 5.4016 - rpn_regr: 0.1670 - final_cls: 0.6956 - final_regr: 0.4264 - loss: 6.6905
48/72 [===================>..........] - ETA: 14s - rpn_cls: 5.3953 - rpn_regr: 0.1664 - final_cls: 0.6955 - final_regr: 0.4257 - loss: 6.6829
49/72 [===================>..........] - ETA: 13s - rpn_cls: 5.3903 - rpn_regr: 0.1658 - final_cls: 0.6954 - final_regr: 0.4251 - loss: 6.6766
50/72 [===================>..........] - ETA: 12s - rpn_cls: 5.3841 - rpn_regr: 0.1653 - final_cls: 0.6954 - final_regr: 0.4244 - loss: 6.6691
51/72 [====================>.........] - ETA: 12s - rpn_cls: 5.3775 - rpn_regr: 0.1647 - final_cls: 0.6953 - final_regr: 0.4237 - loss: 6.6612
52/72 [====================>.........] - ETA: 11s - rpn_cls: 5.3693 - rpn_regr: 0.1642 - final_cls: 0.6952 - final_regr: 0.4231 - loss: 6.6518
53/72 [=====================>........] - ETA: 11s - rpn_cls: 5.3626 - rpn_regr: 0.1637 - final_cls: 0.6951 - final_regr: 0.4226 - loss: 6.6440
54/72 [=====================>........] - ETA: 10s - rpn_cls: 5.3566 - rpn_regr: 0.1632 - final_cls: 0.6950 - final_regr: 0.4221 - loss: 6.6369
55/72 [=====================>........] - ETA: 9s - rpn_cls: 5.3515 - rpn_regr: 0.1626 - final_cls: 0.6949 - final_regr: 0.4216 - loss: 6.6307 
56/72 [======================>.......] - ETA: 9s - rpn_cls: 5.3470 - rpn_regr: 0.1621 - final_cls: 0.6949 - final_regr: 0.4211 - loss: 6.6251
57/72 [======================>.......] - ETA: 8s - rpn_cls: 5.3416 - rpn_regr: 0.1616 - final_cls: 0.6948 - final_regr: 0.4206 - loss: 6.6186
58/72 [=======================>......] - ETA: 7s - rpn_cls: 5.3368 - rpn_regr: 0.1612 - final_cls: 0.6947 - final_regr: 0.4201 - loss: 6.6127
59/72 [=======================>......] - ETA: 7s - rpn_cls: 5.3316 - rpn_regr: 0.1608 - final_cls: 0.6946 - final_regr: 0.4196 - loss: 6.6065
60/72 [========================>.....] - ETA: 6s - rpn_cls: 5.3264 - rpn_regr: 0.1603 - final_cls: 0.6945 - final_regr: 0.4191 - loss: 6.6004
61/72 [========================>.....] - ETA: 6s - rpn_cls: 5.3206 - rpn_regr: 0.1599 - final_cls: 0.6944 - final_regr: 0.4187 - loss: 6.5935
62/72 [========================>.....] - ETA: 5s - rpn_cls: 5.3136 - rpn_regr: 0.1594 - final_cls: 0.6943 - final_regr: 0.4183 - loss: 6.5856
63/72 [=========================>....] - ETA: 4s - rpn_cls: 5.3061 - rpn_regr: 0.1589 - final_cls: 0.6942 - final_regr: 0.4179 - loss: 6.5772
64/72 [=========================>....] - ETA: 4s - rpn_cls: 5.2976 - rpn_regr: 0.1585 - final_cls: 0.6941 - final_regr: 0.4176 - loss: 6.5678
65/72 [==========================>...] - ETA: 3s - rpn_cls: 5.2883 - rpn_regr: 0.1580 - final_cls: 0.6940 - final_regr: 0.4172 - loss: 6.5576
66/72 [==========================>...] - ETA: 3s - rpn_cls: 5.2782 - rpn_regr: 0.1576 - final_cls: 0.6939 - final_regr: 0.4169 - loss: 6.5466
67/72 [==========================>...] - ETA: 2s - rpn_cls: 5.2674 - rpn_regr: 0.1571 - final_cls: 0.6937 - final_regr: 0.4166 - loss: 6.5349
68/72 [===========================>..] - ETA: 2s - rpn_cls: 5.2572 - rpn_regr: 0.1568 - final_cls: 0.6936 - final_regr: 0.4162 - loss: 6.5239
69/72 [===========================>..] - ETA: 1s - rpn_cls: 5.2481 - rpn_regr: 0.1564 - final_cls: 0.6935 - final_regr: 0.4159 - loss: 6.5139
70/72 [============================>.] - ETA: 1s - rpn_cls: 5.2387 - rpn_regr: 0.1561 - final_cls: 0.6934 - final_regr: 0.4156 - loss: 6.5038
71/72 [============================>.] - ETA: 0s - rpn_cls: 5.2290 - rpn_regr: 0.1558 - final_cls: 0.6933 - final_regr: 0.4152 - loss: 6.4933
72/72 [==============================] - 39s 539ms/step - rpn_cls: 5.2193 - rpn_regr: 0.1555 - final_cls: 0.6931 - final_regr: 0.4150 - loss: 6.4828
Mean number of bounding boxes from RPN overlapping ground truth boxes: 9.305555555555555
Classifier accuracy for bounding boxes from RPN: 0.5833333333333334
Loss RPN classifier: 4.528436426676236
Loss RPN regression: 0.13390465556747383
Loss Detector classifier: 0.6845827649037043
Loss Detector regression: 0.3937904126942158
Total loss: 5.74071425984163
Elapsed time: 38.789977073669434
Start of the validation phase

 1/25 [>.............................] - ETA: 15:42 - rpn_cls_val: 4.8375e-05 - rpn_regr_val: 0.7553 - final_cls_val: 0.6121 - final_regr_val: 0.7616 - loss_val: 2.1290
 2/25 [=>............................] - ETA: 7:34 - rpn_cls_val: 0.0040 - rpn_regr_val: 0.5776 - final_cls_val: 0.6253 - final_regr_val: 0.7333 - loss_val: 1.9403     
 3/25 [==>...........................] - ETA: 4:50 - rpn_cls_val: 0.1692 - rpn_regr_val: 0.5173 - final_cls_val: 0.6314 - final_regr_val: 0.7161 - loss_val: 2.0339
 4/25 [===>..........................] - ETA: 3:29 - rpn_cls_val: 0.8513 - rpn_regr_val: 0.4796 - final_cls_val: 0.6362 - final_regr_val: 0.6649 - loss_val: 2.6319
 5/25 [=====>........................] - ETA: 2:39 - rpn_cls_val: 1.4011 - rpn_regr_val: 0.4534 - final_cls_val: 0.6412 - final_regr_val: 0.6255 - loss_val: 3.1213
 6/25 [======>.......................] - ETA: 2:06 - rpn_cls_val: 1.8892 - rpn_regr_val: 0.4340 - final_cls_val: 0.6440 - final_regr_val: 0.6007 - loss_val: 3.5679
 7/25 [=======>......................] - ETA: 1:43 - rpn_cls_val: 2.1872 - rpn_regr_val: 0.4160 - final_cls_val: 0.6464 - final_regr_val: 0.5821 - loss_val: 3.8316
 8/25 [========>.....................] - ETA: 1:25 - rpn_cls_val: 2.5123 - rpn_regr_val: 0.3992 - final_cls_val: 0.6468 - final_regr_val: 0.5644 - loss_val: 4.1227
 9/25 [=========>....................] - ETA: 1:12 - rpn_cls_val: 2.7852 - rpn_regr_val: 0.3865 - final_cls_val: 0.6480 - final_regr_val: 0.5515 - loss_val: 4.3711
10/25 [===========>..................] - ETA: 1:00 - rpn_cls_val: 2.9581 - rpn_regr_val: 0.3788 - final_cls_val: 0.6486 - final_regr_val: 0.5410 - loss_val: 4.5266
11/25 [============>.................] - ETA: 51s - rpn_cls_val: 3.0921 - rpn_regr_val: 0.3708 - final_cls_val: 0.6487 - final_regr_val: 0.5322 - loss_val: 4.6438 
12/25 [=============>................] - ETA: 44s - rpn_cls_val: 3.1730 - rpn_regr_val: 0.3657 - final_cls_val: 0.6482 - final_regr_val: 0.5253 - loss_val: 4.7122
13/25 [==============>...............] - ETA: 37s - rpn_cls_val: 3.2342 - rpn_regr_val: 0.3598 - final_cls_val: 0.6479 - final_regr_val: 0.5210 - loss_val: 4.7628
14/25 [===============>..............] - ETA: 32s - rpn_cls_val: 3.2666 - rpn_regr_val: 0.3537 - final_cls_val: 0.6474 - final_regr_val: 0.5166 - loss_val: 4.7843
15/25 [=================>............] - ETA: 27s - rpn_cls_val: 3.3072 - rpn_regr_val: 0.3481 - final_cls_val: 0.6471 - final_regr_val: 0.5123 - loss_val: 4.8146
16/25 [==================>...........] - ETA: 23s - rpn_cls_val: 3.3287 - rpn_regr_val: 0.3432 - final_cls_val: 0.6468 - final_regr_val: 0.5092 - loss_val: 4.8279
17/25 [===================>..........] - ETA: 19s - rpn_cls_val: 3.3449 - rpn_regr_val: 0.3391 - final_cls_val: 0.6468 - final_regr_val: 0.5069 - loss_val: 4.8376
18/25 [====================>.........] - ETA: 16s - rpn_cls_val: 3.3673 - rpn_regr_val: 0.3347 - final_cls_val: 0.6468 - final_regr_val: 0.5034 - loss_val: 4.85212021-03-03 22:15:17.421140: W tensorflow/core/common_runtime/bfc_allocator.cc:245] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.96GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2021-03-03 22:15:17.421185: W tensorflow/core/common_runtime/bfc_allocator.cc:245] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.96GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.

19/25 [=====================>........] - ETA: 13s - rpn_cls_val: 3.3834 - rpn_regr_val: 0.3304 - final_cls_val: 0.6467 - final_regr_val: 0.4999 - loss_val: 4.8604
20/25 [=======================>......] - ETA: 10s - rpn_cls_val: 3.3890 - rpn_regr_val: 0.3262 - final_cls_val: 0.6465 - final_regr_val: 0.4971 - loss_val: 4.8588
21/25 [========================>.....] - ETA: 8s - rpn_cls_val: 3.3967 - rpn_regr_val: 0.3221 - final_cls_val: 0.6464 - final_regr_val: 0.4943 - loss_val: 4.8594 
22/25 [=========================>....] - ETA: 5s - rpn_cls_val: 3.3963 - rpn_regr_val: 0.3180 - final_cls_val: 0.6460 - final_regr_val: 0.4916 - loss_val: 4.8520
23/25 [==========================>...] - ETA: 3s - rpn_cls_val: 3.4003 - rpn_regr_val: 0.3143 - final_cls_val: 0.6459 - final_regr_val: 0.4890 - loss_val: 4.8496
24/25 [===========================>..] - ETA: 1s - rpn_cls_val: 3.3979 - rpn_regr_val: 0.3107 - final_cls_val: 0.6457 - final_regr_val: 0.4868 - loss_val: 4.8411
25/25 [==============================] - 43s 2s/step - rpn_cls_val: 3.3934 - rpn_regr_val: 0.3073 - final_cls_val: 0.6455 - final_regr_val: 0.4849 - loss_val: 4.8310
End of the validation phase
Validation classifier accuracy for bounding boxes from RPN: 0.76
Validation loss RPN classifier: 3.285257183749636
Validation loss RPN regression: 0.22503365486860274
Validation loss Detector classifier: 0.6411311340332031
Validation loss Detector regression: 0.43764290273189543
Total validation loss: 4.589064875383338
Total validation loss decreased from inf to 4.589064875383338
Epoch 2/2

 1/72 [..............................] - ETA: 11s - rpn_cls: 6.1308 - rpn_regr: 0.1300 - final_cls: 0.5890 - final_regr: 0.3047 - loss: 7.1545
 2/72 [..............................] - ETA: 12s - rpn_cls: 4.8041 - rpn_regr: 0.1011 - final_cls: 0.6079 - final_regr: 0.2872 - loss: 5.8004
 3/72 [>.............................] - ETA: 12s - rpn_cls: 4.7259 - rpn_regr: 0.1014 - final_cls: 0.6216 - final_regr: 0.3215 - loss: 5.7704
 4/72 [>.............................] - ETA: 11s - rpn_cls: 4.4011 - rpn_regr: 0.1220 - final_cls: 0.6204 - final_regr: 0.3555 - loss: 5.4990
 5/72 [=>............................] - ETA: 11s - rpn_cls: 4.1731 - rpn_regr: 0.1346 - final_cls: 0.6175 - final_regr: 0.3637 - loss: 5.2889
 6/72 [=>............................] - ETA: 11s - rpn_cls: 4.1086 - rpn_regr: 0.1493 - final_cls: 0.6117 - final_regr: 0.3686 - loss: 5.2383
 7/72 [=>............................] - ETA: 10s - rpn_cls: 4.0960 - rpn_regr: 0.1589 - final_cls: 0.6101 - final_regr: 0.3728 - loss: 5.2379
 8/72 [==>...........................] - ETA: 10s - rpn_cls: 4.0587 - rpn_regr: 0.1678 - final_cls: 0.6097 - final_regr: 0.3820 - loss: 5.2182
 9/72 [==>...........................] - ETA: 10s - rpn_cls: 4.0636 - rpn_regr: 0.1733 - final_cls: 0.6097 - final_regr: 0.3877 - loss: 5.2343
10/72 [===>..........................] - ETA: 10s - rpn_cls: 4.0513 - rpn_regr: 0.1807 - final_cls: 0.6097 - final_regr: 0.3961 - loss: 5.2378
11/72 [===>..........................] - ETA: 10s - rpn_cls: 4.0089 - rpn_regr: 0.1858 - final_cls: 0.6103 - final_regr: 0.4026 - loss: 5.2075
12/72 [====>.........................] - ETA: 10s - rpn_cls: 3.9600 - rpn_regr: 0.1894 - final_cls: 0.6107 - final_regr: 0.4058 - loss: 5.1659
13/72 [====>.........................] - ETA: 10s - rpn_cls: 3.9101 - rpn_regr: 0.1912 - final_cls: 0.6108 - final_regr: 0.4083 - loss: 5.1204
14/72 [====>.........................] - ETA: 9s - rpn_cls: 3.8509 - rpn_regr: 0.1922 - final_cls: 0.6105 - final_regr: 0.4116 - loss: 5.0651 
15/72 [=====>........................] - ETA: 9s - rpn_cls: 3.8414 - rpn_regr: 0.1924 - final_cls: 0.6106 - final_regr: 0.4136 - loss: 5.0580
16/72 [=====>........................] - ETA: 9s - rpn_cls: 3.8234 - rpn_regr: 0.1927 - final_cls: 0.6102 - final_regr: 0.4159 - loss: 5.0422
17/72 [======>.......................] - ETA: 9s - rpn_cls: 3.8039 - rpn_regr: 0.1926 - final_cls: 0.6101 - final_regr: 0.4179 - loss: 5.0246
18/72 [======>.......................] - ETA: 9s - rpn_cls: 3.7887 - rpn_regr: 0.1925 - final_cls: 0.6101 - final_regr: 0.4193 - loss: 5.0107
19/72 [======>.......................] - ETA: 8s - rpn_cls: 3.7723 - rpn_regr: 0.1925 - final_cls: 0.6107 - final_regr: 0.4204 - loss: 4.9958
20/72 [=======>......................] - ETA: 9s - rpn_cls: 3.7652 - rpn_regr: 0.1926 - final_cls: 0.6108 - final_regr: 0.4213 - loss: 4.9900
21/72 [=======>......................] - ETA: 9s - rpn_cls: 3.7648 - rpn_regr: 0.1929 - final_cls: 0.6106 - final_regr: 0.4219 - loss: 4.9903
22/72 [========>.....................] - ETA: 10s - rpn_cls: 3.7567 - rpn_regr: 0.1934 - final_cls: 0.6102 - final_regr: 0.4221 - loss: 4.9825
23/72 [========>.....................] - ETA: 10s - rpn_cls: 3.7426 - rpn_regr: 0.1939 - final_cls: 0.6099 - final_regr: 0.4229 - loss: 4.9692
24/72 [=========>....................] - ETA: 9s - rpn_cls: 3.7236 - rpn_regr: 0.1947 - final_cls: 0.6094 - final_regr: 0.4228 - loss: 4.9505 
25/72 [=========>....................] - ETA: 9s - rpn_cls: 3.7013 - rpn_regr: 0.1954 - final_cls: 0.6087 - final_regr: 0.4230 - loss: 4.9284
26/72 [=========>....................] - ETA: 10s - rpn_cls: 3.6904 - rpn_regr: 0.1963 - final_cls: 0.6079 - final_regr: 0.4235 - loss: 4.9182
27/72 [==========>...................] - ETA: 9s - rpn_cls: 3.6757 - rpn_regr: 0.1971 - final_cls: 0.6072 - final_regr: 0.4239 - loss: 4.9040 
28/72 [==========>...................] - ETA: 9s - rpn_cls: 3.6579 - rpn_regr: 0.1978 - final_cls: 0.6063 - final_regr: 0.4240 - loss: 4.8860
29/72 [===========>..................] - ETA: 9s - rpn_cls: 3.6442 - rpn_regr: 0.1983 - final_cls: 0.6060 - final_regr: 0.4239 - loss: 4.8724
30/72 [===========>..................] - ETA: 8s - rpn_cls: 3.6352 - rpn_regr: 0.1985 - final_cls: 0.6056 - final_regr: 0.4239 - loss: 4.8632
31/72 [===========>..................] - ETA: 8s - rpn_cls: 3.6282 - rpn_regr: 0.1986 - final_cls: 0.6054 - final_regr: 0.4237 - loss: 4.8559
32/72 [============>.................] - ETA: 8s - rpn_cls: 3.6246 - rpn_regr: 0.1988 - final_cls: 0.6057 - final_regr: 0.4239 - loss: 4.8530
33/72 [============>.................] - ETA: 8s - rpn_cls: 3.6223 - rpn_regr: 0.1989 - final_cls: 0.6059 - final_regr: 0.4238 - loss: 4.8510
34/72 [=============>................] - ETA: 7s - rpn_cls: 3.6194 - rpn_regr: 0.1990 - final_cls: 0.6059 - final_regr: 0.4237 - loss: 4.8481
35/72 [=============>................] - ETA: 8s - rpn_cls: 3.6141 - rpn_regr: 0.1989 - final_cls: 0.6057 - final_regr: 0.4236 - loss: 4.8424
36/72 [==============>...............] - ETA: 8s - rpn_cls: 3.6104 - rpn_regr: 0.1987 - final_cls: 0.6056 - final_regr: 0.4234 - loss: 4.8381
37/72 [==============>...............] - ETA: 7s - rpn_cls: 3.6070 - rpn_regr: 0.1985 - final_cls: 0.6054 - final_regr: 0.4230 - loss: 4.8339
38/72 [==============>...............] - ETA: 7s - rpn_cls: 3.6015 - rpn_regr: 0.1982 - final_cls: 0.6050 - final_regr: 0.4226 - loss: 4.8274
39/72 [===============>..............] - ETA: 7s - rpn_cls: 3.5940 - rpn_regr: 0.1980 - final_cls: 0.6046 - final_regr: 0.4223 - loss: 4.8189
40/72 [===============>..............] - ETA: 7s - rpn_cls: 3.5848 - rpn_regr: 0.1980 - final_cls: 0.6048 - final_regr: 0.4222 - loss: 4.8098
41/72 [================>.............] - ETA: 6s - rpn_cls: 3.5741 - rpn_regr: 0.1979 - final_cls: 0.6052 - final_regr: 0.4219 - loss: 4.7992
42/72 [================>.............] - ETA: 6s - rpn_cls: 3.5622 - rpn_regr: 0.1978 - final_cls: 0.6054 - final_regr: 0.4217 - loss: 4.7871
43/72 [================>.............] - ETA: 6s - rpn_cls: 3.5492 - rpn_regr: 0.1976 - final_cls: 0.6057 - final_regr: 0.4215 - loss: 4.7740
44/72 [=================>............] - ETA: 6s - rpn_cls: 3.5352 - rpn_regr: 0.1975 - final_cls: 0.6058 - final_regr: 0.4213 - loss: 4.7598
45/72 [=================>............] - ETA: 5s - rpn_cls: 3.5209 - rpn_regr: 0.1973 - final_cls: 0.6064 - final_regr: 0.4210 - loss: 4.7455
46/72 [==================>...........] - ETA: 5s - rpn_cls: 3.5059 - rpn_regr: 0.1970 - final_cls: 0.6068 - final_regr: 0.4207 - loss: 4.7304
47/72 [==================>...........] - ETA: 5s - rpn_cls: 3.4915 - rpn_regr: 0.1967 - final_cls: 0.6072 - final_regr: 0.4204 - loss: 4.7158
48/72 [===================>..........] - ETA: 5s - rpn_cls: 3.4775 - rpn_regr: 0.1964 - final_cls: 0.6074 - final_regr: 0.4201 - loss: 4.7015
49/72 [===================>..........] - ETA: 4s - rpn_cls: 3.4675 - rpn_regr: 0.1961 - final_cls: 0.6077 - final_regr: 0.4199 - loss: 4.6912
50/72 [===================>..........] - ETA: 4s - rpn_cls: 3.4566 - rpn_regr: 0.1957 - final_cls: 0.6080 - final_regr: 0.4197 - loss: 4.6800
51/72 [====================>.........] - ETA: 4s - rpn_cls: 3.4457 - rpn_regr: 0.1953 - final_cls: 0.6083 - final_regr: 0.4195 - loss: 4.6688
52/72 [====================>.........] - ETA: 4s - rpn_cls: 3.4342 - rpn_regr: 0.1949 - final_cls: 0.6084 - final_regr: 0.4193 - loss: 4.6568
53/72 [=====================>........] - ETA: 4s - rpn_cls: 3.4227 - rpn_regr: 0.1946 - final_cls: 0.6085 - final_regr: 0.4191 - loss: 4.6449
54/72 [=====================>........] - ETA: 4s - rpn_cls: 3.4118 - rpn_regr: 0.1942 - final_cls: 0.6086 - final_regr: 0.4191 - loss: 4.6337
55/72 [=====================>........] - ETA: 3s - rpn_cls: 3.4015 - rpn_regr: 0.1938 - final_cls: 0.6087 - final_regr: 0.4190 - loss: 4.6231
56/72 [======================>.......] - ETA: 3s - rpn_cls: 3.3907 - rpn_regr: 0.1934 - final_cls: 0.6088 - final_regr: 0.4189 - loss: 4.6118
57/72 [======================>.......] - ETA: 3s - rpn_cls: 3.3799 - rpn_regr: 0.1930 - final_cls: 0.6087 - final_regr: 0.4187 - loss: 4.6003
58/72 [=======================>......] - ETA: 3s - rpn_cls: 3.3704 - rpn_regr: 0.1927 - final_cls: 0.6086 - final_regr: 0.4185 - loss: 4.5902
59/72 [=======================>......] - ETA: 2s - rpn_cls: 3.3615 - rpn_regr: 0.1923 - final_cls: 0.6085 - final_regr: 0.4183 - loss: 4.5806
60/72 [========================>.....] - ETA: 2s - rpn_cls: 3.3525 - rpn_regr: 0.1919 - final_cls: 0.6085 - final_regr: 0.4180 - loss: 4.5710
61/72 [========================>.....] - ETA: 2s - rpn_cls: 3.3446 - rpn_regr: 0.1915 - final_cls: 0.6084 - final_regr: 0.4177 - loss: 4.5622
62/72 [========================>.....] - ETA: 2s - rpn_cls: 3.3378 - rpn_regr: 0.1911 - final_cls: 0.6083 - final_regr: 0.4174 - loss: 4.5546
63/72 [=========================>....] - ETA: 1s - rpn_cls: 3.3311 - rpn_regr: 0.1906 - final_cls: 0.6080 - final_regr: 0.4172 - loss: 4.5469
64/72 [=========================>....] - ETA: 1s - rpn_cls: 3.3255 - rpn_regr: 0.1902 - final_cls: 0.6077 - final_regr: 0.4169 - loss: 4.5403
65/72 [==========================>...] - ETA: 1s - rpn_cls: 3.3204 - rpn_regr: 0.1897 - final_cls: 0.6073 - final_regr: 0.4166 - loss: 4.5341
66/72 [==========================>...] - ETA: 1s - rpn_cls: 3.3148 - rpn_regr: 0.1892 - final_cls: 0.6070 - final_regr: 0.4163 - loss: 4.5273
67/72 [==========================>...] - ETA: 1s - rpn_cls: 3.3087 - rpn_regr: 0.1888 - final_cls: 0.6066 - final_regr: 0.4160 - loss: 4.5200
68/72 [===========================>..] - ETA: 0s - rpn_cls: 3.3035 - rpn_regr: 0.1883 - final_cls: 0.6061 - final_regr: 0.4157 - loss: 4.5136
69/72 [===========================>..] - ETA: 0s - rpn_cls: 3.2992 - rpn_regr: 0.1879 - final_cls: 0.6057 - final_regr: 0.4154 - loss: 4.5082
70/72 [============================>.] - ETA: 0s - rpn_cls: 3.2948 - rpn_regr: 0.1876 - final_cls: 0.6053 - final_regr: 0.4151 - loss: 4.5028
71/72 [============================>.] - ETA: 0s - rpn_cls: 3.2899 - rpn_regr: 0.1872 - final_cls: 0.6048 - final_regr: 0.4149 - loss: 4.4969
72/72 [==============================] - 16s 226ms/step - rpn_cls: 3.2854 - rpn_regr: 0.1869 - final_cls: 0.6044 - final_regr: 0.4147 - loss: 4.4914
Mean number of bounding boxes from RPN overlapping ground truth boxes: 9.916666666666666
Classifier accuracy for bounding boxes from RPN: 0.7395833333333334
Loss RPN classifier: 2.9642820344790968
Loss RPN regression: 0.1653389846194639
Loss Detector classifier: 0.5719743412401941
Loss Detector regression: 0.39934407898949253
Total loss: 4.100939439328247
Elapsed time: 16.306085348129272
Start of the validation phase

 1/25 [>.............................] - ETA: 6:33 - rpn_cls_val: 0.0263 - rpn_regr_val: 0.6505 - final_cls_val: 0.8321 - final_regr_val: 0.2532 - loss_val: 1.7621
 2/25 [=>............................] - ETA: 3:09 - rpn_cls_val: 0.0197 - rpn_regr_val: 0.5198 - final_cls_val: 0.6999 - final_regr_val: 0.2225 - loss_val: 1.4619
 3/25 [==>...........................] - ETA: 2:01 - rpn_cls_val: 0.3132 - rpn_regr_val: 0.4811 - final_cls_val: 0.6080 - final_regr_val: 0.2205 - loss_val: 1.6228
 4/25 [===>..........................] - ETA: 1:27 - rpn_cls_val: 0.8019 - rpn_regr_val: 0.4483 - final_cls_val: 0.5639 - final_regr_val: 0.2465 - loss_val: 2.0606
 5/25 [=====>........................] - ETA: 1:06 - rpn_cls_val: 1.0044 - rpn_regr_val: 0.4375 - final_cls_val: 0.5546 - final_regr_val: 0.2649 - loss_val: 2.2613
 6/25 [======>.......................] - ETA: 53s - rpn_cls_val: 1.0890 - rpn_regr_val: 0.4259 - final_cls_val: 0.5426 - final_regr_val: 0.2793 - loss_val: 2.3368 
 7/25 [=======>......................] - ETA: 43s - rpn_cls_val: 1.1186 - rpn_regr_val: 0.4158 - final_cls_val: 0.5286 - final_regr_val: 0.2893 - loss_val: 2.3523
 8/25 [========>.....................] - ETA: 36s - rpn_cls_val: 1.1205 - rpn_regr_val: 0.4083 - final_cls_val: 0.5139 - final_regr_val: 0.2946 - loss_val: 2.3373
 9/25 [=========>....................] - ETA: 30s - rpn_cls_val: 1.1080 - rpn_regr_val: 0.4067 - final_cls_val: 0.5000 - final_regr_val: 0.3000 - loss_val: 2.3147
10/25 [===========>..................] - ETA: 25s - rpn_cls_val: 1.0880 - rpn_regr_val: 0.4066 - final_cls_val: 0.4895 - final_regr_val: 0.3070 - loss_val: 2.2911
11/25 [============>.................] - ETA: 21s - rpn_cls_val: 1.0793 - rpn_regr_val: 0.4051 - final_cls_val: 0.4788 - final_regr_val: 0.3114 - loss_val: 2.2746
12/25 [=============>................] - ETA: 18s - rpn_cls_val: 1.1097 - rpn_regr_val: 0.4043 - final_cls_val: 0.4699 - final_regr_val: 0.3158 - loss_val: 2.2996
13/25 [==============>...............] - ETA: 16s - rpn_cls_val: 1.1557 - rpn_regr_val: 0.4024 - final_cls_val: 0.4623 - final_regr_val: 0.3186 - loss_val: 2.3390
14/25 [===============>..............] - ETA: 13s - rpn_cls_val: 1.1919 - rpn_regr_val: 0.3996 - final_cls_val: 0.4556 - final_regr_val: 0.3204 - loss_val: 2.3675
15/25 [=================>............] - ETA: 11s - rpn_cls_val: 1.2441 - rpn_regr_val: 0.3967 - final_cls_val: 0.4499 - final_regr_val: 0.3208 - loss_val: 2.4115
16/25 [==================>...........] - ETA: 9s - rpn_cls_val: 1.2915 - rpn_regr_val: 0.3941 - final_cls_val: 0.4453 - final_regr_val: 0.3209 - loss_val: 2.4518 
17/25 [===================>..........] - ETA: 8s - rpn_cls_val: 1.3263 - rpn_regr_val: 0.3912 - final_cls_val: 0.4421 - final_regr_val: 0.3212 - loss_val: 2.4808
18/25 [====================>.........] - ETA: 6s - rpn_cls_val: 1.3558 - rpn_regr_val: 0.3886 - final_cls_val: 0.4403 - final_regr_val: 0.3223 - loss_val: 2.5071
19/25 [=====================>........] - ETA: 5s - rpn_cls_val: 1.3872 - rpn_regr_val: 0.3861 - final_cls_val: 0.4397 - final_regr_val: 0.3233 - loss_val: 2.5362
20/25 [=======================>......] - ETA: 4s - rpn_cls_val: 1.4159 - rpn_regr_val: 0.3838 - final_cls_val: 0.4385 - final_regr_val: 0.3239 - loss_val: 2.5622
21/25 [========================>.....] - ETA: 3s - rpn_cls_val: 1.4377 - rpn_regr_val: 0.3813 - final_cls_val: 0.4371 - final_regr_val: 0.3250 - loss_val: 2.5811
22/25 [=========================>....] - ETA: 2s - rpn_cls_val: 1.4536 - rpn_regr_val: 0.3786 - final_cls_val: 0.4355 - final_regr_val: 0.3253 - loss_val: 2.5929
23/25 [==========================>...] - ETA: 1s - rpn_cls_val: 1.4710 - rpn_regr_val: 0.3762 - final_cls_val: 0.4342 - final_regr_val: 0.3256 - loss_val: 2.6071
24/25 [===========================>..] - ETA: 0s - rpn_cls_val: 1.4837 - rpn_regr_val: 0.3741 - final_cls_val: 0.4325 - final_regr_val: 0.3262 - loss_val: 2.6166
25/25 [==============================] - 18s 738ms/step - rpn_cls_val: 1.4957 - rpn_regr_val: 0.3725 - final_cls_val: 0.4311 - final_regr_val: 0.3263 - loss_val: 2.6257
End of the validation phase
Validation classifier accuracy for bounding boxes from RPN: 0.79
Validation loss RPN classifier: 1.7833985373520091
Validation loss RPN regression: 0.33412458837032316
Validation loss Detector classifier: 0.3975013267993927
Validation loss Detector regression: 0.3297248538583517
Total validation loss: 2.8447493063800766
Total validation loss decreased from 4.589064875383338 to 2.8447493063800766
=== Fold 2/4 ===
Loading weights from ./model/vgg16_weights_tf_dim_ordering_tf_kernels.h5
Epoch 1/2

 1/73 [..............................] - ETA: 4:03 - rpn_cls: 6.3526 - rpn_regr: 0.2565 - final_cls: 0.6931 - final_regr: 0.6540 - loss: 7.9563
 2/73 [..............................] - ETA: 2:11 - rpn_cls: 6.3787 - rpn_regr: 0.2252 - final_cls: 0.6941 - final_regr: 0.5755 - loss: 7.8735
 3/73 [>.............................] - ETA: 1:30 - rpn_cls: 6.1038 - rpn_regr: 0.1983 - final_cls: 0.6941 - final_regr: 0.5073 - loss: 7.5035
 4/73 [>.............................] - ETA: 1:10 - rpn_cls: 6.1869 - rpn_regr: 0.1970 - final_cls: 0.6940 - final_regr: 0.4976 - loss: 7.5754
 5/73 [=>............................] - ETA: 57s - rpn_cls: 6.2327 - rpn_regr: 0.1956 - final_cls: 0.6937 - final_regr: 0.5011 - loss: 7.6231 
 6/73 [=>............................] - ETA: 52s - rpn_cls: 6.2581 - rpn_regr: 0.1908 - final_cls: 0.6935 - final_regr: 0.4944 - loss: 7.6368
 7/73 [=>............................] - ETA: 46s - rpn_cls: 6.2980 - rpn_regr: 0.1845 - final_cls: 0.6933 - final_regr: 0.4943 - loss: 7.6701
 8/73 [==>...........................] - ETA: 41s - rpn_cls: 6.2906 - rpn_regr: 0.1827 - final_cls: 0.6933 - final_regr: 0.4940 - loss: 7.6607
 9/73 [==>...........................] - ETA: 37s - rpn_cls: 6.2315 - rpn_regr: 0.1812 - final_cls: 0.6934 - final_regr: 0.4959 - loss: 7.6020
10/73 [===>..........................] - ETA: 34s - rpn_cls: 6.1697 - rpn_regr: 0.1799 - final_cls: 0.6934 - final_regr: 0.4963 - loss: 7.5393
11/73 [===>..........................] - ETA: 32s - rpn_cls: 6.1058 - rpn_regr: 0.1779 - final_cls: 0.6934 - final_regr: 0.4958 - loss: 7.4729
12/73 [===>..........................] - ETA: 29s - rpn_cls: 6.0586 - rpn_regr: 0.1764 - final_cls: 0.6936 - final_regr: 0.4961 - loss: 7.4246
13/73 [====>.........................] - ETA: 27s - rpn_cls: 6.0303 - rpn_regr: 0.1754 - final_cls: 0.6936 - final_regr: 0.4952 - loss: 7.3945
14/73 [====>.........................] - ETA: 26s - rpn_cls: 6.0013 - rpn_regr: 0.1739 - final_cls: 0.6935 - final_regr: 0.4933 - loss: 7.3620
15/73 [=====>........................] - ETA: 24s - rpn_cls: 5.9793 - rpn_regr: 0.1727 - final_cls: 0.6935 - final_regr: 0.4944 - loss: 7.3399
16/73 [=====>........................] - ETA: 23s - rpn_cls: 5.9590 - rpn_regr: 0.1712 - final_cls: 0.6935 - final_regr: 0.4947 - loss: 7.3184
17/73 [=====>........................] - ETA: 22s - rpn_cls: 5.9387 - rpn_regr: 0.1709 - final_cls: 0.6934 - final_regr: 0.4947 - loss: 7.2978
18/73 [======>.......................] - ETA: 21s - rpn_cls: 5.9052 - rpn_regr: 0.1702 - final_cls: 0.6934 - final_regr: 0.4940 - loss: 7.26292021-03-03 22:15:47.126775: W tensorflow/core/common_runtime/bfc_allocator.cc:311] Garbage collection: deallocate free memory regions (i.e., allocations) so that we can re-allocate a larger region to avoid OOM due to memory fragmentation. If you see this message frequently, you are running near the threshold of the available device memory and re-allocation may incur great performance overhead. You may try smaller batch sizes to observe the performance impact. Set TF_ENABLE_GPU_GARBAGE_COLLECTION=false if you'd like to disable this feature.

19/73 [======>.......................] - ETA: 22s - rpn_cls: 5.8787 - rpn_regr: 0.1695 - final_cls: 0.6934 - final_regr: 0.4937 - loss: 7.2353
20/73 [=======>......................] - ETA: 22s - rpn_cls: 5.8623 - rpn_regr: 0.1686 - final_cls: 0.6934 - final_regr: 0.4933 - loss: 7.2176
21/73 [=======>......................] - ETA: 21s - rpn_cls: 5.8487 - rpn_regr: 0.1675 - final_cls: 0.6933 - final_regr: 0.4925 - loss: 7.2020
22/73 [========>.....................] - ETA: 20s - rpn_cls: 5.8388 - rpn_regr: 0.1664 - final_cls: 0.6933 - final_regr: 0.4915 - loss: 7.1900
23/73 [========>.....................] - ETA: 19s - rpn_cls: 5.8349 - rpn_regr: 0.1656 - final_cls: 0.6932 - final_regr: 0.4903 - loss: 7.1840
24/73 [========>.....................] - ETA: 18s - rpn_cls: 5.8364 - rpn_regr: 0.1651 - final_cls: 0.6932 - final_regr: 0.4892 - loss: 7.1839
25/73 [=========>....................] - ETA: 18s - rpn_cls: 5.8463 - rpn_regr: 0.1646 - final_cls: 0.6931 - final_regr: 0.4881 - loss: 7.1921
26/73 [=========>....................] - ETA: 17s - rpn_cls: 5.8507 - rpn_regr: 0.1639 - final_cls: 0.6931 - final_regr: 0.4870 - loss: 7.1947
27/73 [==========>...................] - ETA: 16s - rpn_cls: 5.8551 - rpn_regr: 0.1633 - final_cls: 0.6930 - final_regr: 0.4859 - loss: 7.1973
28/73 [==========>...................] - ETA: 16s - rpn_cls: 5.8607 - rpn_regr: 0.1627 - final_cls: 0.6929 - final_regr: 0.4850 - loss: 7.2014
29/73 [==========>...................] - ETA: 15s - rpn_cls: 5.8662 - rpn_regr: 0.1622 - final_cls: 0.6929 - final_regr: 0.4840 - loss: 7.2053
30/73 [===========>..................] - ETA: 14s - rpn_cls: 5.8733 - rpn_regr: 0.1617 - final_cls: 0.6928 - final_regr: 0.4826 - loss: 7.2105
31/73 [===========>..................] - ETA: 14s - rpn_cls: 5.8801 - rpn_regr: 0.1612 - final_cls: 0.6928 - final_regr: 0.4814 - loss: 7.2155
32/73 [============>.................] - ETA: 13s - rpn_cls: 5.8901 - rpn_regr: 0.1606 - final_cls: 0.6927 - final_regr: 0.4804 - loss: 7.2239
33/73 [============>.................] - ETA: 13s - rpn_cls: 5.8939 - rpn_regr: 0.1602 - final_cls: 0.6926 - final_regr: 0.4796 - loss: 7.2263
34/73 [============>.................] - ETA: 12s - rpn_cls: 5.8986 - rpn_regr: 0.1597 - final_cls: 0.6925 - final_regr: 0.4788 - loss: 7.2297
35/73 [=============>................] - ETA: 12s - rpn_cls: 5.9065 - rpn_regr: 0.1593 - final_cls: 0.6925 - final_regr: 0.4782 - loss: 7.2364
36/73 [=============>................] - ETA: 11s - rpn_cls: 5.9134 - rpn_regr: 0.1587 - final_cls: 0.6924 - final_regr: 0.4776 - loss: 7.2420
37/73 [==============>...............] - ETA: 11s - rpn_cls: 5.9204 - rpn_regr: 0.1581 - final_cls: 0.6924 - final_regr: 0.4774 - loss: 7.2483
38/73 [==============>...............] - ETA: 10s - rpn_cls: 5.9296 - rpn_regr: 0.1575 - final_cls: 0.6923 - final_regr: 0.4772 - loss: 7.2567
39/73 [===============>..............] - ETA: 10s - rpn_cls: 5.9366 - rpn_regr: 0.1570 - final_cls: 0.6923 - final_regr: 0.4772 - loss: 7.2631
40/73 [===============>..............] - ETA: 9s - rpn_cls: 5.9394 - rpn_regr: 0.1566 - final_cls: 0.6923 - final_regr: 0.4772 - loss: 7.2655 
41/73 [===============>..............] - ETA: 9s - rpn_cls: 5.9461 - rpn_regr: 0.1561 - final_cls: 0.6922 - final_regr: 0.4773 - loss: 7.2717
42/73 [================>.............] - ETA: 9s - rpn_cls: 5.9510 - rpn_regr: 0.1556 - final_cls: 0.6921 - final_regr: 0.4772 - loss: 7.2759
43/73 [================>.............] - ETA: 8s - rpn_cls: 5.9562 - rpn_regr: 0.1551 - final_cls: 0.6921 - final_regr: 0.4773 - loss: 7.2807
44/73 [=================>............] - ETA: 8s - rpn_cls: 5.9580 - rpn_regr: 0.1547 - final_cls: 0.6920 - final_regr: 0.4774 - loss: 7.2821
45/73 [=================>............] - ETA: 7s - rpn_cls: 5.9584 - rpn_regr: 0.1543 - final_cls: 0.6920 - final_regr: 0.4774 - loss: 7.2821
46/73 [=================>............] - ETA: 7s - rpn_cls: 5.9596 - rpn_regr: 0.1539 - final_cls: 0.6919 - final_regr: 0.4773 - loss: 7.2827
47/73 [==================>...........] - ETA: 7s - rpn_cls: 5.9597 - rpn_regr: 0.1534 - final_cls: 0.6919 - final_regr: 0.4772 - loss: 7.2822
48/73 [==================>...........] - ETA: 7s - rpn_cls: 5.9606 - rpn_regr: 0.1530 - final_cls: 0.6919 - final_regr: 0.4772 - loss: 7.2825
49/73 [===================>..........] - ETA: 6s - rpn_cls: 5.9610 - rpn_regr: 0.1525 - final_cls: 0.6918 - final_regr: 0.4771 - loss: 7.2824
50/73 [===================>..........] - ETA: 6s - rpn_cls: 5.9592 - rpn_regr: 0.1520 - final_cls: 0.6918 - final_regr: 0.4770 - loss: 7.2800
51/73 [===================>..........] - ETA: 6s - rpn_cls: 5.9553 - rpn_regr: 0.1516 - final_cls: 0.6917 - final_regr: 0.4769 - loss: 7.2755
52/73 [====================>.........] - ETA: 5s - rpn_cls: 5.9524 - rpn_regr: 0.1512 - final_cls: 0.6917 - final_regr: 0.4768 - loss: 7.2720
53/73 [====================>.........] - ETA: 5s - rpn_cls: 5.9474 - rpn_regr: 0.1508 - final_cls: 0.6917 - final_regr: 0.4768 - loss: 7.2666
54/73 [=====================>........] - ETA: 5s - rpn_cls: 5.9423 - rpn_regr: 0.1504 - final_cls: 0.6916 - final_regr: 0.4767 - loss: 7.2610
55/73 [=====================>........] - ETA: 4s - rpn_cls: 5.9372 - rpn_regr: 0.1500 - final_cls: 0.6916 - final_regr: 0.4766 - loss: 7.2553
56/73 [======================>.......] - ETA: 4s - rpn_cls: 5.9317 - rpn_regr: 0.1496 - final_cls: 0.6916 - final_regr: 0.4765 - loss: 7.2494
57/73 [======================>.......] - ETA: 4s - rpn_cls: 5.9264 - rpn_regr: 0.1493 - final_cls: 0.6915 - final_regr: 0.4764 - loss: 7.2437
58/73 [======================>.......] - ETA: 4s - rpn_cls: 5.9218 - rpn_regr: 0.1489 - final_cls: 0.6915 - final_regr: 0.4764 - loss: 7.2387
59/73 [=======================>......] - ETA: 3s - rpn_cls: 5.9162 - rpn_regr: 0.1486 - final_cls: 0.6915 - final_regr: 0.4763 - loss: 7.2326
60/73 [=======================>......] - ETA: 3s - rpn_cls: 5.9107 - rpn_regr: 0.1483 - final_cls: 0.6915 - final_regr: 0.4762 - loss: 7.2267
61/73 [========================>.....] - ETA: 3s - rpn_cls: 5.9052 - rpn_regr: 0.1480 - final_cls: 0.6914 - final_regr: 0.4760 - loss: 7.2206
62/73 [========================>.....] - ETA: 3s - rpn_cls: 5.9010 - rpn_regr: 0.1477 - final_cls: 0.6914 - final_regr: 0.4758 - loss: 7.2159
63/73 [========================>.....] - ETA: 2s - rpn_cls: 5.8983 - rpn_regr: 0.1474 - final_cls: 0.6913 - final_regr: 0.4756 - loss: 7.2126
64/73 [=========================>....] - ETA: 2s - rpn_cls: 5.8955 - rpn_regr: 0.1470 - final_cls: 0.6913 - final_regr: 0.4755 - loss: 7.2093
65/73 [=========================>....] - ETA: 2s - rpn_cls: 5.8917 - rpn_regr: 0.1467 - final_cls: 0.6912 - final_regr: 0.4754 - loss: 7.2051
66/73 [==========================>...] - ETA: 1s - rpn_cls: 5.8881 - rpn_regr: 0.1463 - final_cls: 0.6912 - final_regr: 0.4753 - loss: 7.2009
67/73 [==========================>...] - ETA: 1s - rpn_cls: 5.8839 - rpn_regr: 0.1460 - final_cls: 0.6912 - final_regr: 0.4752 - loss: 7.1962
68/73 [==========================>...] - ETA: 1s - rpn_cls: 5.8790 - rpn_regr: 0.1457 - final_cls: 0.6911 - final_regr: 0.4751 - loss: 7.1909
69/73 [===========================>..] - ETA: 1s - rpn_cls: 5.8745 - rpn_regr: 0.1454 - final_cls: 0.6911 - final_regr: 0.4749 - loss: 7.1860
70/73 [===========================>..] - ETA: 0s - rpn_cls: 5.8703 - rpn_regr: 0.1452 - final_cls: 0.6910 - final_regr: 0.4749 - loss: 7.1815
71/73 [============================>.] - ETA: 0s - rpn_cls: 5.8665 - rpn_regr: 0.1450 - final_cls: 0.6910 - final_regr: 0.4748 - loss: 7.1773
72/73 [============================>.] - ETA: 0s - rpn_cls: 5.8625 - rpn_regr: 0.1448 - final_cls: 0.6910 - final_regr: 0.4748 - loss: 7.1730
73/73 [==============================] - 20s 269ms/step - rpn_cls: 5.8580 - rpn_regr: 0.1446 - final_cls: 0.6909 - final_regr: 0.4749 - loss: 7.1684
Mean number of bounding boxes from RPN overlapping ground truth boxes: 7.465753424657534
Classifier accuracy for bounding boxes from RPN: 0.5308219178082192
Loss RPN classifier: 5.539065553499338
Loss RPN regression: 0.13000832477661028
Loss Detector classifier: 0.6876649815742284
Loss Detector regression: 0.48019355055812285
Total loss: 6.836932410408299
Elapsed time: 19.60703468322754
Start of the validation phase

 1/24 [>.............................] - ETA: 7:41 - rpn_cls_val: 7.6748 - rpn_regr_val: 0.1411 - final_cls_val: 0.6663 - final_regr_val: 0.4742 - loss_val: 8.9563
 2/24 [=>............................] - ETA: 3:41 - rpn_cls_val: 8.2771 - rpn_regr_val: 0.1128 - final_cls_val: 0.6590 - final_regr_val: 0.4316 - loss_val: 9.4806
 3/24 [==>...........................] - ETA: 2:21 - rpn_cls_val: 8.1925 - rpn_regr_val: 0.1452 - final_cls_val: 0.6490 - final_regr_val: 0.4158 - loss_val: 9.4025
 4/24 [====>.........................] - ETA: 1:41 - rpn_cls_val: 8.1297 - rpn_regr_val: 0.1691 - final_cls_val: 0.6437 - final_regr_val: 0.4312 - loss_val: 9.3737
 5/24 [=====>........................] - ETA: 1:17 - rpn_cls_val: 7.9080 - rpn_regr_val: 0.1791 - final_cls_val: 0.6405 - final_regr_val: 0.4391 - loss_val: 9.1667
 6/24 [======>.......................] - ETA: 1:01 - rpn_cls_val: 7.5652 - rpn_regr_val: 0.1811 - final_cls_val: 0.6380 - final_regr_val: 0.4498 - loss_val: 8.8341
 7/24 [=======>......................] - ETA: 49s - rpn_cls_val: 7.2009 - rpn_regr_val: 0.1809 - final_cls_val: 0.6360 - final_regr_val: 0.4666 - loss_val: 8.4845 
 8/24 [=========>....................] - ETA: 41s - rpn_cls_val: 6.8933 - rpn_regr_val: 0.1817 - final_cls_val: 0.6345 - final_regr_val: 0.4733 - loss_val: 8.1827
 9/24 [==========>...................] - ETA: 34s - rpn_cls_val: 6.6533 - rpn_regr_val: 0.1811 - final_cls_val: 0.6338 - final_regr_val: 0.4772 - loss_val: 7.9455
10/24 [===========>..................] - ETA: 29s - rpn_cls_val: 6.4666 - rpn_regr_val: 0.1817 - final_cls_val: 0.6338 - final_regr_val: 0.4804 - loss_val: 7.7626
11/24 [============>.................] - ETA: 25s - rpn_cls_val: 6.2780 - rpn_regr_val: 0.1809 - final_cls_val: 0.6337 - final_regr_val: 0.4802 - loss_val: 7.5729
12/24 [==============>...............] - ETA: 21s - rpn_cls_val: 6.1214 - rpn_regr_val: 0.1802 - final_cls_val: 0.6342 - final_regr_val: 0.4796 - loss_val: 7.4153
13/24 [===============>..............] - ETA: 18s - rpn_cls_val: 5.9726 - rpn_regr_val: 0.1787 - final_cls_val: 0.6347 - final_regr_val: 0.4779 - loss_val: 7.2638
14/24 [================>.............] - ETA: 15s - rpn_cls_val: 5.8572 - rpn_regr_val: 0.1775 - final_cls_val: 0.6350 - final_regr_val: 0.4759 - loss_val: 7.1455
15/24 [=================>............] - ETA: 12s - rpn_cls_val: 5.7649 - rpn_regr_val: 0.1764 - final_cls_val: 0.6355 - final_regr_val: 0.4755 - loss_val: 7.0523
16/24 [===================>..........] - ETA: 10s - rpn_cls_val: 5.6873 - rpn_regr_val: 0.1754 - final_cls_val: 0.6360 - final_regr_val: 0.4751 - loss_val: 6.9737
17/24 [====================>.........] - ETA: 8s - rpn_cls_val: 5.6230 - rpn_regr_val: 0.1747 - final_cls_val: 0.6364 - final_regr_val: 0.4751 - loss_val: 6.9092 
18/24 [=====================>........] - ETA: 7s - rpn_cls_val: 5.5520 - rpn_regr_val: 0.1744 - final_cls_val: 0.6369 - final_regr_val: 0.4748 - loss_val: 6.8381
19/24 [======================>.......] - ETA: 5s - rpn_cls_val: 5.4971 - rpn_regr_val: 0.1746 - final_cls_val: 0.6375 - final_regr_val: 0.4742 - loss_val: 6.7834
20/24 [========================>.....] - ETA: 4s - rpn_cls_val: 5.4528 - rpn_regr_val: 0.1753 - final_cls_val: 0.6381 - final_regr_val: 0.4735 - loss_val: 6.7398
21/24 [=========================>....] - ETA: 3s - rpn_cls_val: 5.4036 - rpn_regr_val: 0.1760 - final_cls_val: 0.6386 - final_regr_val: 0.4731 - loss_val: 6.6913
22/24 [==========================>...] - ETA: 2s - rpn_cls_val: 5.3509 - rpn_regr_val: 0.1766 - final_cls_val: 0.6392 - final_regr_val: 0.4725 - loss_val: 6.6391
23/24 [===========================>..] - ETA: 0s - rpn_cls_val: 5.3070 - rpn_regr_val: 0.1768 - final_cls_val: 0.6397 - final_regr_val: 0.4719 - loss_val: 6.5954
24/24 [==============================] - 22s 935ms/step - rpn_cls_val: 5.2595 - rpn_regr_val: 0.1770 - final_cls_val: 0.6401 - final_regr_val: 0.4717 - loss_val: 6.5484
End of the validation phase
Validation classifier accuracy for bounding boxes from RPN: 0.78125
Validation loss RPN classifier: 4.166556191879888
Validation loss RPN regression: 0.18213313965437314
Validation loss Detector classifier: 0.6508221576611201
Validation loss Detector regression: 0.46724662867685157
Total validation loss: 5.466758117872232
Total validation loss decreased from inf to 5.466758117872232
Epoch 2/2

 1/73 [..............................] - ETA: 12s - rpn_cls: 1.0370 - rpn_regr: 0.3299 - final_cls: 0.5965 - final_regr: 0.0000e+00 - loss: 1.9634
 2/73 [..............................] - ETA: 12s - rpn_cls: 2.2680 - rpn_regr: 0.2572 - final_cls: 0.6379 - final_regr: 0.1037 - loss: 3.2668    
 3/73 [>.............................] - ETA: 12s - rpn_cls: 2.4543 - rpn_regr: 0.2270 - final_cls: 0.6475 - final_regr: 0.1950 - loss: 3.5238
 4/73 [>.............................] - ETA: 12s - rpn_cls: 2.9073 - rpn_regr: 0.2168 - final_cls: 0.6547 - final_regr: 0.2618 - loss: 4.0407
 5/73 [=>............................] - ETA: 12s - rpn_cls: 3.2395 - rpn_regr: 0.2128 - final_cls: 0.6609 - final_regr: 0.3033 - loss: 4.4164
 6/73 [=>............................] - ETA: 11s - rpn_cls: 3.3891 - rpn_regr: 0.2106 - final_cls: 0.6629 - final_regr: 0.3320 - loss: 4.5946
 7/73 [=>............................] - ETA: 11s - rpn_cls: 3.4235 - rpn_regr: 0.2064 - final_cls: 0.6636 - final_regr: 0.3476 - loss: 4.6411
 8/73 [==>...........................] - ETA: 11s - rpn_cls: 3.4917 - rpn_regr: 0.2040 - final_cls: 0.6636 - final_regr: 0.3593 - loss: 4.7186
 9/73 [==>...........................] - ETA: 11s - rpn_cls: 3.5833 - rpn_regr: 0.2033 - final_cls: 0.6644 - final_regr: 0.3705 - loss: 4.8215
10/73 [===>..........................] - ETA: 11s - rpn_cls: 3.6283 - rpn_regr: 0.2024 - final_cls: 0.6644 - final_regr: 0.3793 - loss: 4.8744
11/73 [===>..........................] - ETA: 10s - rpn_cls: 3.6717 - rpn_regr: 0.2003 - final_cls: 0.6646 - final_regr: 0.3846 - loss: 4.9213
12/73 [===>..........................] - ETA: 10s - rpn_cls: 3.6855 - rpn_regr: 0.1984 - final_cls: 0.6646 - final_regr: 0.3889 - loss: 4.9374
13/73 [====>.........................] - ETA: 10s - rpn_cls: 3.6914 - rpn_regr: 0.1960 - final_cls: 0.6647 - final_regr: 0.3910 - loss: 4.9432
14/73 [====>.........................] - ETA: 10s - rpn_cls: 3.6919 - rpn_regr: 0.1934 - final_cls: 0.6646 - final_regr: 0.3922 - loss: 4.9420
15/73 [=====>........................] - ETA: 10s - rpn_cls: 3.7159 - rpn_regr: 0.1907 - final_cls: 0.6647 - final_regr: 0.3935 - loss: 4.9648
16/73 [=====>........................] - ETA: 10s - rpn_cls: 3.7211 - rpn_regr: 0.1880 - final_cls: 0.6649 - final_regr: 0.3942 - loss: 4.9681
17/73 [=====>........................] - ETA: 10s - rpn_cls: 3.7128 - rpn_regr: 0.1866 - final_cls: 0.6648 - final_regr: 0.3955 - loss: 4.9596
18/73 [======>.......................] - ETA: 9s - rpn_cls: 3.7130 - rpn_regr: 0.1851 - final_cls: 0.6649 - final_regr: 0.3969 - loss: 4.9599 
19/73 [======>.......................] - ETA: 9s - rpn_cls: 3.7143 - rpn_regr: 0.1835 - final_cls: 0.6650 - final_regr: 0.3980 - loss: 4.9608
20/73 [=======>......................] - ETA: 11s - rpn_cls: 3.7106 - rpn_regr: 0.1818 - final_cls: 0.6650 - final_regr: 0.3986 - loss: 4.9560
21/73 [=======>......................] - ETA: 11s - rpn_cls: 3.7074 - rpn_regr: 0.1800 - final_cls: 0.6651 - final_regr: 0.3992 - loss: 4.9517
22/73 [========>.....................] - ETA: 11s - rpn_cls: 3.6971 - rpn_regr: 0.1785 - final_cls: 0.6651 - final_regr: 0.3997 - loss: 4.9403
23/73 [========>.....................] - ETA: 10s - rpn_cls: 3.6875 - rpn_regr: 0.1773 - final_cls: 0.6651 - final_regr: 0.4002 - loss: 4.9301
24/73 [========>.....................] - ETA: 10s - rpn_cls: 3.6737 - rpn_regr: 0.1762 - final_cls: 0.6652 - final_regr: 0.4008 - loss: 4.9160
25/73 [=========>....................] - ETA: 10s - rpn_cls: 3.6612 - rpn_regr: 0.1753 - final_cls: 0.6653 - final_regr: 0.4012 - loss: 4.9030
26/73 [=========>....................] - ETA: 9s - rpn_cls: 3.6456 - rpn_regr: 0.1743 - final_cls: 0.6653 - final_regr: 0.4013 - loss: 4.8864 
27/73 [==========>...................] - ETA: 9s - rpn_cls: 3.6360 - rpn_regr: 0.1733 - final_cls: 0.6651 - final_regr: 0.4012 - loss: 4.8757
28/73 [==========>...................] - ETA: 9s - rpn_cls: 3.6303 - rpn_regr: 0.1723 - final_cls: 0.6649 - final_regr: 0.4011 - loss: 4.8686
29/73 [==========>...................] - ETA: 9s - rpn_cls: 3.6209 - rpn_regr: 0.1720 - final_cls: 0.6645 - final_regr: 0.4011 - loss: 4.8586
30/73 [===========>..................] - ETA: 8s - rpn_cls: 3.6085 - rpn_regr: 0.1717 - final_cls: 0.6642 - final_regr: 0.4012 - loss: 4.8456
31/73 [===========>..................] - ETA: 8s - rpn_cls: 3.5936 - rpn_regr: 0.1714 - final_cls: 0.6640 - final_regr: 0.4012 - loss: 4.8302
32/73 [============>.................] - ETA: 8s - rpn_cls: 3.5808 - rpn_regr: 0.1710 - final_cls: 0.6637 - final_regr: 0.4013 - loss: 4.8168
33/73 [============>.................] - ETA: 8s - rpn_cls: 3.5658 - rpn_regr: 0.1707 - final_cls: 0.6634 - final_regr: 0.4013 - loss: 4.8012
34/73 [============>.................] - ETA: 7s - rpn_cls: 3.5511 - rpn_regr: 0.1703 - final_cls: 0.6631 - final_regr: 0.4016 - loss: 4.7861
35/73 [=============>................] - ETA: 8s - rpn_cls: 3.5379 - rpn_regr: 0.1700 - final_cls: 0.6625 - final_regr: 0.4017 - loss: 4.7722
36/73 [=============>................] - ETA: 7s - rpn_cls: 3.5242 - rpn_regr: 0.1696 - final_cls: 0.6619 - final_regr: 0.4019 - loss: 4.7576
37/73 [==============>...............] - ETA: 7s - rpn_cls: 3.5090 - rpn_regr: 0.1692 - final_cls: 0.6614 - final_regr: 0.4019 - loss: 4.7416
38/73 [==============>...............] - ETA: 7s - rpn_cls: 3.4940 - rpn_regr: 0.1688 - final_cls: 0.6607 - final_regr: 0.4019 - loss: 4.7254
39/73 [===============>..............] - ETA: 7s - rpn_cls: 3.4778 - rpn_regr: 0.1684 - final_cls: 0.6603 - final_regr: 0.4019 - loss: 4.7083
40/73 [===============>..............] - ETA: 6s - rpn_cls: 3.4606 - rpn_regr: 0.1681 - final_cls: 0.6596 - final_regr: 0.4020 - loss: 4.6903
41/73 [===============>..............] - ETA: 6s - rpn_cls: 3.4464 - rpn_regr: 0.1679 - final_cls: 0.6589 - final_regr: 0.4021 - loss: 4.6753
42/73 [================>.............] - ETA: 6s - rpn_cls: 3.4313 - rpn_regr: 0.1678 - final_cls: 0.6580 - final_regr: 0.4021 - loss: 4.6592
43/73 [================>.............] - ETA: 6s - rpn_cls: 3.4159 - rpn_regr: 0.1677 - final_cls: 0.6572 - final_regr: 0.4022 - loss: 4.6430
44/73 [=================>............] - ETA: 5s - rpn_cls: 3.3998 - rpn_regr: 0.1677 - final_cls: 0.6562 - final_regr: 0.4022 - loss: 4.6260
45/73 [=================>............] - ETA: 5s - rpn_cls: 3.3849 - rpn_regr: 0.1678 - final_cls: 0.6553 - final_regr: 0.4023 - loss: 4.6102
46/73 [=================>............] - ETA: 5s - rpn_cls: 3.3702 - rpn_regr: 0.1678 - final_cls: 0.6542 - final_regr: 0.4022 - loss: 4.5944
47/73 [==================>...........] - ETA: 5s - rpn_cls: 3.3577 - rpn_regr: 0.1677 - final_cls: 0.6531 - final_regr: 0.4021 - loss: 4.5807
48/73 [==================>...........] - ETA: 5s - rpn_cls: 3.3462 - rpn_regr: 0.1676 - final_cls: 0.6521 - final_regr: 0.4019 - loss: 4.5679
49/73 [===================>..........] - ETA: 4s - rpn_cls: 3.3361 - rpn_regr: 0.1676 - final_cls: 0.6510 - final_regr: 0.4019 - loss: 4.5565
50/73 [===================>..........] - ETA: 4s - rpn_cls: 3.3291 - rpn_regr: 0.1678 - final_cls: 0.6504 - final_regr: 0.4021 - loss: 4.5493
51/73 [===================>..........] - ETA: 4s - rpn_cls: 3.3212 - rpn_regr: 0.1680 - final_cls: 0.6498 - final_regr: 0.4024 - loss: 4.5413
52/73 [====================>.........] - ETA: 4s - rpn_cls: 3.3132 - rpn_regr: 0.1681 - final_cls: 0.6491 - final_regr: 0.4026 - loss: 4.5330
53/73 [====================>.........] - ETA: 3s - rpn_cls: 3.3069 - rpn_regr: 0.1682 - final_cls: 0.6483 - final_regr: 0.4026 - loss: 4.5261
54/73 [=====================>........] - ETA: 3s - rpn_cls: 3.3011 - rpn_regr: 0.1683 - final_cls: 0.6475 - final_regr: 0.4027 - loss: 4.5197
55/73 [=====================>........] - ETA: 3s - rpn_cls: 3.2953 - rpn_regr: 0.1684 - final_cls: 0.6467 - final_regr: 0.4026 - loss: 4.5131
56/73 [======================>.......] - ETA: 3s - rpn_cls: 3.2921 - rpn_regr: 0.1686 - final_cls: 0.6461 - final_regr: 0.4025 - loss: 4.5093
57/73 [======================>.......] - ETA: 3s - rpn_cls: 3.2881 - rpn_regr: 0.1688 - final_cls: 0.6455 - final_regr: 0.4024 - loss: 4.5048
58/73 [======================>.......] - ETA: 2s - rpn_cls: 3.2843 - rpn_regr: 0.1690 - final_cls: 0.6449 - final_regr: 0.4024 - loss: 4.5005
59/73 [=======================>......] - ETA: 2s - rpn_cls: 3.2799 - rpn_regr: 0.1691 - final_cls: 0.6442 - final_regr: 0.4023 - loss: 4.4956
60/73 [=======================>......] - ETA: 2s - rpn_cls: 3.2752 - rpn_regr: 0.1693 - final_cls: 0.6436 - final_regr: 0.4022 - loss: 4.4902
61/73 [========================>.....] - ETA: 2s - rpn_cls: 3.2708 - rpn_regr: 0.1693 - final_cls: 0.6430 - final_regr: 0.4021 - loss: 4.4853
62/73 [========================>.....] - ETA: 2s - rpn_cls: 3.2667 - rpn_regr: 0.1694 - final_cls: 0.6425 - final_regr: 0.4021 - loss: 4.4807
63/73 [========================>.....] - ETA: 1s - rpn_cls: 3.2619 - rpn_regr: 0.1694 - final_cls: 0.6419 - final_regr: 0.4022 - loss: 4.4755
64/73 [=========================>....] - ETA: 1s - rpn_cls: 3.2574 - rpn_regr: 0.1694 - final_cls: 0.6414 - final_regr: 0.4022 - loss: 4.4705
65/73 [=========================>....] - ETA: 1s - rpn_cls: 3.2524 - rpn_regr: 0.1694 - final_cls: 0.6409 - final_regr: 0.4022 - loss: 4.4649
66/73 [==========================>...] - ETA: 1s - rpn_cls: 3.2474 - rpn_regr: 0.1694 - final_cls: 0.6403 - final_regr: 0.4022 - loss: 4.4594
67/73 [==========================>...] - ETA: 1s - rpn_cls: 3.2419 - rpn_regr: 0.1694 - final_cls: 0.6397 - final_regr: 0.4022 - loss: 4.4532
68/73 [==========================>...] - ETA: 0s - rpn_cls: 3.2361 - rpn_regr: 0.1694 - final_cls: 0.6391 - final_regr: 0.4022 - loss: 4.4468
69/73 [===========================>..] - ETA: 0s - rpn_cls: 3.2311 - rpn_regr: 0.1693 - final_cls: 0.6386 - final_regr: 0.4021 - loss: 4.4412
70/73 [===========================>..] - ETA: 0s - rpn_cls: 3.2285 - rpn_regr: 0.1693 - final_cls: 0.6381 - final_regr: 0.4020 - loss: 4.4378
71/73 [============================>.] - ETA: 0s - rpn_cls: 3.2254 - rpn_regr: 0.1693 - final_cls: 0.6375 - final_regr: 0.4019 - loss: 4.4341
72/73 [============================>.] - ETA: 0s - rpn_cls: 3.2219 - rpn_regr: 0.1692 - final_cls: 0.6371 - final_regr: 0.4018 - loss: 4.4300
73/73 [==============================] - 14s 193ms/step - rpn_cls: 3.2184 - rpn_regr: 0.1692 - final_cls: 0.6367 - final_regr: 0.4017 - loss: 4.4260
Mean number of bounding boxes from RPN overlapping ground truth boxes: 8.602739726027398
Classifier accuracy for bounding boxes from RPN: 0.7294520547945206
Loss RPN classifier: 2.9668703937362633
Loss RPN regression: 0.16664025098187465
Loss Detector classifier: 0.6038418116226588
Loss Detector regression: 0.39643273553619646
Total loss: 4.133785191876993
Elapsed time: 14.112491846084595
Start of the validation phase

 1/24 [>.............................] - ETA: 5:26 - rpn_cls_val: 6.6749 - rpn_regr_val: 0.0916 - final_cls_val: 0.4957 - final_regr_val: 0.4288 - loss_val: 7.6910
 2/24 [=>............................] - ETA: 2:37 - rpn_cls_val: 5.0062 - rpn_regr_val: 0.0718 - final_cls_val: 0.5049 - final_regr_val: 0.3852 - loss_val: 5.9682
 3/24 [==>...........................] - ETA: 1:40 - rpn_cls_val: 4.7839 - rpn_regr_val: 0.0950 - final_cls_val: 0.5186 - final_regr_val: 0.3620 - loss_val: 5.7595
 4/24 [====>.........................] - ETA: 1:12 - rpn_cls_val: 4.8151 - rpn_regr_val: 0.1233 - final_cls_val: 0.5231 - final_regr_val: 0.3633 - loss_val: 5.8248
 5/24 [=====>........................] - ETA: 55s - rpn_cls_val: 4.6375 - rpn_regr_val: 0.1359 - final_cls_val: 0.5247 - final_regr_val: 0.3559 - loss_val: 5.6539 
 6/24 [======>.......................] - ETA: 43s - rpn_cls_val: 4.5496 - rpn_regr_val: 0.1398 - final_cls_val: 0.5293 - final_regr_val: 0.3505 - loss_val: 5.5692
 7/24 [=======>......................] - ETA: 35s - rpn_cls_val: 4.5360 - rpn_regr_val: 0.1416 - final_cls_val: 0.5343 - final_regr_val: 0.3492 - loss_val: 5.5611
 8/24 [=========>....................] - ETA: 30s - rpn_cls_val: 4.4664 - rpn_regr_val: 0.1446 - final_cls_val: 0.5361 - final_regr_val: 0.3481 - loss_val: 5.4951
 9/24 [==========>...................] - ETA: 25s - rpn_cls_val: 4.3872 - rpn_regr_val: 0.1459 - final_cls_val: 0.5381 - final_regr_val: 0.3466 - loss_val: 5.4179
10/24 [===========>..................] - ETA: 21s - rpn_cls_val: 4.3056 - rpn_regr_val: 0.1496 - final_cls_val: 0.5427 - final_regr_val: 0.3429 - loss_val: 5.3408
11/24 [============>.................] - ETA: 18s - rpn_cls_val: 4.2282 - rpn_regr_val: 0.1516 - final_cls_val: 0.5462 - final_regr_val: 0.3418 - loss_val: 5.2678
12/24 [==============>...............] - ETA: 15s - rpn_cls_val: 4.1630 - rpn_regr_val: 0.1531 - final_cls_val: 0.5487 - final_regr_val: 0.3399 - loss_val: 5.2047
13/24 [===============>..............] - ETA: 13s - rpn_cls_val: 4.0879 - rpn_regr_val: 0.1536 - final_cls_val: 0.5510 - final_regr_val: 0.3399 - loss_val: 5.1324
14/24 [================>.............] - ETA: 11s - rpn_cls_val: 4.0073 - rpn_regr_val: 0.1541 - final_cls_val: 0.5529 - final_regr_val: 0.3406 - loss_val: 5.0548
15/24 [=================>............] - ETA: 9s - rpn_cls_val: 3.9530 - rpn_regr_val: 0.1544 - final_cls_val: 0.5542 - final_regr_val: 0.3398 - loss_val: 5.0015 
16/24 [===================>..........] - ETA: 7s - rpn_cls_val: 3.9079 - rpn_regr_val: 0.1548 - final_cls_val: 0.5559 - final_regr_val: 0.3398 - loss_val: 4.9584
17/24 [====================>.........] - ETA: 6s - rpn_cls_val: 3.8621 - rpn_regr_val: 0.1558 - final_cls_val: 0.5575 - final_regr_val: 0.3412 - loss_val: 4.9166
18/24 [=====================>........] - ETA: 5s - rpn_cls_val: 3.8458 - rpn_regr_val: 0.1569 - final_cls_val: 0.5589 - final_regr_val: 0.3425 - loss_val: 4.9042
19/24 [======================>.......] - ETA: 4s - rpn_cls_val: 3.8281 - rpn_regr_val: 0.1585 - final_cls_val: 0.5611 - final_regr_val: 0.3447 - loss_val: 4.8924
20/24 [========================>.....] - ETA: 3s - rpn_cls_val: 3.8033 - rpn_regr_val: 0.1606 - final_cls_val: 0.5630 - final_regr_val: 0.3472 - loss_val: 4.8741
21/24 [=========================>....] - ETA: 2s - rpn_cls_val: 3.7734 - rpn_regr_val: 0.1623 - final_cls_val: 0.5645 - final_regr_val: 0.3496 - loss_val: 4.8498
22/24 [==========================>...] - ETA: 1s - rpn_cls_val: 3.7396 - rpn_regr_val: 0.1637 - final_cls_val: 0.5661 - final_regr_val: 0.3517 - loss_val: 4.8211
23/24 [===========================>..] - ETA: 0s - rpn_cls_val: 3.7030 - rpn_regr_val: 0.1648 - final_cls_val: 0.5674 - final_regr_val: 0.3538 - loss_val: 4.7890
24/24 [==============================] - 16s 685ms/step - rpn_cls_val: 3.6768 - rpn_regr_val: 0.1655 - final_cls_val: 0.5686 - final_regr_val: 0.3553 - loss_val: 4.7662
End of the validation phase
Validation classifier accuracy for bounding boxes from RPN: 0.71875
Validation loss RPN classifier: 3.0730772883916173
Validation loss RPN regression: 0.18294354058646908
Validation loss Detector classifier: 0.5957866248985132
Validation loss Detector regression: 0.3901502639055252
Total validation loss: 4.241957717782125
Total validation loss decreased from 5.466758117872232 to 4.241957717782125
=== Fold 3/4 ===
Loading weights from ./model/vgg16_weights_tf_dim_ordering_tf_kernels.h5
Epoch 1/2

 1/73 [..............................] - ETA: 4:04 - rpn_cls: 6.2288 - rpn_regr: 0.2452 - final_cls: 0.6931 - final_regr: 0.8105 - loss: 7.9777
 2/73 [..............................] - ETA: 2:06 - rpn_cls: 7.6961 - rpn_regr: 0.2176 - final_cls: 0.6928 - final_regr: 0.7961 - loss: 9.4025
 3/73 [>.............................] - ETA: 1:27 - rpn_cls: 7.7075 - rpn_regr: 0.1926 - final_cls: 0.6927 - final_regr: 0.7425 - loss: 9.3352
 4/73 [>.............................] - ETA: 1:07 - rpn_cls: 7.9863 - rpn_regr: 0.1894 - final_cls: 0.6928 - final_regr: 0.7283 - loss: 9.5968
 5/73 [=>............................] - ETA: 55s - rpn_cls: 8.0648 - rpn_regr: 0.1874 - final_cls: 0.6930 - final_regr: 0.7125 - loss: 9.6577 
 6/73 [=>............................] - ETA: 47s - rpn_cls: 7.9789 - rpn_regr: 0.1827 - final_cls: 0.6931 - final_regr: 0.6985 - loss: 9.5533
 7/73 [=>............................] - ETA: 42s - rpn_cls: 7.8787 - rpn_regr: 0.1767 - final_cls: 0.6933 - final_regr: 0.6859 - loss: 9.4345
 8/73 [==>...........................] - ETA: 37s - rpn_cls: 7.8891 - rpn_regr: 0.1752 - final_cls: 0.6936 - final_regr: 0.6731 - loss: 9.4310
 9/73 [==>...........................] - ETA: 34s - rpn_cls: 7.8952 - rpn_regr: 0.1739 - final_cls: 0.6940 - final_regr: 0.6610 - loss: 9.4241
10/73 [===>..........................] - ETA: 31s - rpn_cls: 7.8907 - rpn_regr: 0.1723 - final_cls: 0.6944 - final_regr: 0.6513 - loss: 9.4087
11/73 [===>..........................] - ETA: 30s - rpn_cls: 7.8640 - rpn_regr: 0.1703 - final_cls: 0.6948 - final_regr: 0.6441 - loss: 9.3731
12/73 [===>..........................] - ETA: 27s - rpn_cls: 7.8339 - rpn_regr: 0.1689 - final_cls: 0.6949 - final_regr: 0.6342 - loss: 9.3320
13/73 [====>.........................] - ETA: 26s - rpn_cls: 7.7922 - rpn_regr: 0.1681 - final_cls: 0.6950 - final_regr: 0.6250 - loss: 9.2803
14/73 [====>.........................] - ETA: 24s - rpn_cls: 7.7505 - rpn_regr: 0.1668 - final_cls: 0.6951 - final_regr: 0.6177 - loss: 9.2300
15/73 [=====>........................] - ETA: 23s - rpn_cls: 7.7103 - rpn_regr: 0.1658 - final_cls: 0.6953 - final_regr: 0.6129 - loss: 9.1843
16/73 [=====>........................] - ETA: 22s - rpn_cls: 7.6583 - rpn_regr: 0.1646 - final_cls: 0.6954 - final_regr: 0.6078 - loss: 9.1262
17/73 [=====>........................] - ETA: 21s - rpn_cls: 7.6003 - rpn_regr: 0.1646 - final_cls: 0.6955 - final_regr: 0.6031 - loss: 9.0636
18/73 [======>.......................] - ETA: 20s - rpn_cls: 7.5476 - rpn_regr: 0.1642 - final_cls: 0.6956 - final_regr: 0.5995 - loss: 9.0069
19/73 [======>.......................] - ETA: 19s - rpn_cls: 7.4991 - rpn_regr: 0.1639 - final_cls: 0.6956 - final_regr: 0.5962 - loss: 8.9548
20/73 [=======>......................] - ETA: 18s - rpn_cls: 7.4604 - rpn_regr: 0.1632 - final_cls: 0.6956 - final_regr: 0.5936 - loss: 8.9128
21/73 [=======>......................] - ETA: 18s - rpn_cls: 7.4386 - rpn_regr: 0.1626 - final_cls: 0.6956 - final_regr: 0.5917 - loss: 8.8885
22/73 [========>.....................] - ETA: 17s - rpn_cls: 7.4049 - rpn_regr: 0.1620 - final_cls: 0.6955 - final_regr: 0.5906 - loss: 8.8531
23/73 [========>.....................] - ETA: 16s - rpn_cls: 7.3762 - rpn_regr: 0.1616 - final_cls: 0.6955 - final_regr: 0.5894 - loss: 8.8226
24/73 [========>.....................] - ETA: 15s - rpn_cls: 7.3493 - rpn_regr: 0.1614 - final_cls: 0.6954 - final_regr: 0.5882 - loss: 8.7943
25/73 [=========>....................] - ETA: 15s - rpn_cls: 7.3218 - rpn_regr: 0.1612 - final_cls: 0.6954 - final_regr: 0.5873 - loss: 8.7656
26/73 [=========>....................] - ETA: 14s - rpn_cls: 7.2960 - rpn_regr: 0.1609 - final_cls: 0.6953 - final_regr: 0.5866 - loss: 8.7388
27/73 [==========>...................] - ETA: 14s - rpn_cls: 7.2643 - rpn_regr: 0.1607 - final_cls: 0.6952 - final_regr: 0.5857 - loss: 8.7058
28/73 [==========>...................] - ETA: 13s - rpn_cls: 7.2373 - rpn_regr: 0.1608 - final_cls: 0.6951 - final_regr: 0.5846 - loss: 8.6778
29/73 [==========>...................] - ETA: 13s - rpn_cls: 7.2125 - rpn_regr: 0.1612 - final_cls: 0.6951 - final_regr: 0.5836 - loss: 8.6524
30/73 [===========>..................] - ETA: 12s - rpn_cls: 7.1867 - rpn_regr: 0.1615 - final_cls: 0.6950 - final_regr: 0.5826 - loss: 8.6258
31/73 [===========>..................] - ETA: 12s - rpn_cls: 7.1598 - rpn_regr: 0.1617 - final_cls: 0.6950 - final_regr: 0.5815 - loss: 8.5980
32/73 [============>.................] - ETA: 11s - rpn_cls: 7.1376 - rpn_regr: 0.1621 - final_cls: 0.6949 - final_regr: 0.5800 - loss: 8.5746
33/73 [============>.................] - ETA: 11s - rpn_cls: 7.1181 - rpn_regr: 0.1623 - final_cls: 0.6948 - final_regr: 0.5785 - loss: 8.5537
34/73 [============>.................] - ETA: 11s - rpn_cls: 7.0992 - rpn_regr: 0.1626 - final_cls: 0.6947 - final_regr: 0.5772 - loss: 8.5338
35/73 [=============>................] - ETA: 10s - rpn_cls: 7.0801 - rpn_regr: 0.1628 - final_cls: 0.6947 - final_regr: 0.5759 - loss: 8.5134
36/73 [=============>................] - ETA: 10s - rpn_cls: 7.0571 - rpn_regr: 0.1632 - final_cls: 0.6946 - final_regr: 0.5747 - loss: 8.4895
37/73 [==============>...............] - ETA: 9s - rpn_cls: 7.0335 - rpn_regr: 0.1634 - final_cls: 0.6945 - final_regr: 0.5735 - loss: 8.4649 
38/73 [==============>...............] - ETA: 9s - rpn_cls: 7.0104 - rpn_regr: 0.1636 - final_cls: 0.6944 - final_regr: 0.5722 - loss: 8.4406
39/73 [===============>..............] - ETA: 9s - rpn_cls: 6.9843 - rpn_regr: 0.1637 - final_cls: 0.6943 - final_regr: 0.5710 - loss: 8.4134
40/73 [===============>..............] - ETA: 8s - rpn_cls: 6.9564 - rpn_regr: 0.1638 - final_cls: 0.6943 - final_regr: 0.5698 - loss: 8.3843
41/73 [===============>..............] - ETA: 8s - rpn_cls: 6.9319 - rpn_regr: 0.1639 - final_cls: 0.6942 - final_regr: 0.5687 - loss: 8.3586
42/73 [================>.............] - ETA: 8s - rpn_cls: 6.9091 - rpn_regr: 0.1639 - final_cls: 0.6941 - final_regr: 0.5675 - loss: 8.3347
43/73 [================>.............] - ETA: 7s - rpn_cls: 6.8886 - rpn_regr: 0.1640 - final_cls: 0.6940 - final_regr: 0.5662 - loss: 8.3127
44/73 [=================>............] - ETA: 7s - rpn_cls: 6.8677 - rpn_regr: 0.1640 - final_cls: 0.6939 - final_regr: 0.5647 - loss: 8.2903
45/73 [=================>............] - ETA: 7s - rpn_cls: 6.8451 - rpn_regr: 0.1641 - final_cls: 0.6938 - final_regr: 0.5634 - loss: 8.2664
46/73 [=================>............] - ETA: 6s - rpn_cls: 6.8231 - rpn_regr: 0.1642 - final_cls: 0.6938 - final_regr: 0.5622 - loss: 8.2432
47/73 [==================>...........] - ETA: 6s - rpn_cls: 6.7994 - rpn_regr: 0.1644 - final_cls: 0.6937 - final_regr: 0.5610 - loss: 8.2185
48/73 [==================>...........] - ETA: 6s - rpn_cls: 6.7764 - rpn_regr: 0.1645 - final_cls: 0.6936 - final_regr: 0.5599 - loss: 8.1944
49/73 [===================>..........] - ETA: 6s - rpn_cls: 6.7554 - rpn_regr: 0.1646 - final_cls: 0.6935 - final_regr: 0.5591 - loss: 8.1726
50/73 [===================>..........] - ETA: 5s - rpn_cls: 6.7355 - rpn_regr: 0.1647 - final_cls: 0.6934 - final_regr: 0.5583 - loss: 8.1520
51/73 [===================>..........] - ETA: 5s - rpn_cls: 6.7144 - rpn_regr: 0.1648 - final_cls: 0.6934 - final_regr: 0.5575 - loss: 8.1300
52/73 [====================>.........] - ETA: 5s - rpn_cls: 6.6931 - rpn_regr: 0.1648 - final_cls: 0.6933 - final_regr: 0.5566 - loss: 8.1078
53/73 [====================>.........] - ETA: 4s - rpn_cls: 6.6716 - rpn_regr: 0.1649 - final_cls: 0.6932 - final_regr: 0.5557 - loss: 8.0854
54/73 [=====================>........] - ETA: 4s - rpn_cls: 6.6511 - rpn_regr: 0.1650 - final_cls: 0.6931 - final_regr: 0.5547 - loss: 8.0639
55/73 [=====================>........] - ETA: 4s - rpn_cls: 6.6312 - rpn_regr: 0.1650 - final_cls: 0.6931 - final_regr: 0.5538 - loss: 8.0431
56/73 [======================>.......] - ETA: 4s - rpn_cls: 6.6136 - rpn_regr: 0.1650 - final_cls: 0.6930 - final_regr: 0.5529 - loss: 8.0245
57/73 [======================>.......] - ETA: 3s - rpn_cls: 6.5968 - rpn_regr: 0.1650 - final_cls: 0.6929 - final_regr: 0.5521 - loss: 8.0068
58/73 [======================>.......] - ETA: 3s - rpn_cls: 6.5805 - rpn_regr: 0.1650 - final_cls: 0.6929 - final_regr: 0.5512 - loss: 7.9895
59/73 [=======================>......] - ETA: 3s - rpn_cls: 6.5631 - rpn_regr: 0.1650 - final_cls: 0.6928 - final_regr: 0.5503 - loss: 7.9712
60/73 [=======================>......] - ETA: 3s - rpn_cls: 6.5452 - rpn_regr: 0.1649 - final_cls: 0.6927 - final_regr: 0.5494 - loss: 7.9523
61/73 [========================>.....] - ETA: 2s - rpn_cls: 6.5274 - rpn_regr: 0.1649 - final_cls: 0.6927 - final_regr: 0.5485 - loss: 7.9335
62/73 [========================>.....] - ETA: 2s - rpn_cls: 6.5101 - rpn_regr: 0.1648 - final_cls: 0.6926 - final_regr: 0.5476 - loss: 7.9151
63/73 [========================>.....] - ETA: 2s - rpn_cls: 6.4935 - rpn_regr: 0.1647 - final_cls: 0.6925 - final_regr: 0.5467 - loss: 7.8975
64/73 [=========================>....] - ETA: 2s - rpn_cls: 6.4776 - rpn_regr: 0.1646 - final_cls: 0.6925 - final_regr: 0.5458 - loss: 7.8804
65/73 [=========================>....] - ETA: 1s - rpn_cls: 6.4612 - rpn_regr: 0.1645 - final_cls: 0.6924 - final_regr: 0.5449 - loss: 7.8630
66/73 [==========================>...] - ETA: 1s - rpn_cls: 6.4446 - rpn_regr: 0.1644 - final_cls: 0.6923 - final_regr: 0.5440 - loss: 7.8452
67/73 [==========================>...] - ETA: 1s - rpn_cls: 6.4272 - rpn_regr: 0.1642 - final_cls: 0.6923 - final_regr: 0.5431 - loss: 7.8267
68/73 [==========================>...] - ETA: 1s - rpn_cls: 6.4094 - rpn_regr: 0.1641 - final_cls: 0.6922 - final_regr: 0.5422 - loss: 7.8079
69/73 [===========================>..] - ETA: 0s - rpn_cls: 6.3925 - rpn_regr: 0.1640 - final_cls: 0.6921 - final_regr: 0.5413 - loss: 7.7899
70/73 [===========================>..] - ETA: 0s - rpn_cls: 6.3764 - rpn_regr: 0.1638 - final_cls: 0.6920 - final_regr: 0.5404 - loss: 7.7726
71/73 [============================>.] - ETA: 0s - rpn_cls: 6.3605 - rpn_regr: 0.1637 - final_cls: 0.6919 - final_regr: 0.5396 - loss: 7.7557
72/73 [============================>.] - ETA: 0s - rpn_cls: 6.3444 - rpn_regr: 0.1636 - final_cls: 0.6919 - final_regr: 0.5388 - loss: 7.7387
73/73 [==============================] - 17s 229ms/step - rpn_cls: 6.3283 - rpn_regr: 0.1634 - final_cls: 0.6918 - final_regr: 0.5381 - loss: 7.7217
Mean number of bounding boxes from RPN overlapping ground truth boxes: 7.821917808219178
Classifier accuracy for bounding boxes from RPN: 0.541095890410959
Loss RPN classifier: 5.1696287338925515
Loss RPN regression: 0.1537954178574967
Loss Detector classifier: 0.6862477619354039
Loss Detector regression: 0.4860696655838457
Total loss: 6.495741579269297
Elapsed time: 16.708739757537842
Start of the validation phase

 1/24 [>.............................] - ETA: 6:35 - rpn_cls_val: 4.1121 - rpn_regr_val: 0.0222 - final_cls_val: 0.6156 - final_regr_val: 0.4012 - loss_val: 5.1511
 2/24 [=>............................] - ETA: 3:09 - rpn_cls_val: 5.5765 - rpn_regr_val: 0.0450 - final_cls_val: 0.6326 - final_regr_val: 0.4324 - loss_val: 6.6865
 3/24 [==>...........................] - ETA: 2:01 - rpn_cls_val: 5.6126 - rpn_regr_val: 0.0510 - final_cls_val: 0.6374 - final_regr_val: 0.4258 - loss_val: 6.7268
 4/24 [====>.........................] - ETA: 1:27 - rpn_cls_val: 5.2754 - rpn_regr_val: 0.0668 - final_cls_val: 0.6381 - final_regr_val: 0.4262 - loss_val: 6.4065
 5/24 [=====>........................] - ETA: 1:06 - rpn_cls_val: 5.1091 - rpn_regr_val: 0.0722 - final_cls_val: 0.6405 - final_regr_val: 0.4369 - loss_val: 6.2586
 6/24 [======>.......................] - ETA: 52s - rpn_cls_val: 4.8773 - rpn_regr_val: 0.0757 - final_cls_val: 0.6416 - final_regr_val: 0.4401 - loss_val: 6.0346 
 7/24 [=======>......................] - ETA: 42s - rpn_cls_val: 4.6371 - rpn_regr_val: 0.0774 - final_cls_val: 0.6428 - final_regr_val: 0.4430 - loss_val: 5.8003
 8/24 [=========>....................] - ETA: 35s - rpn_cls_val: 4.5061 - rpn_regr_val: 0.0797 - final_cls_val: 0.6451 - final_regr_val: 0.4424 - loss_val: 5.6733
 9/24 [==========>...................] - ETA: 29s - rpn_cls_val: 4.3898 - rpn_regr_val: 0.0827 - final_cls_val: 0.6460 - final_regr_val: 0.4423 - loss_val: 5.5607
10/24 [===========>..................] - ETA: 25s - rpn_cls_val: 4.3390 - rpn_regr_val: 0.0849 - final_cls_val: 0.6467 - final_regr_val: 0.4416 - loss_val: 5.5123
11/24 [============>.................] - ETA: 21s - rpn_cls_val: 4.2891 - rpn_regr_val: 0.0862 - final_cls_val: 0.6472 - final_regr_val: 0.4381 - loss_val: 5.4606
12/24 [==============>...............] - ETA: 18s - rpn_cls_val: 4.2645 - rpn_regr_val: 0.0868 - final_cls_val: 0.6479 - final_regr_val: 0.4369 - loss_val: 5.4361
13/24 [===============>..............] - ETA: 15s - rpn_cls_val: 4.2437 - rpn_regr_val: 0.0871 - final_cls_val: 0.6485 - final_regr_val: 0.4357 - loss_val: 5.4151
14/24 [================>.............] - ETA: 13s - rpn_cls_val: 4.2361 - rpn_regr_val: 0.0879 - final_cls_val: 0.6491 - final_regr_val: 0.4352 - loss_val: 5.4082
15/24 [=================>............] - ETA: 10s - rpn_cls_val: 4.2330 - rpn_regr_val: 0.0889 - final_cls_val: 0.6496 - final_regr_val: 0.4349 - loss_val: 5.4064
16/24 [===================>..........] - ETA: 9s - rpn_cls_val: 4.2289 - rpn_regr_val: 0.0896 - final_cls_val: 0.6501 - final_regr_val: 0.4344 - loss_val: 5.4030 
17/24 [====================>.........] - ETA: 7s - rpn_cls_val: 4.2313 - rpn_regr_val: 0.0899 - final_cls_val: 0.6506 - final_regr_val: 0.4336 - loss_val: 5.4055
18/24 [=====================>........] - ETA: 6s - rpn_cls_val: 4.2235 - rpn_regr_val: 0.0902 - final_cls_val: 0.6511 - final_regr_val: 0.4327 - loss_val: 5.3975
19/24 [======================>.......] - ETA: 4s - rpn_cls_val: 4.2229 - rpn_regr_val: 0.0905 - final_cls_val: 0.6517 - final_regr_val: 0.4323 - loss_val: 5.3975
20/24 [========================>.....] - ETA: 3s - rpn_cls_val: 4.2219 - rpn_regr_val: 0.0908 - final_cls_val: 0.6521 - final_regr_val: 0.4318 - loss_val: 5.3967
21/24 [=========================>....] - ETA: 2s - rpn_cls_val: 4.2226 - rpn_regr_val: 0.0910 - final_cls_val: 0.6526 - final_regr_val: 0.4315 - loss_val: 5.3976
22/24 [==========================>...] - ETA: 1s - rpn_cls_val: 4.2216 - rpn_regr_val: 0.0911 - final_cls_val: 0.6528 - final_regr_val: 0.4311 - loss_val: 5.3966
23/24 [===========================>..] - ETA: 0s - rpn_cls_val: 4.2263 - rpn_regr_val: 0.0912 - final_cls_val: 0.6531 - final_regr_val: 0.4311 - loss_val: 5.4017
24/24 [==============================] - 19s 793ms/step - rpn_cls_val: 4.2300 - rpn_regr_val: 0.0912 - final_cls_val: 0.6534 - final_regr_val: 0.4309 - loss_val: 5.4056
End of the validation phase
Validation classifier accuracy for bounding boxes from RPN: 0.7604166666666666
Validation loss RPN classifier: 4.316636029630899
Validation loss RPN regression: 0.09155165361395727
Validation loss Detector classifier: 0.6596158345540365
Validation loss Detector regression: 0.4263344658538699
Total validation loss: 5.494137983652763
Total validation loss decreased from inf to 5.494137983652763
Epoch 2/2

 1/73 [..............................] - ETA: 12s - rpn_cls: 5.8182 - rpn_regr: 0.3396 - final_cls: 0.6727 - final_regr: 0.6761 - loss: 7.5066
 2/73 [..............................] - ETA: 12s - rpn_cls: 5.4002 - rpn_regr: 0.2661 - final_cls: 0.6803 - final_regr: 0.5854 - loss: 6.9320
 3/73 [>.............................] - ETA: 12s - rpn_cls: 4.8652 - rpn_regr: 0.2281 - final_cls: 0.6815 - final_regr: 0.5561 - loss: 6.3309
 4/73 [>.............................] - ETA: 12s - rpn_cls: 4.8180 - rpn_regr: 0.2158 - final_cls: 0.6826 - final_regr: 0.5529 - loss: 6.2693
 5/73 [=>............................] - ETA: 12s - rpn_cls: 4.6032 - rpn_regr: 0.2175 - final_cls: 0.6833 - final_regr: 0.5513 - loss: 6.0553
 6/73 [=>............................] - ETA: 12s - rpn_cls: 4.4789 - rpn_regr: 0.2155 - final_cls: 0.6829 - final_regr: 0.5423 - loss: 5.9195
 7/73 [=>............................] - ETA: 11s - rpn_cls: 4.3631 - rpn_regr: 0.2109 - final_cls: 0.6819 - final_regr: 0.5306 - loss: 5.7865
 8/73 [==>...........................] - ETA: 11s - rpn_cls: 4.4182 - rpn_regr: 0.2084 - final_cls: 0.6822 - final_regr: 0.5210 - loss: 5.8299
 9/73 [==>...........................] - ETA: 11s - rpn_cls: 4.4057 - rpn_regr: 0.2070 - final_cls: 0.6825 - final_regr: 0.5112 - loss: 5.8064
10/73 [===>..........................] - ETA: 11s - rpn_cls: 4.3721 - rpn_regr: 0.2061 - final_cls: 0.6821 - final_regr: 0.5036 - loss: 5.7640
11/73 [===>..........................] - ETA: 11s - rpn_cls: 4.3597 - rpn_regr: 0.2044 - final_cls: 0.6814 - final_regr: 0.4965 - loss: 5.7420
12/73 [===>..........................] - ETA: 10s - rpn_cls: 4.3199 - rpn_regr: 0.2023 - final_cls: 0.6813 - final_regr: 0.4907 - loss: 5.6941
13/73 [====>.........................] - ETA: 10s - rpn_cls: 4.2777 - rpn_regr: 0.2006 - final_cls: 0.6808 - final_regr: 0.4864 - loss: 5.6454
14/73 [====>.........................] - ETA: 10s - rpn_cls: 4.2402 - rpn_regr: 0.1983 - final_cls: 0.6801 - final_regr: 0.4830 - loss: 5.6016
15/73 [=====>........................] - ETA: 10s - rpn_cls: 4.2466 - rpn_regr: 0.1963 - final_cls: 0.6797 - final_regr: 0.4825 - loss: 5.6050
16/73 [=====>........................] - ETA: 9s - rpn_cls: 4.2513 - rpn_regr: 0.1947 - final_cls: 0.6790 - final_regr: 0.4826 - loss: 5.6075 
17/73 [=====>........................] - ETA: 9s - rpn_cls: 4.2410 - rpn_regr: 0.1940 - final_cls: 0.6784 - final_regr: 0.4825 - loss: 5.5960
18/73 [======>.......................] - ETA: 9s - rpn_cls: 4.2385 - rpn_regr: 0.1930 - final_cls: 0.6782 - final_regr: 0.4821 - loss: 5.59192021-03-03 22:16:42.727982: W tensorflow/core/common_runtime/bfc_allocator.cc:245] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.96GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2021-03-03 22:16:42.728028: W tensorflow/core/common_runtime/bfc_allocator.cc:245] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.96GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2021-03-03 22:16:43.513420: W tensorflow/core/common_runtime/bfc_allocator.cc:245] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.96GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2021-03-03 22:16:43.513453: W tensorflow/core/common_runtime/bfc_allocator.cc:245] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.96GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.

19/73 [======>.......................] - ETA: 11s - rpn_cls: 4.2436 - rpn_regr: 0.1923 - final_cls: 0.6776 - final_regr: 0.4820 - loss: 5.5955
20/73 [=======>......................] - ETA: 11s - rpn_cls: 4.2518 - rpn_regr: 0.1913 - final_cls: 0.6767 - final_regr: 0.4815 - loss: 5.6013
21/73 [=======>......................] - ETA: 11s - rpn_cls: 4.2535 - rpn_regr: 0.1901 - final_cls: 0.6759 - final_regr: 0.4813 - loss: 5.6009
22/73 [========>.....................] - ETA: 10s - rpn_cls: 4.2462 - rpn_regr: 0.1889 - final_cls: 0.6752 - final_regr: 0.4809 - loss: 5.5911
23/73 [========>.....................] - ETA: 10s - rpn_cls: 4.2392 - rpn_regr: 0.1884 - final_cls: 0.6744 - final_regr: 0.4804 - loss: 5.5823
24/73 [========>.....................] - ETA: 10s - rpn_cls: 4.2256 - rpn_regr: 0.1878 - final_cls: 0.6736 - final_regr: 0.4797 - loss: 5.5667
25/73 [=========>....................] - ETA: 10s - rpn_cls: 4.2127 - rpn_regr: 0.1874 - final_cls: 0.6726 - final_regr: 0.4788 - loss: 5.5515
26/73 [=========>....................] - ETA: 9s - rpn_cls: 4.2025 - rpn_regr: 0.1871 - final_cls: 0.6716 - final_regr: 0.4782 - loss: 5.5394 
27/73 [==========>...................] - ETA: 9s - rpn_cls: 4.1958 - rpn_regr: 0.1866 - final_cls: 0.6708 - final_regr: 0.4773 - loss: 5.5305
28/73 [==========>...................] - ETA: 9s - rpn_cls: 4.1863 - rpn_regr: 0.1862 - final_cls: 0.6699 - final_regr: 0.4766 - loss: 5.5190
29/73 [==========>...................] - ETA: 8s - rpn_cls: 4.1727 - rpn_regr: 0.1861 - final_cls: 0.6690 - final_regr: 0.4761 - loss: 5.5039
30/73 [===========>..................] - ETA: 8s - rpn_cls: 4.1614 - rpn_regr: 0.1860 - final_cls: 0.6682 - final_regr: 0.4754 - loss: 5.4910
31/73 [===========>..................] - ETA: 8s - rpn_cls: 4.1468 - rpn_regr: 0.1859 - final_cls: 0.6675 - final_regr: 0.4749 - loss: 5.4751
32/73 [============>.................] - ETA: 8s - rpn_cls: 4.1355 - rpn_regr: 0.1857 - final_cls: 0.6669 - final_regr: 0.4742 - loss: 5.46222021-03-03 22:16:46.370370: W tensorflow/core/common_runtime/bfc_allocator.cc:245] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.69GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2021-03-03 22:16:46.370413: W tensorflow/core/common_runtime/bfc_allocator.cc:245] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.69GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.

33/73 [============>.................] - ETA: 8s - rpn_cls: 4.1254 - rpn_regr: 0.1855 - final_cls: 0.6663 - final_regr: 0.4734 - loss: 5.4506
34/73 [============>.................] - ETA: 8s - rpn_cls: 4.1182 - rpn_regr: 0.1855 - final_cls: 0.6657 - final_regr: 0.4728 - loss: 5.4421
35/73 [=============>................] - ETA: 8s - rpn_cls: 4.1172 - rpn_regr: 0.1861 - final_cls: 0.6650 - final_regr: 0.4719 - loss: 5.4402
36/73 [=============>................] - ETA: 7s - rpn_cls: 4.1132 - rpn_regr: 0.1867 - final_cls: 0.6643 - final_regr: 0.4711 - loss: 5.4353
37/73 [==============>...............] - ETA: 7s - rpn_cls: 4.1084 - rpn_regr: 0.1872 - final_cls: 0.6637 - final_regr: 0.4704 - loss: 5.4297
38/73 [==============>...............] - ETA: 7s - rpn_cls: 4.1032 - rpn_regr: 0.1876 - final_cls: 0.6630 - final_regr: 0.4697 - loss: 5.4235
39/73 [===============>..............] - ETA: 7s - rpn_cls: 4.0957 - rpn_regr: 0.1880 - final_cls: 0.6621 - final_regr: 0.4690 - loss: 5.4149
40/73 [===============>..............] - ETA: 6s - rpn_cls: 4.0938 - rpn_regr: 0.1883 - final_cls: 0.6611 - final_regr: 0.4681 - loss: 5.4113
41/73 [===============>..............] - ETA: 6s - rpn_cls: 4.0931 - rpn_regr: 0.1892 - final_cls: 0.6600 - final_regr: 0.4671 - loss: 5.4094
42/73 [================>.............] - ETA: 6s - rpn_cls: 4.0918 - rpn_regr: 0.1900 - final_cls: 0.6588 - final_regr: 0.4661 - loss: 5.4067
43/73 [================>.............] - ETA: 6s - rpn_cls: 4.0955 - rpn_regr: 0.1910 - final_cls: 0.6576 - final_regr: 0.4649 - loss: 5.4090
44/73 [=================>............] - ETA: 5s - rpn_cls: 4.0990 - rpn_regr: 0.1919 - final_cls: 0.6564 - final_regr: 0.4637 - loss: 5.4111
45/73 [=================>............] - ETA: 5s - rpn_cls: 4.1001 - rpn_regr: 0.1928 - final_cls: 0.6553 - final_regr: 0.4627 - loss: 5.4110
46/73 [=================>............] - ETA: 5s - rpn_cls: 4.0993 - rpn_regr: 0.1936 - final_cls: 0.6541 - final_regr: 0.4618 - loss: 5.4088
47/73 [==================>...........] - ETA: 5s - rpn_cls: 4.0967 - rpn_regr: 0.1944 - final_cls: 0.6527 - final_regr: 0.4609 - loss: 5.4047
48/73 [==================>...........] - ETA: 5s - rpn_cls: 4.0952 - rpn_regr: 0.1952 - final_cls: 0.6516 - final_regr: 0.4603 - loss: 5.4023
49/73 [===================>..........] - ETA: 4s - rpn_cls: 4.0951 - rpn_regr: 0.1960 - final_cls: 0.6505 - final_regr: 0.4595 - loss: 5.4011
50/73 [===================>..........] - ETA: 4s - rpn_cls: 4.0987 - rpn_regr: 0.1968 - final_cls: 0.6495 - final_regr: 0.4589 - loss: 5.4039
51/73 [===================>..........] - ETA: 4s - rpn_cls: 4.1028 - rpn_regr: 0.1975 - final_cls: 0.6486 - final_regr: 0.4583 - loss: 5.4072
52/73 [====================>.........] - ETA: 4s - rpn_cls: 4.1058 - rpn_regr: 0.1981 - final_cls: 0.6476 - final_regr: 0.4577 - loss: 5.4093
53/73 [====================>.........] - ETA: 3s - rpn_cls: 4.1073 - rpn_regr: 0.1988 - final_cls: 0.6467 - final_regr: 0.4572 - loss: 5.4099
54/73 [=====================>........] - ETA: 3s - rpn_cls: 4.1091 - rpn_regr: 0.1993 - final_cls: 0.6458 - final_regr: 0.4566 - loss: 5.4108
55/73 [=====================>........] - ETA: 3s - rpn_cls: 4.1111 - rpn_regr: 0.1998 - final_cls: 0.6449 - final_regr: 0.4561 - loss: 5.4119
56/73 [======================>.......] - ETA: 3s - rpn_cls: 4.1148 - rpn_regr: 0.2004 - final_cls: 0.6440 - final_regr: 0.4557 - loss: 5.4149
57/73 [======================>.......] - ETA: 3s - rpn_cls: 4.1191 - rpn_regr: 0.2009 - final_cls: 0.6431 - final_regr: 0.4554 - loss: 5.4184
58/73 [======================>.......] - ETA: 2s - rpn_cls: 4.1231 - rpn_regr: 0.2013 - final_cls: 0.6421 - final_regr: 0.4550 - loss: 5.4215
59/73 [=======================>......] - ETA: 2s - rpn_cls: 4.1281 - rpn_regr: 0.2018 - final_cls: 0.6412 - final_regr: 0.4546 - loss: 5.4257
60/73 [=======================>......] - ETA: 2s - rpn_cls: 4.1328 - rpn_regr: 0.2022 - final_cls: 0.6404 - final_regr: 0.4543 - loss: 5.4295
61/73 [========================>.....] - ETA: 2s - rpn_cls: 4.1369 - rpn_regr: 0.2025 - final_cls: 0.6395 - final_regr: 0.4540 - loss: 5.4329
62/73 [========================>.....] - ETA: 2s - rpn_cls: 4.1405 - rpn_regr: 0.2028 - final_cls: 0.6387 - final_regr: 0.4537 - loss: 5.4356
63/73 [========================>.....] - ETA: 1s - rpn_cls: 4.1428 - rpn_regr: 0.2030 - final_cls: 0.6379 - final_regr: 0.4533 - loss: 5.4370
64/73 [=========================>....] - ETA: 1s - rpn_cls: 4.1449 - rpn_regr: 0.2032 - final_cls: 0.6370 - final_regr: 0.4530 - loss: 5.4380
65/73 [=========================>....] - ETA: 1s - rpn_cls: 4.1475 - rpn_regr: 0.2033 - final_cls: 0.6360 - final_regr: 0.4526 - loss: 5.4394
66/73 [==========================>...] - ETA: 1s - rpn_cls: 4.1499 - rpn_regr: 0.2034 - final_cls: 0.6350 - final_regr: 0.4522 - loss: 5.4405
67/73 [==========================>...] - ETA: 1s - rpn_cls: 4.1525 - rpn_regr: 0.2035 - final_cls: 0.6340 - final_regr: 0.4518 - loss: 5.4418
68/73 [==========================>...] - ETA: 0s - rpn_cls: 4.1554 - rpn_regr: 0.2036 - final_cls: 0.6331 - final_regr: 0.4515 - loss: 5.4435
69/73 [===========================>..] - ETA: 0s - rpn_cls: 4.1588 - rpn_regr: 0.2037 - final_cls: 0.6321 - final_regr: 0.4511 - loss: 5.4457
70/73 [===========================>..] - ETA: 0s - rpn_cls: 4.1637 - rpn_regr: 0.2038 - final_cls: 0.6313 - final_regr: 0.4507 - loss: 5.4495
71/73 [============================>.] - ETA: 0s - rpn_cls: 4.1679 - rpn_regr: 0.2040 - final_cls: 0.6303 - final_regr: 0.4504 - loss: 5.4526
72/73 [============================>.] - ETA: 0s - rpn_cls: 4.1718 - rpn_regr: 0.2042 - final_cls: 0.6295 - final_regr: 0.4501 - loss: 5.4556
73/73 [==============================] - 14s 191ms/step - rpn_cls: 4.1750 - rpn_regr: 0.2045 - final_cls: 0.6287 - final_regr: 0.4498 - loss: 5.4580
Mean number of bounding boxes from RPN overlapping ground truth boxes: 9.0
Classifier accuracy for bounding boxes from RPN: 0.7328767123287672
Loss RPN classifier: 4.406815984392857
Loss RPN regression: 0.2274110144871759
Loss Detector classifier: 0.5710796372939463
Loss Detector regression: 0.4292235232583464
Total loss: 5.634530159432326
Elapsed time: 13.935354471206665
Start of the validation phase

 1/24 [>.............................] - ETA: 5:22 - rpn_cls_val: 0.0241 - rpn_regr_val: 0.2300 - final_cls_val: 0.7812 - final_regr_val: 0.2877 - loss_val: 1.3230
 2/24 [=>............................] - ETA: 2:35 - rpn_cls_val: 0.3896 - rpn_regr_val: 0.5244 - final_cls_val: 0.8324 - final_regr_val: 0.3411 - loss_val: 2.0875
 3/24 [==>...........................] - ETA: 1:39 - rpn_cls_val: 0.8117 - rpn_regr_val: 0.5375 - final_cls_val: 0.8016 - final_regr_val: 0.3507 - loss_val: 2.5014
 4/24 [====>.........................] - ETA: 1:11 - rpn_cls_val: 1.3201 - rpn_regr_val: 0.5632 - final_cls_val: 0.8057 - final_regr_val: 0.3495 - loss_val: 3.0385
 5/24 [=====>........................] - ETA: 54s - rpn_cls_val: 1.5190 - rpn_regr_val: 0.5573 - final_cls_val: 0.7884 - final_regr_val: 0.3477 - loss_val: 3.2124 
 6/24 [======>.......................] - ETA: 43s - rpn_cls_val: 1.6525 - rpn_regr_val: 0.5511 - final_cls_val: 0.7716 - final_regr_val: 0.3421 - loss_val: 3.3173
 7/24 [=======>......................] - ETA: 35s - rpn_cls_val: 1.8091 - rpn_regr_val: 0.5411 - final_cls_val: 0.7578 - final_regr_val: 0.3359 - loss_val: 3.4439
 8/24 [=========>....................] - ETA: 29s - rpn_cls_val: 2.0156 - rpn_regr_val: 0.5473 - final_cls_val: 0.7389 - final_regr_val: 0.3338 - loss_val: 3.6356
 9/24 [==========>...................] - ETA: 24s - rpn_cls_val: 2.1370 - rpn_regr_val: 0.5481 - final_cls_val: 0.7261 - final_regr_val: 0.3326 - loss_val: 3.7437
10/24 [===========>..................] - ETA: 20s - rpn_cls_val: 2.3076 - rpn_regr_val: 0.5479 - final_cls_val: 0.7137 - final_regr_val: 0.3301 - loss_val: 3.8993
11/24 [============>.................] - ETA: 17s - rpn_cls_val: 2.4425 - rpn_regr_val: 0.5465 - final_cls_val: 0.7010 - final_regr_val: 0.3287 - loss_val: 4.0186
12/24 [==============>...............] - ETA: 14s - rpn_cls_val: 2.6117 - rpn_regr_val: 0.5430 - final_cls_val: 0.6917 - final_regr_val: 0.3302 - loss_val: 4.1767
13/24 [===============>..............] - ETA: 12s - rpn_cls_val: 2.7500 - rpn_regr_val: 0.5389 - final_cls_val: 0.6815 - final_regr_val: 0.3305 - loss_val: 4.3009
14/24 [================>.............] - ETA: 10s - rpn_cls_val: 2.8460 - rpn_regr_val: 0.5340 - final_cls_val: 0.6723 - final_regr_val: 0.3305 - loss_val: 4.3828
15/24 [=================>............] - ETA: 9s - rpn_cls_val: 2.9163 - rpn_regr_val: 0.5298 - final_cls_val: 0.6641 - final_regr_val: 0.3314 - loss_val: 4.4416 
16/24 [===================>..........] - ETA: 7s - rpn_cls_val: 2.9831 - rpn_regr_val: 0.5252 - final_cls_val: 0.6554 - final_regr_val: 0.3321 - loss_val: 4.4959
17/24 [====================>.........] - ETA: 6s - rpn_cls_val: 3.0413 - rpn_regr_val: 0.5198 - final_cls_val: 0.6469 - final_regr_val: 0.3331 - loss_val: 4.5411
18/24 [=====================>........] - ETA: 5s - rpn_cls_val: 3.0944 - rpn_regr_val: 0.5151 - final_cls_val: 0.6410 - final_regr_val: 0.3349 - loss_val: 4.5854
19/24 [======================>.......] - ETA: 4s - rpn_cls_val: 3.1309 - rpn_regr_val: 0.5099 - final_cls_val: 0.6350 - final_regr_val: 0.3365 - loss_val: 4.6122
20/24 [========================>.....] - ETA: 3s - rpn_cls_val: 3.1542 - rpn_regr_val: 0.5053 - final_cls_val: 0.6289 - final_regr_val: 0.3376 - loss_val: 4.6261
21/24 [=========================>....] - ETA: 2s - rpn_cls_val: 3.1735 - rpn_regr_val: 0.5017 - final_cls_val: 0.6247 - final_regr_val: 0.3387 - loss_val: 4.6387
22/24 [==========================>...] - ETA: 1s - rpn_cls_val: 3.1870 - rpn_regr_val: 0.4981 - final_cls_val: 0.6221 - final_regr_val: 0.3401 - loss_val: 4.6473
23/24 [===========================>..] - ETA: 0s - rpn_cls_val: 3.2001 - rpn_regr_val: 0.4949 - final_cls_val: 0.6190 - final_regr_val: 0.3415 - loss_val: 4.6554
24/24 [==============================] - 16s 660ms/step - rpn_cls_val: 3.2061 - rpn_regr_val: 0.4915 - final_cls_val: 0.6162 - final_regr_val: 0.3426 - loss_val: 4.6564
End of the validation phase
Validation classifier accuracy for bounding boxes from RPN: 0.7916666666666666
Validation loss RPN classifier: 3.343555064609101
Validation loss RPN regression: 0.41494666940222186
Validation loss Detector classifier: 0.5519111758718888
Validation loss Detector regression: 0.36761294802029926
Total validation loss: 4.678025857903511
Total validation loss decreased from 5.494137983652763 to 4.678025857903511
=== Fold 4/4 ===
Loading weights from ./model/vgg16_weights_tf_dim_ordering_tf_kernels.h5
Epoch 1/2

 1/73 [..............................] - ETA: 4:06 - rpn_cls: 12.1624 - rpn_regr: 0.2452 - final_cls: 0.6931 - final_regr: 0.7196 - loss: 13.8204
 2/73 [..............................] - ETA: 2:07 - rpn_cls: 12.0421 - rpn_regr: 0.2158 - final_cls: 0.6931 - final_regr: 0.6827 - loss: 13.6336
 3/73 [>.............................] - ETA: 1:27 - rpn_cls: 11.7391 - rpn_regr: 0.1905 - final_cls: 0.6924 - final_regr: 0.6462 - loss: 13.2683
 4/73 [>.............................] - ETA: 1:08 - rpn_cls: 11.6482 - rpn_regr: 0.1867 - final_cls: 0.6923 - final_regr: 0.6510 - loss: 13.1782
 5/73 [=>............................] - ETA: 56s - rpn_cls: 11.6471 - rpn_regr: 0.1845 - final_cls: 0.6922 - final_regr: 0.6578 - loss: 13.1816 
 6/73 [=>............................] - ETA: 48s - rpn_cls: 11.5342 - rpn_regr: 0.1797 - final_cls: 0.6922 - final_regr: 0.6502 - loss: 13.0563
 7/73 [=>............................] - ETA: 42s - rpn_cls: 11.3806 - rpn_regr: 0.1737 - final_cls: 0.6923 - final_regr: 0.6386 - loss: 12.8851
 8/73 [==>...........................] - ETA: 37s - rpn_cls: 11.1031 - rpn_regr: 0.1722 - final_cls: 0.6922 - final_regr: 0.6243 - loss: 12.5917
 9/73 [==>...........................] - ETA: 34s - rpn_cls: 10.8524 - rpn_regr: 0.1709 - final_cls: 0.6919 - final_regr: 0.6169 - loss: 12.3320
10/73 [===>..........................] - ETA: 31s - rpn_cls: 10.6258 - rpn_regr: 0.1694 - final_cls: 0.6918 - final_regr: 0.6092 - loss: 12.0962
11/73 [===>..........................] - ETA: 29s - rpn_cls: 10.4455 - rpn_regr: 0.1675 - final_cls: 0.6918 - final_regr: 0.6035 - loss: 11.9082
12/73 [===>..........................] - ETA: 27s - rpn_cls: 10.2368 - rpn_regr: 0.1663 - final_cls: 0.6916 - final_regr: 0.5987 - loss: 11.6934
13/73 [====>.........................] - ETA: 25s - rpn_cls: 10.0637 - rpn_regr: 0.1655 - final_cls: 0.6914 - final_regr: 0.5925 - loss: 11.5132
14/73 [====>.........................] - ETA: 23s - rpn_cls: 9.9006 - rpn_regr: 0.1643 - final_cls: 0.6913 - final_regr: 0.5853 - loss: 11.3415 
15/73 [=====>........................] - ETA: 22s - rpn_cls: 9.7529 - rpn_regr: 0.1634 - final_cls: 0.6912 - final_regr: 0.5821 - loss: 11.1895
16/73 [=====>........................] - ETA: 21s - rpn_cls: 9.5952 - rpn_regr: 0.1622 - final_cls: 0.6911 - final_regr: 0.5783 - loss: 11.0267
17/73 [=====>........................] - ETA: 20s - rpn_cls: 9.4528 - rpn_regr: 0.1623 - final_cls: 0.6910 - final_regr: 0.5748 - loss: 10.8808
18/73 [======>.......................] - ETA: 19s - rpn_cls: 9.3236 - rpn_regr: 0.1619 - final_cls: 0.6909 - final_regr: 0.5728 - loss: 10.7492
19/73 [======>.......................] - ETA: 18s - rpn_cls: 9.1982 - rpn_regr: 0.1614 - final_cls: 0.6909 - final_regr: 0.5703 - loss: 10.6208
20/73 [=======>......................] - ETA: 17s - rpn_cls: 9.0779 - rpn_regr: 0.1607 - final_cls: 0.6909 - final_regr: 0.5679 - loss: 10.4975
21/73 [=======>......................] - ETA: 17s - rpn_cls: 8.9802 - rpn_regr: 0.1600 - final_cls: 0.6909 - final_regr: 0.5663 - loss: 10.3974
22/73 [========>.....................] - ETA: 16s - rpn_cls: 8.8777 - rpn_regr: 0.1593 - final_cls: 0.6909 - final_regr: 0.5648 - loss: 10.2927
23/73 [========>.....................] - ETA: 15s - rpn_cls: 8.7847 - rpn_regr: 0.1587 - final_cls: 0.6909 - final_regr: 0.5633 - loss: 10.1976
24/73 [========>.....................] - ETA: 15s - rpn_cls: 8.6953 - rpn_regr: 0.1585 - final_cls: 0.6909 - final_regr: 0.5617 - loss: 10.1065
25/73 [=========>....................] - ETA: 14s - rpn_cls: 8.6162 - rpn_regr: 0.1583 - final_cls: 0.6910 - final_regr: 0.5600 - loss: 10.0254
26/73 [=========>....................] - ETA: 14s - rpn_cls: 8.5500 - rpn_regr: 0.1580 - final_cls: 0.6910 - final_regr: 0.5581 - loss: 9.9571 
27/73 [==========>...................] - ETA: 13s - rpn_cls: 8.4803 - rpn_regr: 0.1577 - final_cls: 0.6910 - final_regr: 0.5560 - loss: 9.8850
28/73 [==========>...................] - ETA: 13s - rpn_cls: 8.4136 - rpn_regr: 0.1577 - final_cls: 0.6910 - final_regr: 0.5544 - loss: 9.8167
29/73 [==========>...................] - ETA: 12s - rpn_cls: 8.3533 - rpn_regr: 0.1581 - final_cls: 0.6910 - final_regr: 0.5528 - loss: 9.7551
30/73 [===========>..................] - ETA: 12s - rpn_cls: 8.3033 - rpn_regr: 0.1583 - final_cls: 0.6910 - final_regr: 0.5511 - loss: 9.7036
31/73 [===========>..................] - ETA: 11s - rpn_cls: 8.2496 - rpn_regr: 0.1585 - final_cls: 0.6909 - final_regr: 0.5493 - loss: 9.6484
32/73 [============>.................] - ETA: 11s - rpn_cls: 8.2002 - rpn_regr: 0.1588 - final_cls: 0.6909 - final_regr: 0.5472 - loss: 9.5971
33/73 [============>.................] - ETA: 10s - rpn_cls: 8.1583 - rpn_regr: 0.1590 - final_cls: 0.6909 - final_regr: 0.5451 - loss: 9.5532
34/73 [============>.................] - ETA: 10s - rpn_cls: 8.1180 - rpn_regr: 0.1591 - final_cls: 0.6908 - final_regr: 0.5430 - loss: 9.5109
35/73 [=============>................] - ETA: 10s - rpn_cls: 8.0809 - rpn_regr: 0.1594 - final_cls: 0.6908 - final_regr: 0.5412 - loss: 9.4722
36/73 [=============>................] - ETA: 9s - rpn_cls: 8.0502 - rpn_regr: 0.1597 - final_cls: 0.6908 - final_regr: 0.5395 - loss: 9.4401 
37/73 [==============>...............] - ETA: 9s - rpn_cls: 8.0245 - rpn_regr: 0.1599 - final_cls: 0.6908 - final_regr: 0.5378 - loss: 9.4130
38/73 [==============>...............] - ETA: 9s - rpn_cls: 8.0023 - rpn_regr: 0.1600 - final_cls: 0.6908 - final_regr: 0.5364 - loss: 9.3895
39/73 [===============>..............] - ETA: 8s - rpn_cls: 7.9797 - rpn_regr: 0.1602 - final_cls: 0.6908 - final_regr: 0.5349 - loss: 9.3656
40/73 [===============>..............] - ETA: 8s - rpn_cls: 7.9562 - rpn_regr: 0.1603 - final_cls: 0.6908 - final_regr: 0.5335 - loss: 9.3408
41/73 [===============>..............] - ETA: 8s - rpn_cls: 7.9339 - rpn_regr: 0.1604 - final_cls: 0.6908 - final_regr: 0.5322 - loss: 9.3174
42/73 [================>.............] - ETA: 7s - rpn_cls: 7.9144 - rpn_regr: 0.1605 - final_cls: 0.6908 - final_regr: 0.5309 - loss: 9.2966
43/73 [================>.............] - ETA: 7s - rpn_cls: 7.8991 - rpn_regr: 0.1605 - final_cls: 0.6908 - final_regr: 0.5298 - loss: 9.2803
44/73 [=================>............] - ETA: 7s - rpn_cls: 7.8858 - rpn_regr: 0.1606 - final_cls: 0.6909 - final_regr: 0.5287 - loss: 9.2660
45/73 [=================>............] - ETA: 6s - rpn_cls: 7.8759 - rpn_regr: 0.1607 - final_cls: 0.6909 - final_regr: 0.5277 - loss: 9.2551
46/73 [=================>............] - ETA: 6s - rpn_cls: 7.8628 - rpn_regr: 0.1608 - final_cls: 0.6909 - final_regr: 0.5268 - loss: 9.2413
47/73 [==================>...........] - ETA: 6s - rpn_cls: 7.8528 - rpn_regr: 0.1609 - final_cls: 0.6909 - final_regr: 0.5258 - loss: 9.2304
48/73 [==================>...........] - ETA: 6s - rpn_cls: 7.8447 - rpn_regr: 0.1610 - final_cls: 0.6909 - final_regr: 0.5249 - loss: 9.2216
49/73 [===================>..........] - ETA: 5s - rpn_cls: 7.8371 - rpn_regr: 0.1611 - final_cls: 0.6909 - final_regr: 0.5242 - loss: 9.2134
50/73 [===================>..........] - ETA: 5s - rpn_cls: 7.8284 - rpn_regr: 0.1612 - final_cls: 0.6910 - final_regr: 0.5234 - loss: 9.2040
51/73 [===================>..........] - ETA: 5s - rpn_cls: 7.8193 - rpn_regr: 0.1612 - final_cls: 0.6909 - final_regr: 0.5226 - loss: 9.1941
52/73 [====================>.........] - ETA: 4s - rpn_cls: 7.8103 - rpn_regr: 0.1612 - final_cls: 0.6909 - final_regr: 0.5219 - loss: 9.1843
53/73 [====================>.........] - ETA: 4s - rpn_cls: 7.8036 - rpn_regr: 0.1612 - final_cls: 0.6909 - final_regr: 0.5212 - loss: 9.1769
54/73 [=====================>........] - ETA: 4s - rpn_cls: 7.7979 - rpn_regr: 0.1612 - final_cls: 0.6909 - final_regr: 0.5205 - loss: 9.1705
55/73 [=====================>........] - ETA: 4s - rpn_cls: 7.7922 - rpn_regr: 0.1612 - final_cls: 0.6908 - final_regr: 0.5197 - loss: 9.1639
56/73 [======================>.......] - ETA: 3s - rpn_cls: 7.7850 - rpn_regr: 0.1611 - final_cls: 0.6908 - final_regr: 0.5189 - loss: 9.1559
57/73 [======================>.......] - ETA: 3s - rpn_cls: 7.7795 - rpn_regr: 0.1611 - final_cls: 0.6908 - final_regr: 0.5182 - loss: 9.1496
58/73 [======================>.......] - ETA: 3s - rpn_cls: 7.7749 - rpn_regr: 0.1610 - final_cls: 0.6907 - final_regr: 0.5175 - loss: 9.1441
59/73 [=======================>......] - ETA: 3s - rpn_cls: 7.7693 - rpn_regr: 0.1609 - final_cls: 0.6907 - final_regr: 0.5168 - loss: 9.1376
60/73 [=======================>......] - ETA: 2s - rpn_cls: 7.7642 - rpn_regr: 0.1608 - final_cls: 0.6906 - final_regr: 0.5161 - loss: 9.1317
61/73 [========================>.....] - ETA: 2s - rpn_cls: 7.7598 - rpn_regr: 0.1606 - final_cls: 0.6906 - final_regr: 0.5153 - loss: 9.1262
62/73 [========================>.....] - ETA: 2s - rpn_cls: 7.7562 - rpn_regr: 0.1605 - final_cls: 0.6905 - final_regr: 0.5145 - loss: 9.1217
63/73 [========================>.....] - ETA: 2s - rpn_cls: 7.7521 - rpn_regr: 0.1603 - final_cls: 0.6905 - final_regr: 0.5138 - loss: 9.1167
64/73 [=========================>....] - ETA: 2s - rpn_cls: 7.7463 - rpn_regr: 0.1602 - final_cls: 0.6904 - final_regr: 0.5130 - loss: 9.1099
65/73 [=========================>....] - ETA: 1s - rpn_cls: 7.7396 - rpn_regr: 0.1600 - final_cls: 0.6904 - final_regr: 0.5123 - loss: 9.1023
66/73 [==========================>...] - ETA: 1s - rpn_cls: 7.7317 - rpn_regr: 0.1598 - final_cls: 0.6903 - final_regr: 0.5116 - loss: 9.0935
67/73 [==========================>...] - ETA: 1s - rpn_cls: 7.7227 - rpn_regr: 0.1597 - final_cls: 0.6902 - final_regr: 0.5109 - loss: 9.0835
68/73 [==========================>...] - ETA: 1s - rpn_cls: 7.7132 - rpn_regr: 0.1595 - final_cls: 0.6902 - final_regr: 0.5102 - loss: 9.0731
69/73 [===========================>..] - ETA: 0s - rpn_cls: 7.7037 - rpn_regr: 0.1594 - final_cls: 0.6901 - final_regr: 0.5095 - loss: 9.0627
70/73 [===========================>..] - ETA: 0s - rpn_cls: 7.6948 - rpn_regr: 0.1592 - final_cls: 0.6901 - final_regr: 0.5088 - loss: 9.0529
71/73 [============================>.] - ETA: 0s - rpn_cls: 7.6860 - rpn_regr: 0.1590 - final_cls: 0.6900 - final_regr: 0.5081 - loss: 9.0432
72/73 [============================>.] - ETA: 0s - rpn_cls: 7.6768 - rpn_regr: 0.1588 - final_cls: 0.6899 - final_regr: 0.5075 - loss: 9.0331
73/73 [==============================] - 16s 216ms/step - rpn_cls: 7.6669 - rpn_regr: 0.1586 - final_cls: 0.6899 - final_regr: 0.5068 - loss: 9.0223
Mean number of bounding boxes from RPN overlapping ground truth boxes: 7.4520547945205475
Classifier accuracy for bounding boxes from RPN: 0.565068493150685
Loss RPN classifier: 6.956514278260914
Loss RPN regression: 0.14461044490031183
Loss Detector classifier: 0.6851347407249555
Loss Detector regression: 0.45971325631827525
Total loss: 8.245972720204456
Elapsed time: 15.73280930519104
Start of the validation phase

 1/24 [>.............................] - ETA: 6:12 - rpn_cls_val: 12.2238 - rpn_regr_val: 0.1100 - final_cls_val: 0.6304 - final_regr_val: 0.0000e+00 - loss_val: 12.9641
 2/24 [=>............................] - ETA: 2:59 - rpn_cls_val: 9.3326 - rpn_regr_val: 0.1152 - final_cls_val: 0.6481 - final_regr_val: 0.1464 - loss_val: 10.2423     
 3/24 [==>...........................] - ETA: 1:54 - rpn_cls_val: 7.9011 - rpn_regr_val: 0.1118 - final_cls_val: 0.6537 - final_regr_val: 0.2026 - loss_val: 8.8693 
 4/24 [====>.........................] - ETA: 1:22 - rpn_cls_val: 7.2806 - rpn_regr_val: 0.1127 - final_cls_val: 0.6569 - final_regr_val: 0.2377 - loss_val: 8.2880
 5/24 [=====>........................] - ETA: 1:02 - rpn_cls_val: 6.8858 - rpn_regr_val: 0.1145 - final_cls_val: 0.6590 - final_regr_val: 0.2571 - loss_val: 7.9164
 6/24 [======>.......................] - ETA: 49s - rpn_cls_val: 6.5694 - rpn_regr_val: 0.1144 - final_cls_val: 0.6604 - final_regr_val: 0.2719 - loss_val: 7.6162 
 7/24 [=======>......................] - ETA: 40s - rpn_cls_val: 6.3579 - rpn_regr_val: 0.1134 - final_cls_val: 0.6607 - final_regr_val: 0.2845 - loss_val: 7.4165
 8/24 [=========>....................] - ETA: 33s - rpn_cls_val: 6.2168 - rpn_regr_val: 0.1143 - final_cls_val: 0.6614 - final_regr_val: 0.2989 - loss_val: 7.2914
 9/24 [==========>...................] - ETA: 28s - rpn_cls_val: 6.0887 - rpn_regr_val: 0.1138 - final_cls_val: 0.6612 - final_regr_val: 0.3098 - loss_val: 7.1735
10/24 [===========>..................] - ETA: 23s - rpn_cls_val: 5.9997 - rpn_regr_val: 0.1147 - final_cls_val: 0.6607 - final_regr_val: 0.3192 - loss_val: 7.0942
11/24 [============>.................] - ETA: 20s - rpn_cls_val: 5.9244 - rpn_regr_val: 0.1147 - final_cls_val: 0.6603 - final_regr_val: 0.3269 - loss_val: 7.0263
12/24 [==============>...............] - ETA: 17s - rpn_cls_val: 5.8618 - rpn_regr_val: 0.1146 - final_cls_val: 0.6604 - final_regr_val: 0.3333 - loss_val: 6.9701
13/24 [===============>..............] - ETA: 14s - rpn_cls_val: 5.7999 - rpn_regr_val: 0.1141 - final_cls_val: 0.6605 - final_regr_val: 0.3391 - loss_val: 6.9136
14/24 [================>.............] - ETA: 12s - rpn_cls_val: 5.7534 - rpn_regr_val: 0.1137 - final_cls_val: 0.6605 - final_regr_val: 0.3449 - loss_val: 6.8726
15/24 [=================>............] - ETA: 10s - rpn_cls_val: 5.7067 - rpn_regr_val: 0.1131 - final_cls_val: 0.6604 - final_regr_val: 0.3496 - loss_val: 6.8299
16/24 [===================>..........] - ETA: 8s - rpn_cls_val: 5.6462 - rpn_regr_val: 0.1126 - final_cls_val: 0.6602 - final_regr_val: 0.3532 - loss_val: 6.7721 
17/24 [====================>.........] - ETA: 7s - rpn_cls_val: 5.5850 - rpn_regr_val: 0.1120 - final_cls_val: 0.6600 - final_regr_val: 0.3567 - loss_val: 6.7137
18/24 [=====================>........] - ETA: 5s - rpn_cls_val: 5.5356 - rpn_regr_val: 0.1116 - final_cls_val: 0.6598 - final_regr_val: 0.3599 - loss_val: 6.6668
19/24 [======================>.......] - ETA: 4s - rpn_cls_val: 5.4790 - rpn_regr_val: 0.1116 - final_cls_val: 0.6597 - final_regr_val: 0.3631 - loss_val: 6.6135
20/24 [========================>.....] - ETA: 3s - rpn_cls_val: 5.4206 - rpn_regr_val: 0.1125 - final_cls_val: 0.6594 - final_regr_val: 0.3666 - loss_val: 6.5591
21/24 [=========================>....] - ETA: 2s - rpn_cls_val: 5.3842 - rpn_regr_val: 0.1132 - final_cls_val: 0.6593 - final_regr_val: 0.3698 - loss_val: 6.5265
22/24 [==========================>...] - ETA: 1s - rpn_cls_val: 5.3500 - rpn_regr_val: 0.1138 - final_cls_val: 0.6592 - final_regr_val: 0.3725 - loss_val: 6.4955
23/24 [===========================>..] - ETA: 0s - rpn_cls_val: 5.3173 - rpn_regr_val: 0.1142 - final_cls_val: 0.6591 - final_regr_val: 0.3749 - loss_val: 6.4656
24/24 [==============================] - 18s 760ms/step - rpn_cls_val: 5.2845 - rpn_regr_val: 0.1146 - final_cls_val: 0.6591 - final_regr_val: 0.3771 - loss_val: 6.4354
End of the validation phase
Validation classifier accuracy for bounding boxes from RPN: 0.7083333333333334
Validation loss RPN classifier: 4.530432228154193
Validation loss RPN regression: 0.12319961764539282
Validation loss Detector classifier: 0.6591391240557035
Validation loss Detector regression: 0.42757152517636615
Total validation loss: 5.740342495031655
Total validation loss decreased from inf to 5.740342495031655
Epoch 2/2

 1/73 [..............................] - ETA: 12s - rpn_cls: 3.4630 - rpn_regr: 0.3394 - final_cls: 0.6598 - final_regr: 0.6822 - loss: 5.1445
 2/73 [..............................] - ETA: 12s - rpn_cls: 2.6718 - rpn_regr: 0.2659 - final_cls: 0.6675 - final_regr: 0.5933 - loss: 4.1985
 3/73 [>.............................] - ETA: 11s - rpn_cls: 2.3658 - rpn_regr: 0.2297 - final_cls: 0.6686 - final_regr: 0.5612 - loss: 3.8253
 4/73 [>.............................] - ETA: 12s - rpn_cls: 2.7772 - rpn_regr: 0.2195 - final_cls: 0.6696 - final_regr: 0.5487 - loss: 4.2150
 5/73 [=>............................] - ETA: 11s - rpn_cls: 3.2470 - rpn_regr: 0.2136 - final_cls: 0.6693 - final_regr: 0.5446 - loss: 4.6746
 6/73 [=>............................] - ETA: 11s - rpn_cls: 3.4334 - rpn_regr: 0.2077 - final_cls: 0.6681 - final_regr: 0.5359 - loss: 4.8450
 7/73 [=>............................] - ETA: 11s - rpn_cls: 3.5416 - rpn_regr: 0.2009 - final_cls: 0.6679 - final_regr: 0.5239 - loss: 4.9343
 8/73 [==>...........................] - ETA: 11s - rpn_cls: 3.6252 - rpn_regr: 0.1973 - final_cls: 0.6670 - final_regr: 0.5148 - loss: 5.0043
 9/73 [==>...........................] - ETA: 11s - rpn_cls: 3.6438 - rpn_regr: 0.1953 - final_cls: 0.6665 - final_regr: 0.5071 - loss: 5.0127
10/73 [===>..........................] - ETA: 11s - rpn_cls: 3.6381 - rpn_regr: 0.1938 - final_cls: 0.6655 - final_regr: 0.5013 - loss: 4.9988
11/73 [===>..........................] - ETA: 10s - rpn_cls: 3.6192 - rpn_regr: 0.1913 - final_cls: 0.6643 - final_regr: 0.4958 - loss: 4.9706
12/73 [===>..........................] - ETA: 10s - rpn_cls: 3.5853 - rpn_regr: 0.1886 - final_cls: 0.6632 - final_regr: 0.4905 - loss: 4.9276
13/73 [====>.........................] - ETA: 10s - rpn_cls: 3.5469 - rpn_regr: 0.1862 - final_cls: 0.6619 - final_regr: 0.4861 - loss: 4.8811
14/73 [====>.........................] - ETA: 10s - rpn_cls: 3.5034 - rpn_regr: 0.1835 - final_cls: 0.6606 - final_regr: 0.4810 - loss: 4.8285
15/73 [=====>........................] - ETA: 10s - rpn_cls: 3.5081 - rpn_regr: 0.1812 - final_cls: 0.6596 - final_regr: 0.4770 - loss: 4.8258
16/73 [=====>........................] - ETA: 9s - rpn_cls: 3.5055 - rpn_regr: 0.1789 - final_cls: 0.6585 - final_regr: 0.4729 - loss: 4.8157 
17/73 [=====>........................] - ETA: 9s - rpn_cls: 3.4934 - rpn_regr: 0.1779 - final_cls: 0.6577 - final_regr: 0.4703 - loss: 4.7993
18/73 [======>.......................] - ETA: 9s - rpn_cls: 3.4916 - rpn_regr: 0.1768 - final_cls: 0.6572 - final_regr: 0.4667 - loss: 4.7922
19/73 [======>.......................] - ETA: 9s - rpn_cls: 3.4910 - rpn_regr: 0.1754 - final_cls: 0.6567 - final_regr: 0.4629 - loss: 4.7861
20/73 [=======>......................] - ETA: 9s - rpn_cls: 3.4913 - rpn_regr: 0.1739 - final_cls: 0.6562 - final_regr: 0.4588 - loss: 4.7802
21/73 [=======>......................] - ETA: 8s - rpn_cls: 3.4984 - rpn_regr: 0.1724 - final_cls: 0.6557 - final_regr: 0.4562 - loss: 4.7827
22/73 [========>.....................] - ETA: 8s - rpn_cls: 3.4973 - rpn_regr: 0.1708 - final_cls: 0.6554 - final_regr: 0.4536 - loss: 4.7772
23/73 [========>.....................] - ETA: 8s - rpn_cls: 3.4936 - rpn_regr: 0.1696 - final_cls: 0.6555 - final_regr: 0.4513 - loss: 4.7700
24/73 [========>.....................] - ETA: 8s - rpn_cls: 3.4843 - rpn_regr: 0.1685 - final_cls: 0.6555 - final_regr: 0.4493 - loss: 4.7576
25/73 [=========>....................] - ETA: 8s - rpn_cls: 3.4795 - rpn_regr: 0.1675 - final_cls: 0.6554 - final_regr: 0.4474 - loss: 4.7497
26/73 [=========>....................] - ETA: 8s - rpn_cls: 3.4794 - rpn_regr: 0.1664 - final_cls: 0.6552 - final_regr: 0.4458 - loss: 4.7467
27/73 [==========>...................] - ETA: 7s - rpn_cls: 3.4747 - rpn_regr: 0.1653 - final_cls: 0.6551 - final_regr: 0.4443 - loss: 4.7393
28/73 [==========>...................] - ETA: 7s - rpn_cls: 3.4743 - rpn_regr: 0.1644 - final_cls: 0.6551 - final_regr: 0.4430 - loss: 4.7368
29/73 [==========>...................] - ETA: 7s - rpn_cls: 3.4851 - rpn_regr: 0.1640 - final_cls: 0.6551 - final_regr: 0.4418 - loss: 4.7461
30/73 [===========>..................] - ETA: 7s - rpn_cls: 3.4994 - rpn_regr: 0.1635 - final_cls: 0.6549 - final_regr: 0.4408 - loss: 4.7586
31/73 [===========>..................] - ETA: 7s - rpn_cls: 3.5087 - rpn_regr: 0.1629 - final_cls: 0.6550 - final_regr: 0.4399 - loss: 4.7665
32/73 [============>.................] - ETA: 7s - rpn_cls: 3.5198 - rpn_regr: 0.1622 - final_cls: 0.6550 - final_regr: 0.4386 - loss: 4.7757
33/73 [============>.................] - ETA: 6s - rpn_cls: 3.5302 - rpn_regr: 0.1617 - final_cls: 0.6549 - final_regr: 0.4375 - loss: 4.7842
34/73 [============>.................] - ETA: 6s - rpn_cls: 3.5368 - rpn_regr: 0.1611 - final_cls: 0.6546 - final_regr: 0.4366 - loss: 4.7891
35/73 [=============>................] - ETA: 6s - rpn_cls: 3.5429 - rpn_regr: 0.1607 - final_cls: 0.6544 - final_regr: 0.4358 - loss: 4.7938
36/73 [=============>................] - ETA: 6s - rpn_cls: 3.5458 - rpn_regr: 0.1604 - final_cls: 0.6542 - final_regr: 0.4354 - loss: 4.7957
37/73 [==============>...............] - ETA: 6s - rpn_cls: 3.5477 - rpn_regr: 0.1600 - final_cls: 0.6540 - final_regr: 0.4352 - loss: 4.7969
38/73 [==============>...............] - ETA: 6s - rpn_cls: 3.5504 - rpn_regr: 0.1596 - final_cls: 0.6537 - final_regr: 0.4349 - loss: 4.7987
39/73 [===============>..............] - ETA: 5s - rpn_cls: 3.5506 - rpn_regr: 0.1592 - final_cls: 0.6534 - final_regr: 0.4348 - loss: 4.7980
40/73 [===============>..............] - ETA: 5s - rpn_cls: 3.5525 - rpn_regr: 0.1588 - final_cls: 0.6531 - final_regr: 0.4344 - loss: 4.7987
41/73 [===============>..............] - ETA: 5s - rpn_cls: 3.5543 - rpn_regr: 0.1586 - final_cls: 0.6527 - final_regr: 0.4341 - loss: 4.7998
42/73 [================>.............] - ETA: 5s - rpn_cls: 3.5556 - rpn_regr: 0.1584 - final_cls: 0.6524 - final_regr: 0.4338 - loss: 4.8002
43/73 [================>.............] - ETA: 5s - rpn_cls: 3.5585 - rpn_regr: 0.1586 - final_cls: 0.6521 - final_regr: 0.4337 - loss: 4.8029
44/73 [=================>............] - ETA: 4s - rpn_cls: 3.5606 - rpn_regr: 0.1587 - final_cls: 0.6518 - final_regr: 0.4337 - loss: 4.8048
45/73 [=================>............] - ETA: 4s - rpn_cls: 3.5608 - rpn_regr: 0.1589 - final_cls: 0.6514 - final_regr: 0.4335 - loss: 4.8047
46/73 [=================>............] - ETA: 4s - rpn_cls: 3.5622 - rpn_regr: 0.1591 - final_cls: 0.6509 - final_regr: 0.4333 - loss: 4.8055
47/73 [==================>...........] - ETA: 4s - rpn_cls: 3.5649 - rpn_regr: 0.1593 - final_cls: 0.6503 - final_regr: 0.4332 - loss: 4.8077
48/73 [==================>...........] - ETA: 4s - rpn_cls: 3.5660 - rpn_regr: 0.1595 - final_cls: 0.6499 - final_regr: 0.4329 - loss: 4.8083
49/73 [===================>..........] - ETA: 4s - rpn_cls: 3.5699 - rpn_regr: 0.1598 - final_cls: 0.6496 - final_regr: 0.4325 - loss: 4.8118
50/73 [===================>..........] - ETA: 3s - rpn_cls: 3.5739 - rpn_regr: 0.1599 - final_cls: 0.6493 - final_regr: 0.4321 - loss: 4.8153
51/73 [===================>..........] - ETA: 3s - rpn_cls: 3.5778 - rpn_regr: 0.1602 - final_cls: 0.6491 - final_regr: 0.4317 - loss: 4.8188
52/73 [====================>.........] - ETA: 3s - rpn_cls: 3.5806 - rpn_regr: 0.1604 - final_cls: 0.6487 - final_regr: 0.4314 - loss: 4.8212
53/73 [====================>.........] - ETA: 3s - rpn_cls: 3.5843 - rpn_regr: 0.1607 - final_cls: 0.6484 - final_regr: 0.4309 - loss: 4.8243
54/73 [=====================>........] - ETA: 3s - rpn_cls: 3.5875 - rpn_regr: 0.1610 - final_cls: 0.6479 - final_regr: 0.4305 - loss: 4.8269
55/73 [=====================>........] - ETA: 3s - rpn_cls: 3.5893 - rpn_regr: 0.1612 - final_cls: 0.6474 - final_regr: 0.4301 - loss: 4.8279
56/73 [======================>.......] - ETA: 2s - rpn_cls: 3.5909 - rpn_regr: 0.1614 - final_cls: 0.6468 - final_regr: 0.4298 - loss: 4.8289
57/73 [======================>.......] - ETA: 2s - rpn_cls: 3.5953 - rpn_regr: 0.1615 - final_cls: 0.6462 - final_regr: 0.4294 - loss: 4.8324
58/73 [======================>.......] - ETA: 2s - rpn_cls: 3.5998 - rpn_regr: 0.1616 - final_cls: 0.6456 - final_regr: 0.4289 - loss: 4.8359
59/73 [=======================>......] - ETA: 2s - rpn_cls: 3.6030 - rpn_regr: 0.1617 - final_cls: 0.6449 - final_regr: 0.4285 - loss: 4.8381
60/73 [=======================>......] - ETA: 2s - rpn_cls: 3.6054 - rpn_regr: 0.1618 - final_cls: 0.6441 - final_regr: 0.4281 - loss: 4.8394
61/73 [========================>.....] - ETA: 2s - rpn_cls: 3.6084 - rpn_regr: 0.1618 - final_cls: 0.6433 - final_regr: 0.4276 - loss: 4.8410
62/73 [========================>.....] - ETA: 1s - rpn_cls: 3.6107 - rpn_regr: 0.1618 - final_cls: 0.6425 - final_regr: 0.4270 - loss: 4.8420
63/73 [========================>.....] - ETA: 1s - rpn_cls: 3.6137 - rpn_regr: 0.1618 - final_cls: 0.6416 - final_regr: 0.4265 - loss: 4.8435
64/73 [=========================>....] - ETA: 1s - rpn_cls: 3.6157 - rpn_regr: 0.1618 - final_cls: 0.6407 - final_regr: 0.4260 - loss: 4.8441
65/73 [=========================>....] - ETA: 1s - rpn_cls: 3.6167 - rpn_regr: 0.1619 - final_cls: 0.6398 - final_regr: 0.4254 - loss: 4.8438
66/73 [==========================>...] - ETA: 1s - rpn_cls: 3.6174 - rpn_regr: 0.1619 - final_cls: 0.6389 - final_regr: 0.4249 - loss: 4.8431
67/73 [==========================>...] - ETA: 1s - rpn_cls: 3.6173 - rpn_regr: 0.1620 - final_cls: 0.6380 - final_regr: 0.4243 - loss: 4.8416
68/73 [==========================>...] - ETA: 0s - rpn_cls: 3.6164 - rpn_regr: 0.1621 - final_cls: 0.6371 - final_regr: 0.4238 - loss: 4.8393
69/73 [===========================>..] - ETA: 0s - rpn_cls: 3.6157 - rpn_regr: 0.1621 - final_cls: 0.6361 - final_regr: 0.4232 - loss: 4.8371
70/73 [===========================>..] - ETA: 0s - rpn_cls: 3.6149 - rpn_regr: 0.1622 - final_cls: 0.6351 - final_regr: 0.4226 - loss: 4.8348
71/73 [============================>.] - ETA: 0s - rpn_cls: 3.6138 - rpn_regr: 0.1622 - final_cls: 0.6342 - final_regr: 0.4221 - loss: 4.8323
72/73 [============================>.] - ETA: 0s - rpn_cls: 3.6127 - rpn_regr: 0.1622 - final_cls: 0.6333 - final_regr: 0.4216 - loss: 4.8298
73/73 [==============================] - 12s 170ms/step - rpn_cls: 3.6109 - rpn_regr: 0.1623 - final_cls: 0.6325 - final_regr: 0.4211 - loss: 4.8267
Mean number of bounding boxes from RPN overlapping ground truth boxes: 9.712328767123287
Classifier accuracy for bounding boxes from RPN: 0.7431506849315068
Loss RPN classifier: 3.480494592399127
Loss RPN regression: 0.16274628923465945
Loss Detector classifier: 0.5741593623406267
Loss Detector regression: 0.38322732730271064
Total loss: 4.6006275712771245
Elapsed time: 12.436379194259644
Start of the validation phase

 1/24 [>.............................] - ETA: 4:47 - rpn_cls_val: 13.1989 - rpn_regr_val: 0.1316 - final_cls_val: 0.9388 - final_regr_val: 0.5304 - loss_val: 14.7997
 2/24 [=>............................] - ETA: 2:18 - rpn_cls_val: 9.8992 - rpn_regr_val: 0.1291 - final_cls_val: 0.7839 - final_regr_val: 0.5172 - loss_val: 11.3293 
 3/24 [==>...........................] - ETA: 1:28 - rpn_cls_val: 8.4206 - rpn_regr_val: 0.1202 - final_cls_val: 0.7112 - final_regr_val: 0.4717 - loss_val: 9.7237 
 4/24 [====>.........................] - ETA: 1:03 - rpn_cls_val: 7.3399 - rpn_regr_val: 0.1228 - final_cls_val: 0.6643 - final_regr_val: 0.4603 - loss_val: 8.5873
 5/24 [=====>........................] - ETA: 48s - rpn_cls_val: 6.7000 - rpn_regr_val: 0.1288 - final_cls_val: 0.6229 - final_regr_val: 0.4469 - loss_val: 7.8985 
 6/24 [======>.......................] - ETA: 38s - rpn_cls_val: 6.1586 - rpn_regr_val: 0.1304 - final_cls_val: 0.6027 - final_regr_val: 0.4320 - loss_val: 7.3237
 7/24 [=======>......................] - ETA: 31s - rpn_cls_val: 5.7593 - rpn_regr_val: 0.1430 - final_cls_val: 0.5793 - final_regr_val: 0.4253 - loss_val: 6.9069
 8/24 [=========>....................] - ETA: 26s - rpn_cls_val: 5.4072 - rpn_regr_val: 0.1546 - final_cls_val: 0.5796 - final_regr_val: 0.4240 - loss_val: 6.5655
 9/24 [==========>...................] - ETA: 22s - rpn_cls_val: 5.1226 - rpn_regr_val: 0.1622 - final_cls_val: 0.5827 - final_regr_val: 0.4238 - loss_val: 6.2913
10/24 [===========>..................] - ETA: 18s - rpn_cls_val: 4.8664 - rpn_regr_val: 0.1678 - final_cls_val: 0.5819 - final_regr_val: 0.4243 - loss_val: 6.0404
11/24 [============>.................] - ETA: 15s - rpn_cls_val: 4.6739 - rpn_regr_val: 0.1717 - final_cls_val: 0.5802 - final_regr_val: 0.4242 - loss_val: 5.8500
12/24 [==============>...............] - ETA: 13s - rpn_cls_val: 4.5039 - rpn_regr_val: 0.1739 - final_cls_val: 0.5771 - final_regr_val: 0.4238 - loss_val: 5.6788
13/24 [===============>..............] - ETA: 11s - rpn_cls_val: 4.3519 - rpn_regr_val: 0.1748 - final_cls_val: 0.5769 - final_regr_val: 0.4230 - loss_val: 5.5266
14/24 [================>.............] - ETA: 9s - rpn_cls_val: 4.2088 - rpn_regr_val: 0.1753 - final_cls_val: 0.5788 - final_regr_val: 0.4220 - loss_val: 5.3849 
15/24 [=================>............] - ETA: 8s - rpn_cls_val: 4.0798 - rpn_regr_val: 0.1750 - final_cls_val: 0.5799 - final_regr_val: 0.4209 - loss_val: 5.2556
16/24 [===================>..........] - ETA: 6s - rpn_cls_val: 3.9581 - rpn_regr_val: 0.1744 - final_cls_val: 0.5808 - final_regr_val: 0.4200 - loss_val: 5.1333
17/24 [====================>.........] - ETA: 5s - rpn_cls_val: 3.8553 - rpn_regr_val: 0.1735 - final_cls_val: 0.5813 - final_regr_val: 0.4189 - loss_val: 5.0290
18/24 [=====================>........] - ETA: 4s - rpn_cls_val: 3.7572 - rpn_regr_val: 0.1725 - final_cls_val: 0.5807 - final_regr_val: 0.4175 - loss_val: 4.9280
19/24 [======================>.......] - ETA: 3s - rpn_cls_val: 3.6636 - rpn_regr_val: 0.1720 - final_cls_val: 0.5789 - final_regr_val: 0.4162 - loss_val: 4.8307
20/24 [========================>.....] - ETA: 2s - rpn_cls_val: 3.5928 - rpn_regr_val: 0.1715 - final_cls_val: 0.5763 - final_regr_val: 0.4145 - loss_val: 4.7551
21/24 [=========================>....] - ETA: 2s - rpn_cls_val: 3.5237 - rpn_regr_val: 0.1712 - final_cls_val: 0.5739 - final_regr_val: 0.4129 - loss_val: 4.6818
22/24 [==========================>...] - ETA: 1s - rpn_cls_val: 3.4586 - rpn_regr_val: 0.1712 - final_cls_val: 0.5726 - final_regr_val: 0.4122 - loss_val: 4.6147
23/24 [===========================>..] - ETA: 0s - rpn_cls_val: 3.3953 - rpn_regr_val: 0.1712 - final_cls_val: 0.5709 - final_regr_val: 0.4117 - loss_val: 4.5491
24/24 [==============================] - 14s 598ms/step - rpn_cls_val: 3.3413 - rpn_regr_val: 0.1714 - final_cls_val: 0.5697 - final_regr_val: 0.4110 - loss_val: 4.4934
End of the validation phase
Validation classifier accuracy for bounding boxes from RPN: 0.7604166666666666
Validation loss RPN classifier: 2.099051201160704
Validation loss RPN regression: 0.17549202172085643
Validation loss Detector classifier: 0.5415644937505325
Validation loss Detector regression: 0.3960381547609965
Total validation loss: 3.2121458713930893
Total validation loss decreased from 5.740342495031655 to 3.2121458713930893
Loading weights from ./model/vgg16_weights_tf_dim_ordering_tf_kernels.h5
Epoch 1/2

 1/97 [..............................] - ETA: 5:30 - rpn_cls: 8.4936 - rpn_regr: 0.1513 - final_cls: 0.6931 - final_regr: 0.4960 - loss: 9.8341
 2/97 [..............................] - ETA: 2:52 - rpn_cls: 7.9850 - rpn_regr: 0.1439 - final_cls: 0.6941 - final_regr: 0.5204 - loss: 9.3434
 3/97 [..............................] - ETA: 1:59 - rpn_cls: 8.3953 - rpn_regr: 0.1550 - final_cls: 0.6943 - final_regr: 0.5203 - loss: 9.7650
 4/97 [>.............................] - ETA: 1:31 - rpn_cls: 8.8196 - rpn_regr: 0.1560 - final_cls: 0.6942 - final_regr: 0.5066 - loss: 10.1763
 5/97 [>.............................] - ETA: 1:15 - rpn_cls: 8.9404 - rpn_regr: 0.1559 - final_cls: 0.6939 - final_regr: 0.4943 - loss: 10.2845
 6/97 [>.............................] - ETA: 1:04 - rpn_cls: 8.8842 - rpn_regr: 0.1592 - final_cls: 0.6939 - final_regr: 0.5001 - loss: 10.2373
 7/97 [=>............................] - ETA: 57s - rpn_cls: 8.8915 - rpn_regr: 0.1622 - final_cls: 0.6938 - final_regr: 0.5055 - loss: 10.2529 
 8/97 [=>............................] - ETA: 51s - rpn_cls: 8.8658 - rpn_regr: 0.1621 - final_cls: 0.6935 - final_regr: 0.5045 - loss: 10.2260
 9/97 [=>............................] - ETA: 47s - rpn_cls: 8.8199 - rpn_regr: 0.1625 - final_cls: 0.6933 - final_regr: 0.5041 - loss: 10.1799
10/97 [==>...........................] - ETA: 43s - rpn_cls: 8.8251 - rpn_regr: 0.1634 - final_cls: 0.6933 - final_regr: 0.5088 - loss: 10.1906
11/97 [==>...........................] - ETA: 40s - rpn_cls: 8.8388 - rpn_regr: 0.1636 - final_cls: 0.6932 - final_regr: 0.5132 - loss: 10.2089
12/97 [==>...........................] - ETA: 37s - rpn_cls: 8.7918 - rpn_regr: 0.1641 - final_cls: 0.6931 - final_regr: 0.5155 - loss: 10.1644
13/97 [===>..........................] - ETA: 35s - rpn_cls: 8.7255 - rpn_regr: 0.1641 - final_cls: 0.6930 - final_regr: 0.5178 - loss: 10.1003
14/97 [===>..........................] - ETA: 33s - rpn_cls: 8.6672 - rpn_regr: 0.1636 - final_cls: 0.6928 - final_regr: 0.5184 - loss: 10.0421
15/97 [===>..........................] - ETA: 31s - rpn_cls: 8.6055 - rpn_regr: 0.1645 - final_cls: 0.6927 - final_regr: 0.5186 - loss: 9.9814 
16/97 [===>..........................] - ETA: 30s - rpn_cls: 8.5474 - rpn_regr: 0.1650 - final_cls: 0.6926 - final_regr: 0.5190 - loss: 9.9241
17/97 [====>.........................] - ETA: 29s - rpn_cls: 8.5120 - rpn_regr: 0.1653 - final_cls: 0.6925 - final_regr: 0.5196 - loss: 9.8894
18/97 [====>.........................] - ETA: 28s - rpn_cls: 8.4820 - rpn_regr: 0.1654 - final_cls: 0.6925 - final_regr: 0.5199 - loss: 9.8598
19/97 [====>.........................] - ETA: 26s - rpn_cls: 8.4646 - rpn_regr: 0.1653 - final_cls: 0.6924 - final_regr: 0.5200 - loss: 9.8423
20/97 [=====>........................] - ETA: 25s - rpn_cls: 8.4285 - rpn_regr: 0.1655 - final_cls: 0.6923 - final_regr: 0.5209 - loss: 9.8072
21/97 [=====>........................] - ETA: 24s - rpn_cls: 8.3933 - rpn_regr: 0.1658 - final_cls: 0.6923 - final_regr: 0.5208 - loss: 9.7722
22/97 [=====>........................] - ETA: 24s - rpn_cls: 8.3544 - rpn_regr: 0.1660 - final_cls: 0.6922 - final_regr: 0.5207 - loss: 9.7334
23/97 [======>.......................] - ETA: 23s - rpn_cls: 8.3186 - rpn_regr: 0.1668 - final_cls: 0.6922 - final_regr: 0.5204 - loss: 9.6980
24/97 [======>.......................] - ETA: 22s - rpn_cls: 8.2766 - rpn_regr: 0.1673 - final_cls: 0.6921 - final_regr: 0.5201 - loss: 9.6562
25/97 [======>.......................] - ETA: 21s - rpn_cls: 8.2486 - rpn_regr: 0.1677 - final_cls: 0.6920 - final_regr: 0.5201 - loss: 9.6285
26/97 [=======>......................] - ETA: 21s - rpn_cls: 8.2197 - rpn_regr: 0.1678 - final_cls: 0.6920 - final_regr: 0.5200 - loss: 9.5995
27/97 [=======>......................] - ETA: 20s - rpn_cls: 8.1862 - rpn_regr: 0.1679 - final_cls: 0.6919 - final_regr: 0.5204 - loss: 9.5664
28/97 [=======>......................] - ETA: 19s - rpn_cls: 8.1559 - rpn_regr: 0.1680 - final_cls: 0.6919 - final_regr: 0.5207 - loss: 9.5365
29/97 [=======>......................] - ETA: 19s - rpn_cls: 8.1347 - rpn_regr: 0.1679 - final_cls: 0.6918 - final_regr: 0.5205 - loss: 9.5149
30/97 [========>.....................] - ETA: 18s - rpn_cls: 8.1195 - rpn_regr: 0.1679 - final_cls: 0.6917 - final_regr: 0.5200 - loss: 9.4992
31/97 [========>.....................] - ETA: 18s - rpn_cls: 8.1052 - rpn_regr: 0.1681 - final_cls: 0.6916 - final_regr: 0.5194 - loss: 9.4843
32/97 [========>.....................] - ETA: 17s - rpn_cls: 8.0914 - rpn_regr: 0.1683 - final_cls: 0.6915 - final_regr: 0.5187 - loss: 9.4699
33/97 [=========>....................] - ETA: 17s - rpn_cls: 8.0824 - rpn_regr: 0.1685 - final_cls: 0.6914 - final_regr: 0.5181 - loss: 9.46052021-03-03 22:17:41.280915: W tensorflow/core/common_runtime/bfc_allocator.cc:245] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.12GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2021-03-03 22:17:41.280962: W tensorflow/core/common_runtime/bfc_allocator.cc:245] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.12GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.

34/97 [=========>....................] - ETA: 17s - rpn_cls: 8.0725 - rpn_regr: 0.1688 - final_cls: 0.6913 - final_regr: 0.5174 - loss: 9.4501
35/97 [=========>....................] - ETA: 16s - rpn_cls: 8.0631 - rpn_regr: 0.1690 - final_cls: 0.6912 - final_regr: 0.5169 - loss: 9.4402
36/97 [==========>...................] - ETA: 17s - rpn_cls: 8.0532 - rpn_regr: 0.1691 - final_cls: 0.6912 - final_regr: 0.5164 - loss: 9.4298
37/97 [==========>...................] - ETA: 16s - rpn_cls: 8.0434 - rpn_regr: 0.1692 - final_cls: 0.6911 - final_regr: 0.5161 - loss: 9.4198
38/97 [==========>...................] - ETA: 16s - rpn_cls: 8.0289 - rpn_regr: 0.1693 - final_cls: 0.6910 - final_regr: 0.5159 - loss: 9.4051
39/97 [===========>..................] - ETA: 15s - rpn_cls: 8.0133 - rpn_regr: 0.1693 - final_cls: 0.6909 - final_regr: 0.5154 - loss: 9.3889
40/97 [===========>..................] - ETA: 15s - rpn_cls: 8.0007 - rpn_regr: 0.1692 - final_cls: 0.6908 - final_regr: 0.5150 - loss: 9.3757
41/97 [===========>..................] - ETA: 14s - rpn_cls: 7.9891 - rpn_regr: 0.1693 - final_cls: 0.6907 - final_regr: 0.5147 - loss: 9.3637
42/97 [===========>..................] - ETA: 14s - rpn_cls: 7.9774 - rpn_regr: 0.1694 - final_cls: 0.6906 - final_regr: 0.5145 - loss: 9.3519
43/97 [============>.................] - ETA: 14s - rpn_cls: 7.9659 - rpn_regr: 0.1694 - final_cls: 0.6905 - final_regr: 0.5144 - loss: 9.3402
44/97 [============>.................] - ETA: 13s - rpn_cls: 7.9569 - rpn_regr: 0.1694 - final_cls: 0.6904 - final_regr: 0.5143 - loss: 9.3310
45/97 [============>.................] - ETA: 13s - rpn_cls: 7.9447 - rpn_regr: 0.1694 - final_cls: 0.6903 - final_regr: 0.5142 - loss: 9.3186
46/97 [=============>................] - ETA: 13s - rpn_cls: 7.9322 - rpn_regr: 0.1693 - final_cls: 0.6902 - final_regr: 0.5142 - loss: 9.3059
47/97 [=============>................] - ETA: 12s - rpn_cls: 7.9173 - rpn_regr: 0.1692 - final_cls: 0.6901 - final_regr: 0.5141 - loss: 9.2908
48/97 [=============>................] - ETA: 12s - rpn_cls: 7.9027 - rpn_regr: 0.1691 - final_cls: 0.6900 - final_regr: 0.5141 - loss: 9.2759
49/97 [==============>...............] - ETA: 12s - rpn_cls: 7.8869 - rpn_regr: 0.1690 - final_cls: 0.6899 - final_regr: 0.5140 - loss: 9.2599
50/97 [==============>...............] - ETA: 11s - rpn_cls: 7.8690 - rpn_regr: 0.1689 - final_cls: 0.6898 - final_regr: 0.5140 - loss: 9.2417
51/97 [==============>...............] - ETA: 11s - rpn_cls: 7.8523 - rpn_regr: 0.1688 - final_cls: 0.6897 - final_regr: 0.5139 - loss: 9.2247
52/97 [===============>..............] - ETA: 11s - rpn_cls: 7.8360 - rpn_regr: 0.1687 - final_cls: 0.6896 - final_regr: 0.5138 - loss: 9.2082
53/97 [===============>..............] - ETA: 10s - rpn_cls: 7.8201 - rpn_regr: 0.1686 - final_cls: 0.6895 - final_regr: 0.5137 - loss: 9.1920
54/97 [===============>..............] - ETA: 10s - rpn_cls: 7.8047 - rpn_regr: 0.1686 - final_cls: 0.6895 - final_regr: 0.5135 - loss: 9.1762
55/97 [================>.............] - ETA: 10s - rpn_cls: 7.7888 - rpn_regr: 0.1685 - final_cls: 0.6894 - final_regr: 0.5133 - loss: 9.1600
56/97 [================>.............] - ETA: 9s - rpn_cls: 7.7734 - rpn_regr: 0.1684 - final_cls: 0.6893 - final_regr: 0.5131 - loss: 9.1441 
57/97 [================>.............] - ETA: 9s - rpn_cls: 7.7576 - rpn_regr: 0.1682 - final_cls: 0.6892 - final_regr: 0.5128 - loss: 9.1279
58/97 [================>.............] - ETA: 9s - rpn_cls: 7.7423 - rpn_regr: 0.1681 - final_cls: 0.6892 - final_regr: 0.5126 - loss: 9.1121
59/97 [=================>............] - ETA: 9s - rpn_cls: 7.7263 - rpn_regr: 0.1679 - final_cls: 0.6891 - final_regr: 0.5124 - loss: 9.0957
60/97 [=================>............] - ETA: 8s - rpn_cls: 7.7106 - rpn_regr: 0.1677 - final_cls: 0.6890 - final_regr: 0.5121 - loss: 9.0795
61/97 [=================>............] - ETA: 8s - rpn_cls: 7.6962 - rpn_regr: 0.1675 - final_cls: 0.6889 - final_regr: 0.5119 - loss: 9.0645
62/97 [==================>...........] - ETA: 8s - rpn_cls: 7.6815 - rpn_regr: 0.1673 - final_cls: 0.6889 - final_regr: 0.5116 - loss: 9.0493
63/97 [==================>...........] - ETA: 7s - rpn_cls: 7.6675 - rpn_regr: 0.1671 - final_cls: 0.6888 - final_regr: 0.5114 - loss: 9.0348
64/97 [==================>...........] - ETA: 7s - rpn_cls: 7.6533 - rpn_regr: 0.1669 - final_cls: 0.6887 - final_regr: 0.5111 - loss: 9.0201
65/97 [===================>..........] - ETA: 7s - rpn_cls: 7.6395 - rpn_regr: 0.1667 - final_cls: 0.6886 - final_regr: 0.5107 - loss: 9.0056
66/97 [===================>..........] - ETA: 7s - rpn_cls: 7.6256 - rpn_regr: 0.1666 - final_cls: 0.6885 - final_regr: 0.5104 - loss: 8.9910
67/97 [===================>..........] - ETA: 6s - rpn_cls: 7.6117 - rpn_regr: 0.1663 - final_cls: 0.6885 - final_regr: 0.5100 - loss: 8.9766
68/97 [====================>.........] - ETA: 6s - rpn_cls: 7.5969 - rpn_regr: 0.1661 - final_cls: 0.6884 - final_regr: 0.5098 - loss: 8.9612
69/97 [====================>.........] - ETA: 6s - rpn_cls: 7.5824 - rpn_regr: 0.1659 - final_cls: 0.6884 - final_regr: 0.5095 - loss: 8.9463
70/97 [====================>.........] - ETA: 6s - rpn_cls: 7.5670 - rpn_regr: 0.1658 - final_cls: 0.6884 - final_regr: 0.5093 - loss: 8.9305
71/97 [====================>.........] - ETA: 5s - rpn_cls: 7.5517 - rpn_regr: 0.1656 - final_cls: 0.6883 - final_regr: 0.5092 - loss: 8.9147
72/97 [=====================>........] - ETA: 5s - rpn_cls: 7.5355 - rpn_regr: 0.1654 - final_cls: 0.6883 - final_regr: 0.5090 - loss: 8.8982
73/97 [=====================>........] - ETA: 5s - rpn_cls: 7.5196 - rpn_regr: 0.1652 - final_cls: 0.6882 - final_regr: 0.5088 - loss: 8.8819
74/97 [=====================>........] - ETA: 5s - rpn_cls: 7.5042 - rpn_regr: 0.1650 - final_cls: 0.6882 - final_regr: 0.5086 - loss: 8.8660
75/97 [======================>.......] - ETA: 4s - rpn_cls: 7.4889 - rpn_regr: 0.1648 - final_cls: 0.6882 - final_regr: 0.5085 - loss: 8.8503
76/97 [======================>.......] - ETA: 4s - rpn_cls: 7.4737 - rpn_regr: 0.1646 - final_cls: 0.6881 - final_regr: 0.5083 - loss: 8.8347
77/97 [======================>.......] - ETA: 4s - rpn_cls: 7.4588 - rpn_regr: 0.1643 - final_cls: 0.6881 - final_regr: 0.5080 - loss: 8.8193
78/97 [=======================>......] - ETA: 4s - rpn_cls: 7.4442 - rpn_regr: 0.1641 - final_cls: 0.6881 - final_regr: 0.5078 - loss: 8.8041
79/97 [=======================>......] - ETA: 3s - rpn_cls: 7.4295 - rpn_regr: 0.1638 - final_cls: 0.6880 - final_regr: 0.5076 - loss: 8.7890
80/97 [=======================>......] - ETA: 3s - rpn_cls: 7.4147 - rpn_regr: 0.1636 - final_cls: 0.6880 - final_regr: 0.5073 - loss: 8.7736
81/97 [========================>.....] - ETA: 3s - rpn_cls: 7.4002 - rpn_regr: 0.1633 - final_cls: 0.6880 - final_regr: 0.5071 - loss: 8.7587
82/97 [========================>.....] - ETA: 3s - rpn_cls: 7.3853 - rpn_regr: 0.1631 - final_cls: 0.6880 - final_regr: 0.5069 - loss: 8.7433
83/97 [========================>.....] - ETA: 3s - rpn_cls: 7.3707 - rpn_regr: 0.1628 - final_cls: 0.6879 - final_regr: 0.5067 - loss: 8.7281
84/97 [========================>.....] - ETA: 2s - rpn_cls: 7.3558 - rpn_regr: 0.1625 - final_cls: 0.6879 - final_regr: 0.5066 - loss: 8.7128
85/97 [=========================>....] - ETA: 2s - rpn_cls: 7.3410 - rpn_regr: 0.1623 - final_cls: 0.6878 - final_regr: 0.5064 - loss: 8.6975
86/97 [=========================>....] - ETA: 2s - rpn_cls: 7.3264 - rpn_regr: 0.1620 - final_cls: 0.6878 - final_regr: 0.5062 - loss: 8.6824
87/97 [=========================>....] - ETA: 2s - rpn_cls: 7.3117 - rpn_regr: 0.1618 - final_cls: 0.6878 - final_regr: 0.5060 - loss: 8.6673
88/97 [==========================>...] - ETA: 1s - rpn_cls: 7.2970 - rpn_regr: 0.1615 - final_cls: 0.6877 - final_regr: 0.5059 - loss: 8.6522
89/97 [==========================>...] - ETA: 1s - rpn_cls: 7.2827 - rpn_regr: 0.1613 - final_cls: 0.6877 - final_regr: 0.5058 - loss: 8.6374
90/97 [==========================>...] - ETA: 1s - rpn_cls: 7.2684 - rpn_regr: 0.1610 - final_cls: 0.6876 - final_regr: 0.5056 - loss: 8.6227
91/97 [===========================>..] - ETA: 1s - rpn_cls: 7.2538 - rpn_regr: 0.1608 - final_cls: 0.6876 - final_regr: 0.5055 - loss: 8.6076
92/97 [===========================>..] - ETA: 1s - rpn_cls: 7.2387 - rpn_regr: 0.1605 - final_cls: 0.6875 - final_regr: 0.5054 - loss: 8.5921
93/97 [===========================>..] - ETA: 0s - rpn_cls: 7.2240 - rpn_regr: 0.1603 - final_cls: 0.6875 - final_regr: 0.5052 - loss: 8.5770
94/97 [============================>.] - ETA: 0s - rpn_cls: 7.2091 - rpn_regr: 0.1601 - final_cls: 0.6874 - final_regr: 0.5050 - loss: 8.5616
95/97 [============================>.] - ETA: 0s - rpn_cls: 7.1946 - rpn_regr: 0.1598 - final_cls: 0.6874 - final_regr: 0.5049 - loss: 8.5467
96/97 [============================>.] - ETA: 0s - rpn_cls: 7.1804 - rpn_regr: 0.1596 - final_cls: 0.6873 - final_regr: 0.5048 - loss: 8.5322
97/97 [==============================] - 20s 211ms/step - rpn_cls: 7.1665 - rpn_regr: 0.1594 - final_cls: 0.6873 - final_regr: 0.5046 - loss: 8.5178
Mean number of bounding boxes from RPN overlapping ground truth boxes: 8.639175257731958
Classifier accuracy for bounding boxes from RPN: 0.5979381443298969
Loss RPN classifier: 5.82910734675118
Loss RPN regression: 0.1377970284887964
Loss Detector classifier: 0.6834101984181356
Loss Detector regression: 0.4893404277636833
Total loss: 7.139655001421795
Elapsed time: 20.491838693618774
Epoch 2/2

 1/97 [..............................] - ETA: 19s - rpn_cls: 4.4782 - rpn_regr: 0.0561 - final_cls: 0.6682 - final_regr: 0.4105 - loss: 5.6129
 2/97 [..............................] - ETA: 17s - rpn_cls: 4.4906 - rpn_regr: 0.0606 - final_cls: 0.6638 - final_regr: 0.4717 - loss: 5.6866
 3/97 [..............................] - ETA: 17s - rpn_cls: 4.0002 - rpn_regr: 0.0732 - final_cls: 0.6465 - final_regr: 0.4739 - loss: 5.1939
 4/97 [>.............................] - ETA: 16s - rpn_cls: 3.8076 - rpn_regr: 0.0759 - final_cls: 0.6384 - final_regr: 0.4525 - loss: 4.9744
 5/97 [>.............................] - ETA: 15s - rpn_cls: 3.6880 - rpn_regr: 0.0802 - final_cls: 0.6339 - final_regr: 0.4430 - loss: 4.8452
 6/97 [>.............................] - ETA: 15s - rpn_cls: 3.7086 - rpn_regr: 0.0917 - final_cls: 0.6312 - final_regr: 0.4332 - loss: 4.8646
 7/97 [=>............................] - ETA: 15s - rpn_cls: 3.7160 - rpn_regr: 0.0991 - final_cls: 0.6270 - final_regr: 0.4253 - loss: 4.8674
 8/97 [=>............................] - ETA: 15s - rpn_cls: 3.7597 - rpn_regr: 0.1039 - final_cls: 0.6245 - final_regr: 0.4188 - loss: 4.9068
 9/97 [=>............................] - ETA: 14s - rpn_cls: 3.8211 - rpn_regr: 0.1062 - final_cls: 0.6197 - final_regr: 0.4121 - loss: 4.9591
10/97 [==>...........................] - ETA: 15s - rpn_cls: 3.8740 - rpn_regr: 0.1106 - final_cls: 0.6144 - final_regr: 0.4067 - loss: 5.0056
11/97 [==>...........................] - ETA: 14s - rpn_cls: 3.8896 - rpn_regr: 0.1173 - final_cls: 0.6103 - final_regr: 0.4068 - loss: 5.0240
12/97 [==>...........................] - ETA: 14s - rpn_cls: 3.8921 - rpn_regr: 0.1219 - final_cls: 0.6073 - final_regr: 0.4052 - loss: 5.0265
13/97 [===>..........................] - ETA: 14s - rpn_cls: 3.9027 - rpn_regr: 0.1249 - final_cls: 0.6074 - final_regr: 0.4034 - loss: 5.0383
14/97 [===>..........................] - ETA: 14s - rpn_cls: 3.9063 - rpn_regr: 0.1311 - final_cls: 0.6069 - final_regr: 0.4037 - loss: 5.0479
15/97 [===>..........................] - ETA: 13s - rpn_cls: 3.9086 - rpn_regr: 0.1361 - final_cls: 0.6065 - final_regr: 0.4035 - loss: 5.0547
16/97 [===>..........................] - ETA: 13s - rpn_cls: 3.9031 - rpn_regr: 0.1402 - final_cls: 0.6065 - final_regr: 0.4039 - loss: 5.0537
17/97 [====>.........................] - ETA: 13s - rpn_cls: 3.8849 - rpn_regr: 0.1434 - final_cls: 0.6068 - final_regr: 0.4040 - loss: 5.0392
18/97 [====>.........................] - ETA: 13s - rpn_cls: 3.8747 - rpn_regr: 0.1460 - final_cls: 0.6069 - final_regr: 0.4037 - loss: 5.0313
19/97 [====>.........................] - ETA: 13s - rpn_cls: 3.8554 - rpn_regr: 0.1485 - final_cls: 0.6068 - final_regr: 0.4036 - loss: 5.0143
20/97 [=====>........................] - ETA: 13s - rpn_cls: 3.8376 - rpn_regr: 0.1513 - final_cls: 0.6070 - final_regr: 0.4040 - loss: 4.9999
21/97 [=====>........................] - ETA: 13s - rpn_cls: 3.8277 - rpn_regr: 0.1535 - final_cls: 0.6067 - final_regr: 0.4043 - loss: 4.9922
22/97 [=====>........................] - ETA: 12s - rpn_cls: 3.8118 - rpn_regr: 0.1556 - final_cls: 0.6064 - final_regr: 0.4045 - loss: 4.9783
23/97 [======>.......................] - ETA: 12s - rpn_cls: 3.8157 - rpn_regr: 0.1572 - final_cls: 0.6062 - final_regr: 0.4039 - loss: 4.9830
24/97 [======>.......................] - ETA: 12s - rpn_cls: 3.8241 - rpn_regr: 0.1587 - final_cls: 0.6060 - final_regr: 0.4035 - loss: 4.9922
25/97 [======>.......................] - ETA: 12s - rpn_cls: 3.8254 - rpn_regr: 0.1599 - final_cls: 0.6055 - final_regr: 0.4031 - loss: 4.9939
26/97 [=======>......................] - ETA: 11s - rpn_cls: 3.8209 - rpn_regr: 0.1611 - final_cls: 0.6050 - final_regr: 0.4028 - loss: 4.9898
27/97 [=======>......................] - ETA: 11s - rpn_cls: 3.8205 - rpn_regr: 0.1622 - final_cls: 0.6043 - final_regr: 0.4025 - loss: 4.9896
28/97 [=======>......................] - ETA: 11s - rpn_cls: 3.8191 - rpn_regr: 0.1632 - final_cls: 0.6037 - final_regr: 0.4022 - loss: 4.9882
29/97 [=======>......................] - ETA: 11s - rpn_cls: 3.8135 - rpn_regr: 0.1639 - final_cls: 0.6032 - final_regr: 0.4021 - loss: 4.9826
30/97 [========>.....................] - ETA: 11s - rpn_cls: 3.8080 - rpn_regr: 0.1644 - final_cls: 0.6025 - final_regr: 0.4018 - loss: 4.9767
31/97 [========>.....................] - ETA: 11s - rpn_cls: 3.8028 - rpn_regr: 0.1648 - final_cls: 0.6018 - final_regr: 0.4016 - loss: 4.9710
32/97 [========>.....................] - ETA: 11s - rpn_cls: 3.7987 - rpn_regr: 0.1651 - final_cls: 0.6011 - final_regr: 0.4013 - loss: 4.9662
33/97 [=========>....................] - ETA: 10s - rpn_cls: 3.7915 - rpn_regr: 0.1658 - final_cls: 0.6003 - final_regr: 0.4008 - loss: 4.9584
34/97 [=========>....................] - ETA: 10s - rpn_cls: 3.7824 - rpn_regr: 0.1664 - final_cls: 0.5994 - final_regr: 0.4004 - loss: 4.9487
35/97 [=========>....................] - ETA: 10s - rpn_cls: 3.7762 - rpn_regr: 0.1671 - final_cls: 0.5984 - final_regr: 0.3999 - loss: 4.9416
36/97 [==========>...................] - ETA: 10s - rpn_cls: 3.7717 - rpn_regr: 0.1677 - final_cls: 0.5973 - final_regr: 0.3995 - loss: 4.9362
37/97 [==========>...................] - ETA: 10s - rpn_cls: 3.7679 - rpn_regr: 0.1688 - final_cls: 0.5974 - final_regr: 0.3990 - loss: 4.9331
38/97 [==========>...................] - ETA: 10s - rpn_cls: 3.7661 - rpn_regr: 0.1701 - final_cls: 0.5972 - final_regr: 0.3985 - loss: 4.9319
39/97 [===========>..................] - ETA: 9s - rpn_cls: 3.7637 - rpn_regr: 0.1714 - final_cls: 0.5968 - final_regr: 0.3979 - loss: 4.9298 
40/97 [===========>..................] - ETA: 9s - rpn_cls: 3.7591 - rpn_regr: 0.1728 - final_cls: 0.5965 - final_regr: 0.3974 - loss: 4.9258
41/97 [===========>..................] - ETA: 9s - rpn_cls: 3.7527 - rpn_regr: 0.1744 - final_cls: 0.5960 - final_regr: 0.3969 - loss: 4.9200
42/97 [===========>..................] - ETA: 9s - rpn_cls: 3.7458 - rpn_regr: 0.1758 - final_cls: 0.5954 - final_regr: 0.3965 - loss: 4.9136
43/97 [============>.................] - ETA: 9s - rpn_cls: 3.7375 - rpn_regr: 0.1772 - final_cls: 0.5947 - final_regr: 0.3960 - loss: 4.9054
44/97 [============>.................] - ETA: 9s - rpn_cls: 3.7277 - rpn_regr: 0.1784 - final_cls: 0.5939 - final_regr: 0.3956 - loss: 4.8956
45/97 [============>.................] - ETA: 8s - rpn_cls: 3.7201 - rpn_regr: 0.1796 - final_cls: 0.5930 - final_regr: 0.3950 - loss: 4.8877
46/97 [=============>................] - ETA: 8s - rpn_cls: 3.7113 - rpn_regr: 0.1807 - final_cls: 0.5924 - final_regr: 0.3946 - loss: 4.8790
47/97 [=============>................] - ETA: 8s - rpn_cls: 3.7069 - rpn_regr: 0.1819 - final_cls: 0.5919 - final_regr: 0.3942 - loss: 4.8750
48/97 [=============>................] - ETA: 8s - rpn_cls: 3.7012 - rpn_regr: 0.1830 - final_cls: 0.5913 - final_regr: 0.3939 - loss: 4.8695
49/97 [==============>...............] - ETA: 8s - rpn_cls: 3.6943 - rpn_regr: 0.1840 - final_cls: 0.5906 - final_regr: 0.3937 - loss: 4.8627
50/97 [==============>...............] - ETA: 8s - rpn_cls: 3.6864 - rpn_regr: 0.1849 - final_cls: 0.5901 - final_regr: 0.3936 - loss: 4.8550
51/97 [==============>...............] - ETA: 7s - rpn_cls: 3.6784 - rpn_regr: 0.1856 - final_cls: 0.5896 - final_regr: 0.3934 - loss: 4.8470
52/97 [===============>..............] - ETA: 7s - rpn_cls: 3.6713 - rpn_regr: 0.1864 - final_cls: 0.5892 - final_regr: 0.3932 - loss: 4.8402
53/97 [===============>..............] - ETA: 7s - rpn_cls: 3.6637 - rpn_regr: 0.1874 - final_cls: 0.5888 - final_regr: 0.3931 - loss: 4.8330
54/97 [===============>..............] - ETA: 7s - rpn_cls: 3.6553 - rpn_regr: 0.1883 - final_cls: 0.5884 - final_regr: 0.3928 - loss: 4.8248
55/97 [================>.............] - ETA: 7s - rpn_cls: 3.6470 - rpn_regr: 0.1891 - final_cls: 0.5880 - final_regr: 0.3926 - loss: 4.8167
56/97 [================>.............] - ETA: 6s - rpn_cls: 3.6381 - rpn_regr: 0.1899 - final_cls: 0.5874 - final_regr: 0.3923 - loss: 4.8077
57/97 [================>.............] - ETA: 6s - rpn_cls: 3.6288 - rpn_regr: 0.1907 - final_cls: 0.5870 - final_regr: 0.3920 - loss: 4.7986
58/97 [================>.............] - ETA: 6s - rpn_cls: 3.6190 - rpn_regr: 0.1915 - final_cls: 0.5866 - final_regr: 0.3917 - loss: 4.7888
59/97 [=================>............] - ETA: 6s - rpn_cls: 3.6090 - rpn_regr: 0.1922 - final_cls: 0.5862 - final_regr: 0.3914 - loss: 4.7787
60/97 [=================>............] - ETA: 6s - rpn_cls: 3.5988 - rpn_regr: 0.1929 - final_cls: 0.5858 - final_regr: 0.3913 - loss: 4.7688
61/97 [=================>............] - ETA: 6s - rpn_cls: 3.5893 - rpn_regr: 0.1935 - final_cls: 0.5855 - final_regr: 0.3911 - loss: 4.7593
62/97 [==================>...........] - ETA: 5s - rpn_cls: 3.5809 - rpn_regr: 0.1940 - final_cls: 0.5851 - final_regr: 0.3908 - loss: 4.7508
63/97 [==================>...........] - ETA: 6s - rpn_cls: 3.5721 - rpn_regr: 0.1946 - final_cls: 0.5846 - final_regr: 0.3905 - loss: 4.7418
64/97 [==================>...........] - ETA: 5s - rpn_cls: 3.5627 - rpn_regr: 0.1951 - final_cls: 0.5842 - final_regr: 0.3902 - loss: 4.7323
65/97 [===================>..........] - ETA: 5s - rpn_cls: 3.5534 - rpn_regr: 0.1955 - final_cls: 0.5838 - final_regr: 0.3901 - loss: 4.7228
66/97 [===================>..........] - ETA: 5s - rpn_cls: 3.5442 - rpn_regr: 0.1959 - final_cls: 0.5833 - final_regr: 0.3899 - loss: 4.7133
67/97 [===================>..........] - ETA: 5s - rpn_cls: 3.5346 - rpn_regr: 0.1964 - final_cls: 0.5829 - final_regr: 0.3897 - loss: 4.7034
68/97 [====================>.........] - ETA: 5s - rpn_cls: 3.5246 - rpn_regr: 0.1968 - final_cls: 0.5824 - final_regr: 0.3895 - loss: 4.6933
69/97 [====================>.........] - ETA: 4s - rpn_cls: 3.5148 - rpn_regr: 0.1972 - final_cls: 0.5820 - final_regr: 0.3893 - loss: 4.6833
70/97 [====================>.........] - ETA: 4s - rpn_cls: 3.5047 - rpn_regr: 0.1976 - final_cls: 0.5816 - final_regr: 0.3891 - loss: 4.6730
71/97 [====================>.........] - ETA: 4s - rpn_cls: 3.4949 - rpn_regr: 0.1979 - final_cls: 0.5812 - final_regr: 0.3890 - loss: 4.6630
72/97 [=====================>........] - ETA: 4s - rpn_cls: 3.4857 - rpn_regr: 0.1982 - final_cls: 0.5808 - final_regr: 0.3888 - loss: 4.6536
73/97 [=====================>........] - ETA: 4s - rpn_cls: 3.4766 - rpn_regr: 0.1985 - final_cls: 0.5805 - final_regr: 0.3887 - loss: 4.6443
74/97 [=====================>........] - ETA: 4s - rpn_cls: 3.4691 - rpn_regr: 0.1988 - final_cls: 0.5801 - final_regr: 0.3886 - loss: 4.6366
75/97 [======================>.......] - ETA: 3s - rpn_cls: 3.4613 - rpn_regr: 0.1990 - final_cls: 0.5798 - final_regr: 0.3885 - loss: 4.6286
76/97 [======================>.......] - ETA: 3s - rpn_cls: 3.4538 - rpn_regr: 0.1992 - final_cls: 0.5794 - final_regr: 0.3884 - loss: 4.6208
77/97 [======================>.......] - ETA: 3s - rpn_cls: 3.4460 - rpn_regr: 0.1993 - final_cls: 0.5791 - final_regr: 0.3883 - loss: 4.6127
78/97 [=======================>......] - ETA: 3s - rpn_cls: 3.4391 - rpn_regr: 0.1995 - final_cls: 0.5787 - final_regr: 0.3882 - loss: 4.6054
79/97 [=======================>......] - ETA: 3s - rpn_cls: 3.4318 - rpn_regr: 0.1996 - final_cls: 0.5783 - final_regr: 0.3881 - loss: 4.5978
80/97 [=======================>......] - ETA: 3s - rpn_cls: 3.4243 - rpn_regr: 0.1998 - final_cls: 0.5779 - final_regr: 0.3880 - loss: 4.5899
81/97 [========================>.....] - ETA: 2s - rpn_cls: 3.4165 - rpn_regr: 0.2000 - final_cls: 0.5775 - final_regr: 0.3879 - loss: 4.5819
82/97 [========================>.....] - ETA: 2s - rpn_cls: 3.4095 - rpn_regr: 0.2001 - final_cls: 0.5771 - final_regr: 0.3878 - loss: 4.5745
83/97 [========================>.....] - ETA: 2s - rpn_cls: 3.4026 - rpn_regr: 0.2003 - final_cls: 0.5766 - final_regr: 0.3877 - loss: 4.5671
84/97 [========================>.....] - ETA: 2s - rpn_cls: 3.3956 - rpn_regr: 0.2004 - final_cls: 0.5760 - final_regr: 0.3875 - loss: 4.5596
85/97 [=========================>....] - ETA: 2s - rpn_cls: 3.3886 - rpn_regr: 0.2005 - final_cls: 0.5755 - final_regr: 0.3874 - loss: 4.5520
86/97 [=========================>....] - ETA: 1s - rpn_cls: 3.3828 - rpn_regr: 0.2007 - final_cls: 0.5749 - final_regr: 0.3874 - loss: 4.5457
87/97 [=========================>....] - ETA: 1s - rpn_cls: 3.3770 - rpn_regr: 0.2008 - final_cls: 0.5744 - final_regr: 0.3873 - loss: 4.5395
88/97 [==========================>...] - ETA: 1s - rpn_cls: 3.3717 - rpn_regr: 0.2009 - final_cls: 0.5739 - final_regr: 0.3872 - loss: 4.5337
89/97 [==========================>...] - ETA: 1s - rpn_cls: 3.3664 - rpn_regr: 0.2009 - final_cls: 0.5734 - final_regr: 0.3870 - loss: 4.5278
90/97 [==========================>...] - ETA: 1s - rpn_cls: 3.3612 - rpn_regr: 0.2010 - final_cls: 0.5728 - final_regr: 0.3869 - loss: 4.5219
91/97 [===========================>..] - ETA: 1s - rpn_cls: 3.3561 - rpn_regr: 0.2011 - final_cls: 0.5724 - final_regr: 0.3867 - loss: 4.5163
92/97 [===========================>..] - ETA: 0s - rpn_cls: 3.3507 - rpn_regr: 0.2012 - final_cls: 0.5719 - final_regr: 0.3866 - loss: 4.5104
93/97 [===========================>..] - ETA: 0s - rpn_cls: 3.3451 - rpn_regr: 0.2012 - final_cls: 0.5715 - final_regr: 0.3865 - loss: 4.5044
94/97 [============================>.] - ETA: 0s - rpn_cls: 3.3401 - rpn_regr: 0.2013 - final_cls: 0.5711 - final_regr: 0.3863 - loss: 4.4988
95/97 [============================>.] - ETA: 0s - rpn_cls: 3.3353 - rpn_regr: 0.2013 - final_cls: 0.5707 - final_regr: 0.3862 - loss: 4.4934
96/97 [============================>.] - ETA: 0s - rpn_cls: 3.3304 - rpn_regr: 0.2013 - final_cls: 0.5703 - final_regr: 0.3861 - loss: 4.4881
97/97 [==============================] - 17s 175ms/step - rpn_cls: 3.3254 - rpn_regr: 0.2013 - final_cls: 0.5698 - final_regr: 0.3860 - loss: 4.4826
Using TensorFlow backend.
/home/vbeyraghi/Faster_RCNN_for_Open_Images_Dataset_Keras/recorder.py:30: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  plt.figure(figsize=(15, 5))
Mean number of bounding boxes from RPN overlapping ground truth boxes: 9.29896907216495
Classifier accuracy for bounding boxes from RPN: 0.7680412371134021
Loss RPN classifier: 2.8430578031440175
Loss RPN regression: 0.20328031167311153
Loss Detector classifier: 0.5277874477438091
Loss Detector regression: 0.3777132690260091
Total loss: 3.9518388315869473
Elapsed time: 17.01323938369751
Training complete, exiting.
